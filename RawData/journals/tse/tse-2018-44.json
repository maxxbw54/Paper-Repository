[
    {
        "title": "State of the Journal.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2778898",
        "volume": "44",
        "abstract": "Presents the state of the journal for this issue of the publication."
    },
    {
        "title": "Editorial from the New Editor in Chief.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2778899",
        "volume": "44",
        "abstract": "Presents the introductory editorial for this issue of the publication."
    },
    {
        "title": "A Developer Centered Bug Prediction Model.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2659747",
        "volume": "44",
        "abstract": "Several techniques have been proposed to accurately predict software defects. These techniques generally exploit characteristics of the code artefacts (e.g., size, complexity, etc.) and/or of the process adopted during their development and maintenance (e.g., the number of developers working on a component) to spot out components likely containing bugs. While these bug prediction models achieve good levels of accuracy, they mostly ignore the major role played by human-related factors in the introduction of bugs. Previous studies have demonstrated that focused developers are less prone to introduce defects than non-focused developers. According to this observation, software components changed by focused developers should also be less error prone than components changed by less focused developers. We capture this observation by measuring the scattering of changes performed by developers working on a component and use this information to build a bug prediction model. Such a model has been evaluated on 26 systems and compared with four competitive techniques. The achieved results show the superiority of our model, and its high complementarity with respect to predictors commonly used in the literature. Based on this result, we also show the results of a “hybrid” prediction model combining our predictors with the existing ones.",
        "keywords": [
            "Measurement",
            "Computer bugs",
            "Predictive models",
            "Complexity theory",
            "Scattering",
            "Entropy",
            "Software"
        ]
    },
    {
        "title": "Eliminating Path Redundancy via Postconditioned Symbolic Execution.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2659751",
        "volume": "44",
        "abstract": "Symbolic execution is emerging as a powerful technique for generating test inputs systematically to achieve exhaustive path coverage of a bounded depth. However, its practical use is often limited by path explosion because the number of paths of a program can be exponential in the number of branch conditions encountered during the execution. To mitigate the path explosion problem, we propose a new redundancy removal method called postconditioned symbolic execution. At each branching location, in addition to determine whether a particular branch is feasible as in traditional symbolic execution, our approach checks whether the branch is subsumed by previous explorations. This is enabled by summarizing previously explored paths by weakest precondition computations. Postconditioned symbolic execution can identify path suffixes shared by multiple runs and eliminate them during test generation when they are redundant. Pruning away such redundant paths can lead to a potentially exponential reduction in the number of explored paths. Since the new approach is computationally expensive, we also propose several heuristics to reduce its cost. We have implemented our method in the symbolic execution engine KLEE [1] and conducted experiments on a large set of programs from the GNU Coreutils suite. Our results confirm that redundancy due to common path suffix is both abundant and widespread in real-world applications.",
        "keywords": [
            "Concrete",
            "Explosions",
            "Input variables",
            "Redundancy",
            "Software",
            "Syntactics",
            "Testing"
        ]
    },
    {
        "title": "Empirical Evaluation of the Impact of Object-Oriented Code Refactoring on Quality Attributes: A Systematic Literature Review.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2658573",
        "volume": "44",
        "abstract": "Software refactoring is a maintenance task that addresses code restructuring to improve its quality. Many studies have addressed the impact of different refactoring scenarios on software quality. This study presents a systematic literature review that aggregates, summarizes, and discusses the results of 76 relevant primary studies (PSs) concerning the impact of refactoring on several internal and external quality attributes. The included PSs were selected using inclusion and exclusion criteria applied to relevant articles published before the end of 2015. We analyzed the PSs based on a set of classification criteria, including software quality attributes and measures, refactoring scenarios, evaluation approaches, datasets, and impact results. We followed the vote-counting approach to determine the level of consistency among the PS reported results concerning the relationship between refactoring and software quality. The results indicated that different refactoring scenarios sometimes have opposite impacts on different quality attributes. Therefore, it is false that refactoring always improves all software quality aspects. The vote-counting study provided a clear view of the impacts of some individual refactoring scenarios on some internal quality attributes such as cohesion, coupling, complexity, inheritance, and size, but failed to identify their impacts on external and other internal quality attributes due to insufficient findings.",
        "keywords": [
            "Software quality",
            "Systematics",
            "Unified modeling language",
            "Bibliographies",
            "Libraries",
            "Object oriented modeling"
        ]
    },
    {
        "title": "Test Case Generation for Boolean Expressions by Cell Covering.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2669184",
        "volume": "44",
        "abstract": "This paper characterizes Boolean expression faults as changes of the topological structures in terms of shrinking and/or expanding regions in K-map. A cell-covering is a set of cells (test cases) in K-map to cover the fault regions such that faults guarantee to be detected. Minimizing cell covering can be formulated as an Integer Linear Programming (ILP) problem. By analyzing the structures of the constraint coefficient matrix, the original problem can be decomposed into sub-programs that can be solved instead of the original problem, and this significantly reduces the time needed for ILP execution. An efficient approximate algorithm with a tight theoretical bound is used to address those complex Boolean expressions by corresponding the cell-covering problem to the set-covering problem. The optimal approach and the approximate approach are combined into a hybrid process to identify test cases based on the fraction analysis on the ILP relaxation. The proposed approach is evaluated by three sets of Boolean expressions and the results are compared with three leading approaches with respect to test sizes, time consumption and fault detection capabilities. For most Boolean expressions encountered, the proposed approach obtains optimal solutions quickly, and produces near-optimal solutions rapidly for those rare and complex expressions.",
        "keywords": [
            "Fault detection",
            "Approximation algorithms",
            "Optimization",
            "Periodic structures",
            "Algorithm design and analysis",
            "Testing",
            "Software"
        ]
    },
    {
        "title": "A Templating System to Generate Provenance.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2659745",
        "volume": "44",
        "abstract": "PROV-TEMPLATEIS a declarative approach that enables designers and programmers to design and generate provenance compatible with the PROV standard of the World Wide Web Consortium. Designers specify the topology of the provenance to be generated by composing templates, which are provenance graphs containing variables, acting as placeholders for values. Programmers write programs that log values and package them up in sets of bindings, a data structure associating variables and values. An expansion algorithm generates instantiated provenance from templates and sets of bindings in any of the serialisation formats supported by PROV. A quantitative evaluation shows that sets of bindings have a size that is typically 40 percent of that of expanded provenance templates and that the expansion algorithm is suitably tractable, operating in fractions of milliseconds for the type of templates surveyed in the article. Furthermore, the approach shows four significant software engineering benefits: separation of responsibilities, provenance maintenance, potential runtime checks and static analysis, and provenance consumption. The article gathers quantitative data and qualitative benefits descriptions from four different applications making use of PROV-TEMPLATE. The system is implemented and released in the open-source library ProvToolbox for provenance processing.",
        "keywords": [
            "Electronic publishing",
            "Instruments",
            "Standards",
            "Maintenance engineering",
            "Runtime",
            "Libraries",
            "Automobiles"
        ]
    },
    {
        "title": "Automated Test Case Generation as a Many-Objective Optimisation Problem with Dynamic Selection of the Targets.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2663435",
        "volume": "44",
        "abstract": "The test case generation is intrinsically a multi-objective problem, since the goal is covering multiple test targets (e.g., branches). Existing search-based approaches either consider one target at a time or aggregate all targets into a single fitness function (whole-suite approach). Multi and many-objective optimisation algorithms (MOAs) have never been applied to this problem, because existing algorithms do not scale to the number of coverage objectives that are typically found in real-world software. In addition, the final goal for MOAs is to find alternative trade-off solutions in the objective space, while in test generation the interesting solutions are only those test cases covering one or more uncovered targets. In this paper, we present Dynamic Many-Objective Sorting Algorithm (DynaMOSA), a novel many-objective solver specifically designed to address the test case generation problem in the context of coverage testing. DynaMOSA extends our previous many-objective technique Many-Objective Sorting Algorithm (MOSA) with dynamic selection of the coverage targets based on the control dependency hierarchy. Such extension makes the approach more effective and efficient in case of limited search budget. We carried out an empirical study on 346 Java classes using three coverage criteria (i.e., statement, branch, and strong mutation coverage) to assess the performance of DynaMOSA with respect to the whole-suite approach (WS), its archive-based variant (WSA) and MOSA. The results show that DynaMOSA outperforms WSA in 28 percent of the classes for branch coverage (+8 percent more coverage on average) and in 27 percent of the classes for mutation coverage (+11 percent more killed mutants on average). It outperforms WS in 51 percent of the classes for statement coverage, leading to +11 percent more coverage on average. Moreover, DynaMOSA outperforms its predecessor MOSA for all the three coverage criteria in 19 percent of the classes with +8 percent more code coverage on average.",
        "keywords": [
            "Heuristic algorithms",
            "Optimization",
            "Testing",
            "Software algorithms",
            "Algorithm design and analysis",
            "Sorting",
            "Genetic algorithms"
        ]
    },
    {
        "title": "Measuring the Impact of Code Dependencies on Software Architecture Recovery Techniques.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2671865",
        "volume": "44",
        "abstract": "Many techniques have been proposed to automatically recover software architectures from software implementations. A thorough comparison among the recovery techniques is needed to understand their effectiveness and applicability. This study improves on previous studies in two ways. First, we study the impact of leveraging accurate symbol dependencies on the accuracy of architecture recovery techniques. In addition, we evaluate other factors of the input dependencies such as the level of granularity and the dynamic-bindings graph construction. Second, we recovered the architecture of a large system, Chromium, that was not available previously. Obtaining the ground-truth architecture of Chromium involved two years of collaboration with its developers. As part of this work, we developed a new submodule-based technique to recover preliminary versions of ground-truth architectures. The results of our evaluation of nine architecture recovery techniques and their variants suggest that (1) using accurate symbol dependencies has a major influence on recovery quality, and (2) more accurate recovery techniques are needed. Our results show that some of the studied architecture recovery techniques scale to very large systems, whereas others do not.",
        "keywords": [
            "Computer architecture",
            "Software architecture",
            "Software",
            "Heuristic algorithms",
            "Chromium",
            "Software algorithms",
            "Manuals"
        ]
    },
    {
        "title": "Semantic Slicing of Software Version Histories.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2664824",
        "volume": "44",
        "abstract": "Software developers often need to transfer functionality, e.g., a set of commits implementing a new feature or a bug fix, from one branch of a configuration management system to another. That can be a challenging task as the existing configuration management tools lack support for matching high-level, semantic functionality with low-level version histories. The developer thus has to either manually identify the exact set of semantically-related commits implementing the functionality of interest or sequentially port a segment of the change history, “inheriting” additional, unwanted functionality. In this paper, we tackle this problem by providing automated support for identifying the set of semantically-related commits implementing a particular functionality, which is defined by a set of tests. We formally define the semantic slicing problem, provide an algorithm for identifying a set of commits that constitute a slice, and propose techniques to minimize the produced slice. We then instantiate the overall approach, CSlicer, in a specific implementation for Java projects managed in Git and evaluate its correctness and effectiveness on a set of open-source software repositories. We show that it allows to identify subsets of change histories that maintain the functionality of interest but are substantially smaller than the original ones.",
        "keywords": [
            "History",
            "Semantics",
            "Software",
            "Minimization",
            "Context",
            "Computer bugs",
            "Java"
        ]
    },
    {
        "title": "Automatic Software Refactoring via Weighted Clustering in Method-Level Networks.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2679752",
        "volume": "44",
        "abstract": "In this study, we describe a system-level multiple refactoring algorithm, which can identify the move method, move field, and extract class refactoring opportunities automatically according to the principle of “high cohesion and low coupling.” The algorithm works by merging and splitting related classes to obtain the optimal functionality distribution from the system-level. Furthermore, we present a weighted clustering algorithm for regrouping the entities in a system based on merged method-level networks. Using a series of preprocessing steps and preconditions, the “bad smells” introduced by cohesion and coupling problems can be removed from both the non-inheritance and inheritance hierarchies without changing the code behaviors. We rank the refactoring suggestions based on the anticipated benefits that they bring to the system. Based on comparisons with related research and assessing the refactoring results using quality metrics and empirical evaluation, we show that the proposed approach performs well in different systems and is beneficial from the perspective of the original developers. Finally, an open source tool is implemented to support the proposed approach.",
        "keywords": [
            "Couplings",
            "Clustering algorithms",
            "Software algorithms",
            "Measurement",
            "Software systems",
            "Partitioning algorithms"
        ]
    },
    {
        "title": "Choosing Component Origins for Software Intensive Systems: In-House, COTS, OSS or Outsourcing? - A Case Survey.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2677909",
        "volume": "44",
        "abstract": "The choice of which software component to use influences the success of a software system. Only a few empirical studies investigate how the choice of components is conducted in industrial practice. This is important to understand to tailor research solutions to the needs of the industry. Existing studies focus on the choice for off-the-shelf (OTS) components. It is, however, also important to understand the implications of the choice of alternative component sourcing options (CSOs), such as outsourcing versus the use of OTS. Previous research has shown that the choice has major implications on the development process as well as on the ability to evolve the system. The objective of this study is to explore how decision making took place in industry to choose among CSOs. Overall, 22 industrial cases have been studied through a case survey. The results show that the solutions specifically for CSO decisions are deterministic and based on optimization approaches. The non-deterministic solutions proposed for architectural group decision making appear to suit the CSO decision making in industry better. Interestingly, the final decision was perceived negatively in nine cases and positively in seven cases, while in the remaining cases it was perceived as neither positive nor negative.",
        "keywords": [
            "Decision making",
            "Outsourcing",
            "Companies",
            "Computer architecture",
            "Software",
            "Industries"
        ]
    },
    {
        "title": "Complete and Interpretable Conformance Checking of Business Processes.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2668418",
        "volume": "44",
        "abstract": "This article presents a method for checking the conformance between an event log capturing the actual execution of a business process, and a model capturing its expected or normative execution. Given a process model and an event log, the method returns a set of statements in natural language describing the behavior allowed by the model but not observed in the log and vice versa. The method relies on a unified representation of process models and event logs based on a well-known model of concurrency, namely event structures. Specifically, the problem of conformance checking is approached by converting the event log into an event structure, converting the process model into another event structure, and aligning the two event structures via an error-correcting synchronized product. Each difference detected in the synchronized product is then verbalized as a natural language statement. An empirical evaluation shows that the proposed method can handle real datasets and produces more concise and higher-level difference descriptions than state-of-the-art conformance checking methods. In a survey designed according to the technology acceptance model, practitioners showed a preference towards the proposed method with respect to a state-of-the-art baseline.",
        "keywords": [
            "Business",
            "Synchronization",
            "Computational modeling",
            "Data mining",
            "Natural languages",
            "Software systems",
            "Context modeling"
        ]
    },
    {
        "title": "Formulating Criticality-Based Cost-Effective Fault Tolerance Strategies for Multi-Tenant Service-Based Systems.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2681667",
        "volume": "44",
        "abstract": "The proliferation of cloud computing has fueled the rapid growth of multi-tenant service-based systems (SBSs), which serve multiple tenants simultaneously by composing existing services in the form of business processes. In a distributed and volatile operating environment, runtime anomalies may occur to the component services of an SBS and cause end-to-end quality violations. Engineering multi-tenant SBSs that can quickly handle runtime anomalies cost effectively has become a significant challenge. Different approaches have been proposed to formulate fault tolerance strategies for engineering SBSs. However, none of the existing approaches has sufficiently considered the service criticality based on multi-tenancy where multiple tenants share the same SBS instance with different multi-dimensional quality preferences. In this paper, we propose Criticality-based Fault Tolerance for Multi-Tenant SBSs (CFT4MTS), a novel approach that formulates cost-effective fault tolerance strategies for multi-tenant SBSs by providing redundancy for the critical component services. First, the criticality of each component service is evaluated based on its multi-dimensional quality and multiple tenants sharing the component service with differentiated quality preferences. Then, the fault tolerance problem is modelled as an Integer Programming problem to identify the optimal fault tolerance strategy. The experimental results show that, compared with three existing representative approaches, CFT4MTS can alleviate degradation in the quality of multi-tenant SBSs in a much more effective and efficient way.",
        "keywords": [
            "Fault tolerant systems",
            "Streaming media",
            "Runtime",
            "Redundancy",
            "Cloud computing",
            "Business"
        ]
    },
    {
        "title": "Detecting Trivial Mutant Equivalences via Compiler Optimisations.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2684805",
        "volume": "44",
        "abstract": "Mutation testing realises the idea of fault-based testing, i.e., using artificial defects to guide the testing process. It is used to evaluate the adequacy of test suites and to guide test case generation. It is a potentially powerful form of testing, but it is well-known that its effectiveness is inhibited by the presence of equivalent mutants. We recently studied Trivial Compiler Equivalence (TCE) as a simple, fast and readily applicable technique for identifying equivalent mutants for C programs. In the present work, we augment our findings with further results for the Java programming language. TCE can remove a large portion of all mutants because they are determined to be either equivalent or duplicates of other mutants. In particular, TCE equivalent mutants account for 7.4 and 5.7 percent of all C and Java mutants, while duplicated mutants account for a further 21 percent of all C mutants and 5.4 percent Java mutants, on average. With respect to a benchmark ground truth suite (of known equivalent mutants), approximately 30 percent (for C) and 54 percent (for Java) are TCE equivalent. It is unsurprising that results differ between languages, since mutation characteristics are language-dependent. In the case of Java, our new results suggest that TCE may be particularly effective, finding almost half of all equivalent mutants.",
        "keywords": [
            "Java",
            "Testing",
            "Optimization",
            "Syntactics",
            "Program processors",
            "Electronic mail"
        ]
    },
    {
        "title": "Hybrid Program Dependence Approximation for Effective Dynamic Impact Prediction.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2692783",
        "volume": "44",
        "abstract": "Impact analysis determines the effects that program entities of interest, or changes to them, may have on the rest of the program for software measurement, maintenance, and evolution tasks. Dynamic impact analysis could be one major approach to impact analysis that computes smaller impact setsthan static alternatives for concrete sets of executions. However, existing dynamic approaches often produce impact sets that are too large to be useful, hindering their adoption in practice. To address this problem, we propose to exploit static program dependencies to drastically prune false-positive impacts that are not exercised by the set of executions utilized by the analysis, via hybrid dependence approximation. Further, we present a novel dynamic impact analysis called Diver which leverages both the information provided by the dependence graph and method-execution events to identify runtimemethod-level dependencies, hence dynamic impact sets, much more precisely without reducing safety and at acceptable costs. We evaluate Diver on ten Java subjects of various sizes and application domains against both arbitrary queries covering entire programs and practical queries based on changes actually committed by developers to actively evolving software repositories. Our extensive empirical studies show that Diver can significantly improve the precision of impact prediction, with 100-186 percent increase, with respect to a representative existing alternative thus provide a far more effective option for dynamic impact prediction. Following a similar rationale to Diver, we further developed and evaluated an online dynamic impact analysis called DiverOnline which produces impact sets immediately upon the termination of program execution. Our results show that compared to the offline approach, for the same precision, the online approach can reduce the time by 50 percent on average for answering all possible queries in the given program at once albeit at the price of possibly significant increase in runtime overhead. For users interested in one specific query only, the online approach may compute the impact set for that query during runtime without much slowing down normal program operation. Further, the online analysis, which does not incur any space cost beyond the static-analysis phase, may be favored against the offline approach when trace storage and/or related file-system resource consumption becomes a serious challenge or even stopper for adopting dynamic impact prediction. Therefore, the online and offline analysis together offer complementary options to practitioners accommodating varied application/task scenarios and diverse budget constraints.",
        "keywords": [
            "Performance analysis",
            "Runtime",
            "Software",
            "Java",
            "Concrete",
            "Software measurement",
            "Maintenance engineering"
        ]
    },
    {
        "title": "Refactoring Inspection Support for Manual Refactoring Edits.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2679742",
        "volume": "44",
        "abstract": "Refactoring is commonly performed manually, supported by regression testing, which serves as a safety net to provide confidence on the edits performed. However, inadequate test suites may prevent developers from initiating or performing refactorings. We propose RefDistiller, a static analysis approach to support the inspection of manual refactorings. It combines two techniques. First, it applies predefined templates to identify potential missed edits during manual refactoring. Second, it leverages an automated refactoring engine to identify extra edits that might be incorrect. RefDistiller also helps determine the root cause of detected anomalies. In our evaluation, RefDistiller identifies 97 percent of seeded anomalies, of which 24 percent are not detected by generated test suites. Compared to running existing regression test suites, it detects 22 times more anomalies, with 94 percent precision on average. In a study with 15 professional developers, the participants inspected problematic refactorings with RefDistiller versus testing only. With RefDistiller, participants located 90 percent of the seeded anomalies, while they located only 13 percent with testing. The results show RefDistiller can help check the correctness of manual refactorings.",
        "keywords": [
            "Manuals",
            "Inspection",
            "Testing",
            "Computer bugs",
            "Transforms",
            "Engines",
            "Detectors"
        ]
    },
    {
        "title": "Understanding Diverse Usage Patterns from Large-Scale Appstore-Service Profiles.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2685387",
        "volume": "44",
        "abstract": "The prevalence of smart mobile devices has promoted the popularity of mobile applications (a.k.a. apps). Supporting mobility has become a promising trend in software engineering research. This article presents an empirical study of behavioral service profiles collected from millions of users whose devices are deployed with Wandoujia, a leading Android app-store service in China. The dataset of Wandoujia service profiles consists of two kinds of user behavioral data from using 0.28 million free Android apps, including (1) app management activities (i.e., downloading, updating, and uninstalling apps) from over 17 million unique users and (2) app network usage from over 6 million unique users. We explore multiple aspects of such behavioral data and present patterns of app usage. Based on the findings as well as derived knowledge, we also suggest some new open opportunities and challenges that can be explored by the research community, including app development, deployment, delivery, revenue, etc.",
        "keywords": [
            "Androids",
            "Humanoid robots",
            "Software",
            "Biological system modeling",
            "Mobile communication",
            "Electronic mail",
            "Software engineering"
        ]
    },
    {
        "title": "Are Fix-Inducing Changes a Moving Target? A Longitudinal Case Study of Just-In-Time Defect Prediction.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2693980",
        "volume": "44",
        "abstract": "Just-In-Time (JIT) models identify fix-inducing code changes. JIT models are trained using techniques that assume that past fix-inducing changes are similar to future ones. However, this assumption may not hold, e.g., as system complexity tends to accrue, expertise may become more important as systems age. In this paper, we study JIT models as systems evolve. Through a longitudinal case study of 37,524 changes from the rapidly evolving Qt and OpenStack systems, we find that fluctuations in the properties of fix-inducing changes can impact the performance and interpretation of JIT models. More specifically: (a) the discriminatory power (AUC) and calibration (Brier) scores of JIT models drop considerably one year after being trained; (b) the role that code change properties (e.g., Size, Experience) play within JIT models fluctuates over time; and (c) those fluctuations yield over- and underestimates of the future impact of code change properties on the likelihood of inducing fixes. To avoid erroneous or misleading predictions, JIT models should be retrained using recently recorded data (within three months). Moreover, quality improvement plans should be informed by JIT models that are trained using six months (or more) of historical data, since they are more resilient to period-specific fluctuations in the importance of code change properties.",
        "keywords": [
            "Predictive models",
            "Data models",
            "Software",
            "Complexity theory",
            "Market research",
            "Context modeling",
            "Calibration"
        ]
    },
    {
        "title": "Detecting Overly Strong Preconditions in Refactoring Engines.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2693982",
        "volume": "44",
        "abstract": "Refactoring engines may have overly strong preconditions preventing developers from applying useful transformations. We find that 32 percent of the Eclipse and JRRT test suites are concerned with detecting overly strong preconditions. In general, developers manually write test cases, which is costly and error prone. Our previous technique detects overly strong preconditions using differential testing. However, it needs at least two refactoring engines. In this work, we propose a technique to detect overly strong preconditions in refactoring engines without needing reference implementations. We automatically generate programs and attempt to refactor them. For each rejected transformation, we attempt to apply it again after disabling the preconditions that lead the refactoring engine to reject the transformation. If it applies a behavior preserving transformation, we consider the disabled preconditions overly strong. We evaluate 10 refactorings of Eclipse and JRRT by generating 154,040 programs. We find 15 overly strong preconditions in Eclipse and 15 in JRRT. Our technique detects 11 bugs that our previous technique cannot detect while missing 5 bugs. We evaluate the technique by replacing the programs generated by JDolly with the input programs of Eclipse and JRRT test suites. Our technique detects 14 overly strong preconditions in Eclipse and 4 in JRRT.",
        "keywords": [
            "Engines",
            "Computer bugs",
            "Databases",
            "Testing",
            "Java",
            "Electronic mail",
            "Usability"
        ]
    },
    {
        "title": "Discipline Matters: Refactoring of Preprocessor Directives in the #ifdef Hell.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2688333",
        "volume": "44",
        "abstract": "The C preprocessor is used in many C projects to support variability and portability. However, researchers and practitioners criticize the C preprocessor because of its negative effect on code understanding and maintainability and its error proneness. More importantly, the use of the preprocessor hinders the development of tool support that is standard in other languages, such as automated refactoring. Developers aggravate these problems when using the preprocessor in undisciplined ways (e.g., conditional blocks that do not align with the syntactic structure of the code). In this article, we proposed a catalogue of refactorings and we evaluated the number of application possibilities of the refactorings in practice, the opinion of developers about the usefulness of the refactorings, and whether the refactorings preserve behavior. Overall, we found 5,670 application possibilities for the refactorings in 63 real-world C projects. In addition, we performed an online survey among 246 developers, and we submitted 28 patches to convert undisciplined directives into disciplined ones. According to our results, 63 percent of developers prefer to use the refactored (i.e., disciplined) version of the code instead of the original code with undisciplined preprocessor usage. To verify that the refactorings are indeed behavior preserving, we applied them to more than 36 thousand programs generated automatically using a model of a subset of the C language, running the same test cases in the original and refactored programs. Furthermore, we applied the refactorings to three real-world projects: BusyBox, OpenSSL, and SQLite. This way, we detected and fixed a few behavioral changes, 62 percent caused by unspecified behavior in the C programming language.",
        "keywords": [
            "Syntactics",
            "C languages",
            "Guidelines",
            "Linux",
            "Kernel",
            "Standards"
        ]
    },
    {
        "title": "EnergyPatch: Repairing Resource Leaks to Improve Energy-Efficiency of Android Apps.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2689012",
        "volume": "44",
        "abstract": "Increased usage of mobile devices, such as smartphones and tablets, has led to widespread popularity and usage of mobile apps. If not carefully developed, such apps may demonstrate energy-inefficient behaviour, where one or more energy-intensive hardware components (such as Wifi, GPS, etc) are left in a high-power state, even when no apps are using these components. We refer to such kind of energy-inefficiencies as energy bugs. Executing an app with an energy bug causes the mobile device to exhibit poor energy consumption behaviour and a drastically shortened battery life. Since mobiles apps can have huge input domains, therefore exhaustive exploration is often impractical. We believe that there is a need for a framework that can systematically detect and fix energy bugs in mobile apps in a scalable fashion. To address this need, we have developed EnergyPatch, a framework that uses a combination of static and dynamic analysis techniques to detect, validate and repair energy bugs in Android apps. The use of a light-weight, static analysis technique enables EnergyPatch to quickly narrow down to the potential program paths along which energy bugs may occur. Subsequent exploration of these potentially buggy program paths using a dynamic analysis technique helps in validations of the reported bugs and to generate test cases. Finally, EnergyPatch generates repair expressions to fix the validated energy bugs. Evaluation with real-life apps from repositories such as F-droid and Github, shows that EnergyPatch is scalable and can produce results in reasonable amount of time. Additionally, we observed that the repair expressions generated by EnergyPatch could bring down the energy consumption on tested apps up to 60 percent.",
        "keywords": [
            "Computer bugs",
            "Androids",
            "Humanoid robots",
            "Maintenance engineering",
            "Mobile handsets",
            "Energy consumption",
            "Batteries"
        ]
    },
    {
        "title": "Reviving Sequential Program Birthmarking for Multithreaded Software Plagiarism Detection.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2688383",
        "volume": "44",
        "abstract": "As multithreaded programs become increasingly popular, plagiarism of multithreaded programs starts to plague the software industry. Although there has been tremendous progress on software plagiarism detection technology, existing dynamic birthmark approaches are applicable only to sequential programs, due to the fact that thread scheduling nondeterminism severely perturbs birthmark generation and comparison. We propose a framework called TOB (Thread-oblivious dynamic Birthmark) that revives existing techniques so they can be applied to detect plagiarism of multithreaded programs. This is achieved by thread-oblivious algorithms that shield the influence of thread schedules on executions. We have implemented a set of tools collectively called TOB-PD (TOB based Plagiarism Detection tool) by applying TOB to three existing representative dynamic birthmarks, including SCSSB (System Call Short Sequence Birthmark), DYKIS (DYnamic Key Instruction Sequence birthmark) and JB (an API based birthmark for Java). Our experiments conducted on large number of binary programs show that our approach exhibits strong resilience against state-of-the-art semantics-preserving code obfuscation techniques. Comparisons against the three existing tools SCSSB, DYKIS and JB show that the new framework is effective for plagiarism detection of multithreaded programs. The tools, the benchmarks and the experimental results are all publicly available.",
        "keywords": [
            "Plagiarism",
            "Instruction sets",
            "Computer science",
            "Dynamic scheduling",
            "Indexes",
            "Electronic mail"
        ]
    },
    {
        "title": "A PVS-Simulink Integrated Environment for Model-Based Analysis of Cyber-Physical Systems.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2694423",
        "volume": "44",
        "abstract": "This paper presents a methodology, with supporting tool, for formal modeling and analysis of software components in cyber-physical systems. Using our approach, developers can integrate a simulation of logic-based specifications of software components and Simulink models of continuous processes. The integrated simulation is useful to validate the characteristics of discrete system components early in the development process. The same logic-based specifications can also be formally verified using the Prototype Verification System (PVS), to gain additional confidence that the software design complies with specific safety requirements. Modeling patterns are defined for generating the logic-based specifications from the more familiar automata-based formalism. The ultimate aim of this work is to facilitate the introduction of formal verification technologies in the software development process of cyber-physical systems, which typically requires the integrated use of different formalisms and tools. A case study from the medical domain is used to illustrate the approach. A PVS model of a pacemaker is interfaced with a Simulink model of the human heart. The overall cyber-physical system is co-simulated to validate design requirements through exploration of relevant test scenarios. Formal verification with the PVS theorem prover is demonstrated for the pacemaker model for specific safety aspects of the pacemaker design.",
        "keywords": [
            "Software packages",
            "Automata",
            "Analytical models",
            "Cyber-physical systems",
            "Mathematical model",
            "Data models"
        ]
    },
    {
        "title": "MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2731766",
        "volume": "44",
        "abstract": "Highly imbalanced data typically make accurate predictions difficult. Unfortunately, software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches, they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study, we introduce MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant pf values than the other oversampling approaches, based on Brunner's statistical significance test and Cliff's effect sizes. Therefore, MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.",
        "keywords": [
            "Biological cells",
            "Software",
            "Predictive models",
            "Animals",
            "Electronic mail",
            "Sampling methods"
        ]
    },
    {
        "title": "Predicting Delivery Capability in Iterative Software Development.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2693989",
        "volume": "44",
        "abstract": "Iterative software development has become widely practiced in industry. Since modern software projects require fast, incremental delivery for every iteration of software development, it is essential to monitor the execution of an iteration, and foresee a capability to deliver quality products as the iteration progresses. This paper presents a novel, data-driven approach to providing automated support for project managers and other decision makers in predicting delivery capability for an ongoing iteration. Our approach leverages a history of project iterations and associated issues, and in particular, we extract characteristics of previous iterations and their issues in the form of features. In addition, our approach characterizes an iteration using a novel combination of techniques including feature aggregation statistics, automatic feature learning using the Bag-of-Words approach, and graph-based complexity measures. An extensive evaluation of the technique on five large open source projects demonstrates that our predictive models outperform three common baseline methods in Normalized Mean Absolute Error and are highly accurate in predicting the outcome of an ongoing iteration.",
        "keywords": [
            "Software",
            "Feature extraction",
            "Predictive models",
            "Data mining",
            "Complexity theory",
            "Iterative methods",
            "Agile software development"
        ]
    },
    {
        "title": "Specialising Software for Different Downstream Applications Using Genetic Improvement and Code Transplantation.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2702606",
        "volume": "44",
        "abstract": "Genetic improvement uses automated search to find improved versions of existing software. Genetic improvement has previously been concerned with improving a system with respect to all possible usage scenarios. In this paper, we show how genetic improvement can also be used to achieve specialisation to a specific set of usage scenarios. We use genetic improvement to evolve faster versions of a C++ program, a Boolean satisfiability solver called MiniSAT, specialising it for three different applications, each with their own characteristics. Our specialised solvers achieve between 4 and 36 percent execution time improvement, which is commensurate with efficiency gains achievable using human expert optimisation for the general solver. We also use genetic improvement to evolve faster versions of an image processing tool called ImageMagick, utilising code from GraphicsMagick, another image processing tool which was forked from it. We specialise the format conversion functionality to greyscale images and colour images only. Our specialised versions achieve up to 3 percent execution time improvement.",
        "keywords": [
            "Software",
            "Software engineering",
            "Image processing",
            "C++ languages",
            "Genetic programming",
            "Optimization"
        ]
    },
    {
        "title": "Towards Model Checking Android Applications.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2697848",
        "volume": "44",
        "abstract": "As feature-rich Android applications (apps for short) are increasingly popularized in security-sensitive scenarios, methods to verify their security properties are highly desirable. Existing approaches on verifying Android apps often have limited effectiveness. For instance, static analysis often suffers from a high false-positive rate, whereas approaches based on dynamic testing are limited in coverage. In this work, we propose an alternative approach, which is to apply the software model checking technique to verify Android apps. We have built a general framework named DroidPF upon Java PathFinder (JPF), towards model checking Android apps. In the framework, we craft an executable mock-up Android OS which enables JPF to dynamically explore the concrete state spaces of the tested apps; we construct programs to generate user interaction and environmental input so as to drive the dynamic execution of the apps; and we introduce Android specific reduction techniques to help alleviate the state space explosion. DroidPF focuses on common security vulnerabilities in Android apps including sensitive data leakage involving a non-trivial flow- and context-sensitive taint-style analysis. DroidPF has been evaluated with 131 apps, which include real-world apps, third-party libraries, malware samples and benchmarks for evaluating app analysis techniques like ours. DroidPF precisely identifies nearly all of the previously known security issues and nine previously unreported vulnerabilities/bugs.",
        "keywords": [
            "Androids",
            "Humanoid robots",
            "Model checking",
            "Java",
            "Security",
            "Software",
            "Libraries"
        ]
    },
    {
        "title": "Effectively Incorporating Expert Knowledge in Automated Software Remodularisation.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2786222",
        "volume": "44",
        "abstract": "Remodularising the components of a software system is challenging: sound design principles (e.g., coupling and cohesion) need to be balanced against developer intuition of which entities conceptually belong together. Despite this, automated approaches to remodularisation tend to ignore domain knowledge, leading to results that can be nonsensical to developers. Nevertheless, suppling such knowledge is a potentially burdensome task to perform manually. A lot information may need to be specified, particularly for large systems. Addressing these concerns, we propose the SUpervised reMOdularisation (SUMO) approach. SUMO is a technique that aims to leverage a small subset of domain knowledge about a system to produce a remodularisation that will be acceptable to a developer. With SUMO, developers refine a modularisation by iteratively supplying corrections. These corrections constrain the type of remodularisation eventually required, enabling SUMO to dramatically reduce the solution space. This in turn reduces the amount of feedback the developer needs to supply. We perform a comprehensive systematic evaluation using 100 real world subject systems. Our results show that SUMO guarantees convergence on a target remodularisation with a tractable amount of user interaction.",
        "keywords": [
            "Clustering algorithms",
            "Tools",
            "Software algorithms",
            "Software systems",
            "Algorithm design and analysis"
        ]
    },
    {
        "title": "Implementing and Evaluating Candidate-Based Invariant Generation.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2718516",
        "volume": "44",
        "abstract": "The discovery of inductive invariants lies at the heart of static program verification. Presently, many automatic solutions to inductive invariant generation are inflexible, only applicable to certain classes of programs, or unpredictable. An automatic technique that circumvents these deficiencies to some extent is candidate-based invariant generation, whereby a large number of candidate invariants are guessed and then proven to be inductive or rejected using a sound program analyzer. This paper describes our efforts to apply candidate-based invariant generation in GPUVerify, a static checker for programs that run on GPUs. We study a set of 383 GPU programs that contain loops, drawn from a number of open source suites and vendor SDKs. Among this set, 253 benchmarks require provision of loop invariants for verification to succeed. We describe the methodology we used to incrementally improve the invariant generation capabilities of GPUVerify to handle these benchmarks, through candidate-based invariant generation, using cheap static analysis to speculate potential program invariants. We also describe a set of experiments that we used to examine the effectiveness of our rules for candidate generation, assessing rules based on their generality (the extent to which they generate candidate invariants), hit rate (the extent to which the generated candidates hold), worth (the extent to which provable candidates actually help in allowing verification to succeed), and influence (the extent to which the success of one generation rule depends on candidates generated by another rule). We believe that our methodology may serve as a useful framework for other researchers interested in candidate-based invariant generation. The candidates produced by GPUVerify help to verify 231 of the 253 programs. This increase in precision, however, makes GPUVerify sluggish: the more candidates that are generated, the more time is spent determining which are inductive invariants. To speed up this process, we have investigated four under-approximating program analyses that aim to reject false candidates quickly and a framework whereby these analyses can run in sequence or in parallel. Across two platforms, running Windows and Linux, our results show that the best combination of these techniques running sequentially-speeds up invariant generation across our benchmarks by 1.17× (Windows) and 1.01× (Linux), with per-benchmark best speedups of 93.58× (Windows) and 48.34× (Linux), and worst slowdowns of 10.24× (Windows) and 43.31× (Linux). We find that parallelizing the strategies marginally improves overall invariant generation speedups to 1.27× (Windows) and 1.11× (Linux), maintains good best-case speedups of 91.18× (Windows) and 44.60× (Linux), and, importantly, dramatically reduces worst-case slowdowns to 3.15× (Windows) and 3.17× (Linux).",
        "keywords": [
            "Linux",
            "Graphics processing units",
            "Benchmark testing",
            "Tools",
            "Cognition",
            "Acceleration"
        ]
    },
    {
        "title": "Mining Semantic Loop Idioms.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2832048",
        "volume": "44",
        "abstract": "To write code, developers stitch together patterns, like API protocols or data structure traversals. Discovering these patterns can identify inconsistencies in code or opportunities to replace these patterns with an API or a language construct. We present coiling, a technique for automatically mining code for semantic idioms: surprisingly probable, semantic patterns. We specialize coiling for loop idioms, semantic idioms of loops. First, we show that automatically identifiable patterns exist, in great numbers, with a largescale empirical study of loops over 25MLOC. We find that most loops in this corpus are simple and predictable: 90 percent have fewer than 15LOC and 90 percent have no nesting and very simple control. Encouraged by this result, we then mine loop idioms over a second, buildable corpus. Over this corpus, we show that only 50 loop idioms cover 50 percent of the concrete loops. Our framework opens the door to data-driven tool and language design, discovering opportunities to introduce new API calls and language constructs. Loop idioms show that LINQ would benefit from an Enumerate operator. This can be confirmed by the exitence of a StackOverflow question with 542k views that requests precisely this feature.",
        "keywords": [
            "Semantics",
            "Tools",
            "Syntactics",
            "Data mining",
            "C# languages",
            "Machine learning",
            "Testing"
        ]
    },
    {
        "title": "On Accelerating Source Code Analysis at Massive Scale.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2828848",
        "volume": "44",
        "abstract": "Encouraged by the success of data-driven software engineering (SE) techniques that have found numerous applications e.g., in defect prediction, specification inference, the demand for mining and analyzing source code repositories at scale has significantly increased. However, analyzing source code at scale remains expensive to the extent that data-driven solutions to certain SE problems are beyond our reach today. Extant techniques have focused on leveraging distributed computing to solve this problem, but with a concomitant increase in computational resource needs. This work proposes a technique that reduces the amount of computation performed by the ultra-large-scale source code mining task, especially those that make use of control and data flow analyses. Our key idea is to analyze the mining task to identify and remove the irrelevant portions of the source code, prior to running the mining task. We show a realization of our insight for mining and analyzing massive collections of control flow graphs of source codes. Our evaluation using 16 classical control-/data-flow analyses that are typical components of mining tasks and 7 Million CFGs shows that our technique can achieve on average a 40 percent reduction in the task computation time. Our case studies demonstrates the applicability of our technique to massive scale source code mining tasks.",
        "keywords": [
            "Task analysis",
            "Data mining",
            "Acceleration",
            "Static analysis",
            "Software engineering",
            "Distributed computing",
            "Software"
        ]
    },
    {
        "title": "On the Semantics of Distributed Reactive Programming: The Cost of Consistency.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2833109",
        "volume": "44",
        "abstract": "The reactive programming paradigm aims to simplify the development of reactive systems. It provides abstractions to define time-changing values that are automatically updated by the runtime according to their dependencies. The benefits of reactive programming in distributed settings have been recognized for long. Yet, existing solutions for distributed reactive programming enforce the same semantics as in single processes, introducing communication and synchronization costs that hamper scalability. Establishing suitable abstractions for distributed reactive programming demands for a deeper investigation of the semantics of change propagation. This paper takes a foundational approach and defines precise propagation semantics in terms of consistency guarantees that constrain the order and isolation of value updates. We study the benefits and costs of these consistency guarantees both theoretically and empirically, using case studies and synthetic benchmarks. We show that different applications require different levels of consistency and that manually implementing the required level on a middleware that provides a lower one annuls the abstraction improvements of reactive programming. This motivates a framework that enables the developers to select the best trade-off between consistency and overhead for the problem at hand. To this end, we present DREAM, a distributed reactive programming middleware with flexible consistency guarantees.",
        "keywords": [
            "Programming",
            "Semantics",
            "Artificial intelligence",
            "Runtime",
            "Middleware",
            "Games",
            "Computational modeling"
        ]
    },
    {
        "title": "A Comparison of Program Comprehension Strategies by Blind and Sighted Programmers.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2729548",
        "volume": "44",
        "abstract": "Programmers who are blind use a screen reader to speak source code one word at a time, as though the code were text. This process of reading is in stark contrast to sighted programmers, who skim source code rapidly with their eyes. At present, it is not known whether the difference in these processes has effects on the program comprehension gained from reading code. These effects are important because they could reduce both the usefulness of accessibility tools and the generalizability of software engineering studies to persons with low vision. In this paper, we present an empirical study comparing the program comprehension of blind and sighted programmers. We found that both blind and sighted programmers prioritize reading method signatures over other areas of code. Both groups obtained an equal and high degree of comprehension, despite the different reading processes.",
        "keywords": [
            "Tools",
            "Software",
            "Blindness",
            "Navigation",
            "Programming profession",
            "Software engineering"
        ]
    },
    {
        "title": "A Formal Specification and Verification Framework for Timed Security Protocols.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2712621",
        "volume": "44",
        "abstract": "Nowadays, protocols often use time to provide better security. For instance, critical credentials are often associated with expiry dates in system designs. However, using time correctly in protocol design is challenging, due to the lack of time related formal specification and verification techniques. Thus, we propose a comprehensive analysis framework to formally specify as well as automatically verify timed security protocols. A parameterized method is introduced in our framework to handle timing parameters whose values cannot be decided in the protocol design stage. In this work, we first propose timed applied p-calculus as a formal language for specifying timed security protocols. It supports modeling of continuous time as well as application of cryptographic functions. Then, we define its formal semantics based on timed logic rules, which facilitates efficient verification against various authentication and secrecy properties. Given a parameterized security protocol, our method either produces a constraint on the timing parameters which guarantees the security property satisfied by the protocol, or reports an attack that works for any parameter value. The correctness of our verification algorithm has been formally proved. We evaluate our framework with multiple timed and untimed security protocols and successfully find a previously unknown timing attack in Kerberos V.",
        "keywords": [
            "Cryptographic protocols",
            "Formal specifications",
            "Authentication",
            "Formal verification"
        ]
    },
    {
        "title": "A Survey of Recent Trends in Testing Concurrent Software Systems.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2707089",
        "volume": "44",
        "abstract": "Many modern software systems are composed of multiple execution flows that run simultaneously, spanning from applications designed to exploit the power of modern multi-core architectures to distributed systems consisting of multiple components deployed on different physical nodes. We collectively refer to such systems as concurrent systems. Concurrent systems are difficult to test, since the faults that derive from their concurrent nature depend on the interleavings of the actions performed by the individual execution flows. Testing techniques that target these faults must take into account the concurrency aspects of the systems. The increasingly rapid spread of parallel and distributed architectures led to a deluge of concurrent software systems, and the explosion of testing techniques for such systems in the last decade. The current lack of a comprehensive classification, analysis and comparison of the many testing techniques for concurrent systems limits the understanding of the strengths and weaknesses of each approach and hampers the future advancements in the field. This survey provides a framework to capture the key features of the available techniques to test concurrent software systems, identifies a set of classification criteria to review and compare the available techniques, and discusses in details their strengths and weaknesses, leading to a thorough assessment of the field and paving the road for future progresses.",
        "keywords": [
            "Testing",
            "Software systems",
            "Message passing",
            "History",
            "Concurrent computing",
            "Computer architecture",
            "Synchronization"
        ]
    },
    {
        "title": "Control-Theoretical Software Adaptation: A Systematic Literature Review.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2704579",
        "volume": "44",
        "abstract": "Modern software applications are subject to uncertain operating conditions, such as dynamics in the availability of services and variations of system goals. Consequently, runtime changes cannot be ignored, but often cannot be predicted at design time. Control theory has been identified as a principled way of addressing runtime changes and it has been applied successfully to modify the structure and behavior of software applications. Most of the times, however, the adaptation targeted the resources that the software has available for execution (CPU, storage, etc.) more than the software application itself. This paper investigates the research efforts that have been conducted to make software adaptable by modifying the software rather than the resource allocated to its execution. This paper aims to identify: the focus of research on control-theoretical software adaptation; how software is modeled and what control mechanisms are used to adapt software; what software qualities and controller guarantees are considered. To that end, we performed a systematic literature review in which we extracted data from 42 primary studies selected from 1,512 papers that resulted from an automatic search. The results of our investigation show that even though the behavior of software is considered non-linear, research efforts use linear models to represent it, with some success. Also, the control strategies that are most often considered are classic control, mostly in the form of Proportional and Integral controllers, and Model Predictive Control. The paper also discusses sensing and actuating strategies that are prominent for software adaptation and the (often neglected) proof of formal properties. Finally, we distill open challenges for control-theoretical software adaptation.",
        "keywords": [
            "Software",
            "Control theory",
            "Adaptation models",
            "Runtime",
            "Bibliographies",
            "Mathematical model",
            "Knowledge based systems"
        ]
    },
    {
        "title": "A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2724538",
        "volume": "44",
        "abstract": "Cross-Project Defect Prediction (CPDP) as a means to focus quality assurance of software projects was under heavy investigation in recent years. However, within the current state-of-the-art it is unclear which of the many proposals performs best due to a lack of replication of results and diverse experiment setups that utilize different performance metrics and are based on different underlying data. Within this article, we provide a benchmark for CPDP. We replicate 24 approaches proposed by researchers between 2008 and 2015 and evaluate their performance on software products from five different data sets. Based on our benchmark, we determined that an approach proposed by Camargo Cruz and Ochimizu (2009) based on data standardization performs best and is always ranked among the statistically significant best results for all metrics and data sets. Approaches proposed by Turhan et al. (2009), Menzies et al. (2011), and Watanabe et al. (2008) are also nearly always among the best results. Moreover, we determined that predictions only seldom achieve a high performance of 0.75 recall, precision, and accuracy. Thus, CPDP still has not reached a point where the performance of the results is sufficient for the application in practice.",
        "keywords": [
            "Benchmark testing",
            "Prediction methods",
            "Software",
            "Quality assurance",
            "Measurement",
            "Correlation"
        ]
    },
    {
        "title": "Enhancing the Description-to-Behavior Fidelity in Android Apps with Privacy Policy.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2730198",
        "volume": "44",
        "abstract": "Since more than 96 percent of mobile malware targets the Android platform, various techniques based on static code analysis or dynamic behavior analysis have been proposed to detect malicious apps. As malware is becoming more complicated and stealthy, recent research proposed a promising detection approach that looks for the inconsistency between an app's permissions and its description. In this paper, we first revisit this approach and reveal that using description and permission will lead to many false positives because descriptions often fail to declare all sensitive operations. Then, we propose exploiting an app's privacy policy and its bytecode to enhance the malware detection based on description and permissions. It is non-trivial to automatically analyze privacy policy and perform the cross-verification among these four kinds of software artifacts including, privacy policy, bytecode, description, and permissions. To address these challenging issues, we first propose a novel data flow model for analyzing privacy policy, and then develop a new system, named TAPVerifier, for carrying out investigation of individual software artifacts and conducting the cross-verification. The experimental results show that TAPVerifier can analyze privacy policy with a high accuracy and recall rate. More importantly, integrating privacy policy and bytecode level information can remove up to 59.4 percent false alerts of the state-of-the-art systems, such as AutoCog, CHABADA, etc.",
        "keywords": [
            "Privacy",
            "Data privacy",
            "Semantics",
            "Malware",
            "Permission",
            "Google",
            "Androids"
        ]
    },
    {
        "title": "Global-Aware Recommendations for Repairing Violations in Exception Handling.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2716925",
        "volume": "44",
        "abstract": "Empirical evidence suggests exception handling is not reliably implemented. Most faults in exception handling are related to global exceptions violating the intended exception handling design. However, repairing these violations is a cumbersome and error-prone task. It requires knowing the intended design and understanding how the source code violates it. It also requires changing the source code to make it compliant with the intended design. But changing the exception handling code is a difficult task, since changes in exception handling requires changing different parts of a program. Currently, there is still no solution to assist the repair of this type of violations. To bridge this gap, we present RAVEN, a heuristic strategy aware of the global context of exceptions that produces recommendations of how violations in exception handling may be repaired. This strategy takes advantage of explicit specifications of the intended design, although their availability is not mandatory. Our results revealed RAVEN provides recommendations able to repair violations in 69 percent of the cases when policy specifications are not available and in 97 percent of the cases when specifications are available. Thus, development teams may benefit from RAVEN, even when exception handling design decisions are not documented in their projects.",
        "keywords": [
            "Source coding",
            "Robustness",
            "Runtime",
            "Software development management",
            "Software reliability"
        ]
    },
    {
        "title": "Heterogeneous Defect Prediction.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2720603",
        "volume": "44",
        "abstract": "Many recent studies have documented the success of cross-project defect prediction (CPDP) to predict defects for new projects lacking in defect data by using prediction models built by other projects. However, most studies share the same limitations: it requires homogeneous data; i.e., different projects must describe themselves using the same metrics. This paper presents methods for heterogeneous defect prediction (HDP) that matches up different metrics in different projects. Metric matching for HDP requires a “large enough” sample of distributions in the source and target projects-which raises the question on how large is “large enough” for effective heterogeneous defect prediction. This paper shows that empirically and theoretically, “large enough” may be very small indeed. For example, using a mathematical model of defect prediction, we identify categories of data sets were as few as 50 instances are enough to build a defect prediction model. Our conclusion for this work is that, even when projects use different metric sets, it is possible to quickly transfer lessons learned about defect prediction.",
        "keywords": [
            "Predictive models",
            "Software metrics",
            "Quality assurance",
            "Training"
        ]
    },
    {
        "title": "Towards Prioritizing Documentation Effort.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2716950",
        "volume": "44",
        "abstract": "Programmers need documentation to comprehend software, but they often lack the time to write it. Thus, programmers must prioritize their documentation effort to ensure that sections of code important to program comprehension are thoroughly explained. In this paper, we explore the possibility of automatically prioritizing documentation effort. We performed two user studies to evaluate the effectiveness of static source code attributes and textual analysis of source code towards prioritizing documentation effort. The first study used open-source API Libraries while the second study was conducted using closed-source industrial software from ABB. Our findings suggest that static source code attributes are poor predictors of documentation effort priority, whereas textual analysis of source code consistently performed well as a predictor of documentation effort priority.",
        "keywords": [
            "Documentation",
            "Libraries",
            "Java",
            "Gold",
            "Programming",
            "Software",
            "Neural networks"
        ]
    },
    {
        "title": "A Theoretical and Empirical Study of Diversity-Aware Mutation Adequacy Criterion.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2732347",
        "volume": "44",
        "abstract": "Diversity has been widely studied in software testing as a guidance towards effective sampling of test inputs in the vast space of possible program behaviors. However, diversity has received relatively little attention in mutation testing. The traditional mutation adequacy criterion is a one-dimensional measure of the total number of killed mutants. We propose a novel, diversity-aware mutation adequacy criterion called distinguishing mutation adequacy criterion, which is fully satisfied when each of the considered mutants can be identified by the set of tests that kill it, thereby encouraging inclusion of more diverse range of tests. This paper presents the formal definition of the distinguishing mutation adequacy and its score. Subsequently, an empirical study investigates the relationship among distinguishing mutation score, fault detection capability, and test suite size. The results show that the distinguishing mutation adequacy criterion detects 1.33 times more unseen faults than the traditional mutation adequacy criterion, at the cost of a 1.56 times increase in test suite size, for adequate test suites that fully satisfies the criteria. The results show a better picture for inadequate test suites; on average, 8.63 times more unseen faults are detected at the cost of a 3.14 times increase in test suite size.",
        "keywords": [
            "Fault detection",
            "Software engineering",
            "Software testing",
            "Correlation",
            "Indexes",
            "Subspace constraints"
        ]
    },
    {
        "title": "Coordination Challenges in Large-Scale Software Development: A Case Study of Planning Misalignment in Hybrid Settings.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2730870",
        "volume": "44",
        "abstract": "Achieving effective inter-team coordination is one of the most pressing challenges in large-scale software development. Hybrid approaches of traditional and agile development promise combining the overview and predictability of long-term planning on an inter-team level with the flexibility and adaptability of agile development on a team level. It is currently unclear, however, why such hybrids often fail. Our case study within a large software development unit of 13 teams at a global enterprise software company explores how and why a combination of traditional planning on an inter-team level and agile development on a team level can result in ineffective coordination. Based on a variety of data, including interviews with scrum masters, product owners, architects and senior management, and using Grounded Theory data analysis procedures, we identify a lack of dependency awareness across development teams as a key explanation of ineffective coordination. Our findings show how a lack of dependency awareness emerges from misaligned planning activities of specification, prioritization, estimation and allocation between agile team and traditional inter-team levels and ultimately prevents effective coordination. Knowing about these issues, large-scale hybrid projects in similar contexts can try to better align their planning activities across levels to improve dependency awareness and in turn achieve more effective coordination.",
        "keywords": [
            "Software",
            "Planning",
            "Agile software development",
            "Companies",
            "Task analysis",
            "Interviews"
        ]
    },
    {
        "title": "Measuring Program Comprehension: A Large-Scale Field Study with Professionals.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2734091",
        "volume": "44",
        "abstract": "During software development and maintenance, developers spend a considerable amount of time on program comprehension activities. Previous studies show that program comprehension takes up as much as half of a developer's time. However, most of these studies are performed in a controlled setting, or with a small number of participants, and investigate the program comprehension activities only within the IDEs. However, developers' program comprehension activities go well beyond their IDE interactions. In this paper, we extend our ActivitySpace framework to collect and analyze Human-Computer Interaction (HCI) data across many applications (not just the IDEs). We follow Minelli et al.'s approach to assign developers' activities into four categories: navigation, editing, comprehension, and other. We then measure the comprehension time by calculating the time that developers spend on program comprehension, e.g., inspecting console and breakpoints in IDE, or reading and understanding tutorials in web browsers. Using this approach, we can perform a more realistic investigation of program comprehension activities, through a field study of program comprehension in practice across a total of seven real projects, on 78 professional developers, and amounting to 3,148 working hours. Our study leverages interaction data that is collected across many applications by the developers. Our study finds that on average developers spend ~58 percent of their time on program comprehension activities, and that they frequently use web browsers and document editors to perform program comprehension activities. We also investigate the impact of programming language, developers' experience, and project phase on the time that is spent on program comprehension, and we find senior developers spend significantly less percentages of time on program comprehension than junior developers. Our study also highlights the importance of several research directions needed to reduce program comprehension time, e.g., building automatic detection and improvement of low quality code and documentation, construction of software-engineering-specific search engines, designing better IDEs that help developers navigate code and browse information more efficiently, etc.",
        "keywords": [
            "Navigation",
            "Software",
            "Time measurement",
            "Browsers",
            "Maintenance engineering",
            "Programming",
            "Debugging"
        ]
    },
    {
        "title": "Two-Phase Assessment Approach to Improve the Efficiency of Refactoring Identification.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2731853",
        "volume": "44",
        "abstract": "To automate the refactoring identification process, a large number of candidates need to be compared. Such an overhead can make the refactoring approach impractical if the software size is large and the computational load of a fitness function is substantial. In this paper, we propose a two-phase assessment approach to improving the efficiency of the process. For each iteration of the refactoring process, refactoring candidates are preliminarily assessed using a lightweight, fast delta assessment method called the Delta Table. Using multiple Delta Tables, candidates to be evaluated with a fitness function are selected. A refactoring can be selected either interactively by the developer or automatically by choosing the best refactoring, and the refactorings are applied one after another in a stepwise fashion. The Delta Table is the key concept enabling a two-phase assessment approach because of its ability to quickly calculate the varying amounts of maintainability provided by each refactoring candidate. Our approach has been evaluated for three large-scale open-source projects. The results convincingly show that the proposed approach is efficient because it saves a considerable time while still achieving the same amount of fitness improvement as the approach examining all possible candidates.",
        "keywords": [
            "Measurement",
            "Couplings",
            "Symmetric matrices",
            "Open source software",
            "Computational efficiency",
            "System analysis and design"
        ]
    },
    {
        "title": "The Scent of a Smell: An Extensive Comparison Between Textual and Structural Smells.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2752171",
        "volume": "44",
        "abstract": "Code smells are symptoms of poor design or implementation choices that have a negative effect on several aspects of software maintenance and evolution, such as program comprehension or change- and fault-proneness. This is why researchers have spent a lot of effort on devising methods that help developers to automatically detect them in source code. Almost all the techniques presented in literature are based on the analysis of structural properties extracted from source code, although alternative sources of information (e.g., textual analysis) for code smell detection have also been recently investigated. Nevertheless, some studies have indicated that code smells detected by existing tools based on the analysis of structural properties are generally ignored (and thus not refactored) by the developers. In this paper, we aim at understanding whether code smells detected using textual analysis are perceived and refactored by developers in the same or different way than code smells detected through structural analysis. To this aim, we set up two different experiments. We have first carried out a software repository mining study to analyze how developers act on textually or structurally detected code smells. Subsequently, we have conducted a user study with industrial developers and quality experts in order to qualitatively analyze how they perceive code smells identified using the two different sources of information. Results indicate that textually detected code smells are easier to identify and for this reason they are considered easier to refactor with respect to code smells detected using structural properties. On the other hand, the latter are often perceived as more severe, but more difficult to exactly identify and remove.",
        "keywords": [
            "Tools",
            "Data mining",
            "Software systems",
            "Detectors",
            "Maintenance engineering",
            "Large scale integration"
        ]
    },
    {
        "title": "Data Scientists in Software Teams: State of the Art and Challenges.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2754374",
        "volume": "44",
        "abstract": "The demand for analyzing large scale telemetry, machine, and quality data is rapidly increasing in software industry. Data scientists are becoming popular within software teams, e.g., Facebook, LinkedIn and Microsoft are creating a new career path for data scientists. In this paper, we present a large-scale survey with 793 professional data scientists at Microsoft to understand their educational background, problem topics that they work on, tool usages, and activities. We cluster these data scientists based on the time spent for various activities and identify 9 distinct clusters of data scientists, and their corresponding characteristics. We also discuss the challenges that they face and the best practices they share with other data scientists. Our study finds several trends about data scientists in the software engineering context at Microsoft, and should inform managers on how to leverage data science capability effectively within their teams.",
        "keywords": [
            "Data science",
            "Tools",
            "Sociology",
            "Statistics",
            "Software",
            "Best practices",
            "Interviews"
        ]
    },
    {
        "title": "Engineering Trustworthy Self-Adaptive Software with Dynamic Assurance Cases.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2738640",
        "volume": "44",
        "abstract": "Building on concepts drawn from control theory, self-adaptive software handles environmental and internal uncertainties by dynamically adjusting its architecture and parameters in response to events such as workload changes and component failures. Self-adaptive software is increasingly expected to meet strict functional and non-functional requirements in applications from areas as diverse as manufacturing, healthcare and finance. To address this need, we introduce a methodology for the systematic ENgineering of TRUstworthy Self-adaptive sofTware (ENTRUST). ENTRUST uses a combination of (1) design-time and runtime modelling and verification, and (2) industry-adopted assurance processes to develop trustworthy self-adaptive software and assurance cases arguing the suitability of the software for its intended application. To evaluate the effectiveness of our methodology, we present a tool-supported instance of ENTRUST and its use to develop proof-of-concept self-adaptive software for embedded and service-based systems from the oceanic monitoring and e-finance domains, respectively. The experimental results show that ENTRUST can be used to engineer self-adaptive software systems in different application domains and to generate dynamic assurance cases for these systems.",
        "keywords": [
            "Software systems",
            "Control systems",
            "Runtime",
            "Monitoring",
            "Computer architecture",
            "Adaptive systems"
        ]
    },
    {
        "title": "Expanding Queries for Code Search Using Semantically Related API Class-names.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2750682",
        "volume": "44",
        "abstract": "When encountering unfamiliar programming tasks (e.g., connecting to a database), there is a need to seek potential working code examples. Instead of using code search engines, software developers usually post related programming questions on online Q&A forums (e.g., Stack Overflow). One possible reason is that existing code search engines would return effective code examples only if a query contains identifiers (e.g., class or method names). In other words, existing code search engines do not handle natural-language queries well (e.g., a description of a programming task). However, developers may not know the appropriate identifiers at the time of the search. As the demand of searching code examples is increasing, it is of significant interest to enhance code search engines. We conjecture that expanding natural-language queries with their semantically related identifiers has a great potential to enhance code search engines. In this paper, we propose an automated approach to find identifiers (in particular API class-names) that are semantically related to a given natural-language query. We evaluate the effectiveness of our approach using 74 queries on a corpus of 23,677,216 code snippets that are extracted from 24,666 open source Java projects. The results show that our approach can effectively recommend semantically related API class-names to expand the original natural-language queries. For instance, our approach successfully retrieves relevant code examples in the top 10 retrieved results for 76 percent of 74 queries, while it is 36 percent when using the original natural-language query; and the median rank of the first relevant code example is increased from 22 to 7.",
        "keywords": [
            "Search engines",
            "Programming",
            "Java",
            "Software engineering",
            "IEEE transactions",
            "Software",
            "Joining processes"
        ]
    },
    {
        "title": "Metamorphic Testing of RESTful Web APIs.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2764464",
        "volume": "44",
        "abstract": "Web Application Programming Interfaces (APIs) allow systems to interact with each other over the network. Modern Web APIs often adhere to the REST architectural style, being referred to as RESTful Web APIs. RESTful Web APIs are decomposed into multiple resources (e.g., a video in the YouTube API) that clients can manipulate through HTTP interactions. Testing Web APIs is critical but challenging due to the difficulty to assess the correctness of API responses, i.e., the oracle problem. Metamorphic testing alleviates the oracle problem by exploiting relations (so-called metamorphic relations) among multiple executions of the program under test. In this paper, we present a metamorphic testing approach for the detection of faults in RESTful Web APIs. We first propose six abstract relations that capture the shape of many of the metamorphic relations found in RESTful Web APIs, we call these Metamorphic Relation Output Patterns (MROPs). Each MROP can then be instantiated into one or more concrete metamorphic relations. The approach was evaluated using both automatically seeded and real faults in six subject Web APIs. Among other results, we identified 60 metamorphic relations (instances of the proposed MROPs) in the Web APIs of Spotify and YouTube. Each metamorphic relation was implemented using both random and manual test data, running over 4.7K automated tests. As a result, 11 issues were detected (3 in Spotify and 8 in YouTube), 10 of them confirmed by the API developers or reproduced by other users, supporting the effectiveness of the approach.",
        "keywords": [
            "Testing",
            "YouTube",
            "Web services",
            "Companies",
            "Standards",
            "Manuals",
            "Indexes"
        ]
    },
    {
        "title": "Predicting Future Developer Behavior in the IDE Using Topic Models.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2748134",
        "volume": "44",
        "abstract": "While early software command recommender systems drew negative user reaction, recent studies show that users of unusually complex applications will accept and utilize command recommendations. Given this new interest, more than a decade after first attempts, both the recommendation generation (backend) and the user experience (frontend) should be revisited. In this work, we focus on recommendation generation. One shortcoming of existing command recommenders is that algorithms focus primarily on mirroring the short-term past,-i.e., assuming that a developer who is currently debugging will continue to debug endlessly. We propose an approach to improve on the state of the art by modeling future task context to make better recommendations to developers. That is, the approach can predict that a developer who is currently debugging may continue to debug OR may edit their program. To predict future development commands, we applied Temporal Latent Dirichlet Allocation, a topic model used primarily for natural language, to software development interaction data (i.e., command streams). We evaluated this approach on two large interaction datasets for two different IDEs, Microsoft Visual Studio and ABB Robot Studio. Our evaluation shows that this is a promising approach for both predicting future IDE commands and producing empirically-interpretable observations.",
        "keywords": [
            "Natural languages",
            "Data models",
            "Analytical models",
            "Predictive models",
            "Visualization",
            "Adaptation models",
            "Data analysis"
        ]
    },
    {
        "title": "Using Local Clocks to Reproduce Concurrency Bugs.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2752158",
        "volume": "44",
        "abstract": "Multi-threaded programs play an increasingly important role in current multi-core environments. Exposing concurrency bugs and debugging such multi-threaded programs are quite challenging due to their inherent non-determinism. In order to mitigate such non-determinism, many approaches such as record-and-replay have been proposed. However, those approaches often suffer significant performance degradation because they require a large amount of recorded information and/or long analysis and replay time. In this paper, we propose an efficient and effective approach, ReCBuLC (reproducing concurrency bugs using local clocks), to take advantage of the hardware clocks available on modern processors. The key idea is to reduce the recording overhead and the time to analyze events’ global order by recording timestamps in each thread. These timestamps are used to determine the global order of shared accesses. To avoid the large overhead in accessing system-wide global clock, we opt to use local per-core clocks that incur much less access overhead. We then propose techniques to resolve skews among local clocks and obtain an accurate global event order. By using per-core clocks, state-of-the-art bug reproducing systems such as PRES and CLAP can reduce their recording overheads by up to 85 percent, and the analysis time up to 84.66%\n<inline-formula> <tex-math notation=\"LaTeX\">$\\sim$</tex-math></inline-formula>\n99.99%, respectively.",
        "keywords": [
            "Clocks",
            "Program processors",
            "Computer bugs",
            "Concurrent computing",
            "Hardware",
            "Debugging",
            "Computer architecture"
        ]
    },
    {
        "title": "Authors' Reply to \"Comments on 'Researcher Bias: The Use of Machine Learning in Software Defect Prediction'\".",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2731308",
        "volume": "44",
        "abstract": "In 2014 we published a meta-analysis of software defect prediction studies [1] . This suggested that the most important factor in determining results was Research Group, i.e., who conducts the experiment is more important than the classifier algorithms being investigated. A recent re-analysis [2] sought to argue that the effect is less strong than originally claimed since there is a relationship between Research Group and Dataset. In this response we show (i) the re-analysis is based on a small (21 percent) subset of our original data, (ii) using the same re-analysis approach with a larger subset shows that Research Group is more important than type of Classifier and (iii) however the data are analysed there is compelling evidence that who conducts the research has an effect on the results. This means that the problem of researcher bias remains. Addressing it should be seen as a matter of priority amongst those of us who conduct and publish experiments comparing the performance of competing software defect prediction systems.",
        "keywords": [
            "Software",
            "NASA",
            "Measurement",
            "Analysis of variance",
            "Data models",
            "Predictive models",
            "Analytical models"
        ]
    },
    {
        "title": "A Study of Social Interactions in Open Source Component Use.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2756043",
        "volume": "44",
        "abstract": "All kinds of software projects, whether open or closed source, rely on open source components. Repositories that serve open source components to organizations, such as the Central Repository and npmjs.org, report billions of requests per year. Despite the widespread reliance of projects on open source components, little is known about the social interactions that occur between developers of a project using a component and developers of the component itself. In this paper, we investigate the social interactions that occur for 5,133 pairs of projects, from two different communities (Java and Ruby) representing user projects that depend on a component project. We consider such questions as how often are there social interactions when a component is used? When do the social interactions occur? And, why do social interactions occur? From our investigation, we observed that social interactions typically occur after a component has been chosen for use and relied upon. When social interactions occur, they most frequently begin with creating issues or feature requests. We also found that the more use a component receives, the less likely it is that developers of project using the component will interact with the component project, and when those interactions occur, they will be shorter in duration. Our results provide insight into how socio-technical interactions occur beyond the level of an individual or small group of projects previously studied by others and identify the need for a new model of socio-technical congruence for dependencies between, instead of within, projects.",
        "keywords": [
            "Social factors",
            "Computer bugs",
            "Java",
            "Collaboration",
            "Software reusability",
            "Open source software",
            "Project management"
        ]
    },
    {
        "title": "Collaborative Model-Driven Software Engineering: A Classification Framework and a Research Map.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2755039",
        "volume": "44",
        "abstract": "Context: Collaborative Model-Driven Software Engineering (MDSE) consists of methods and techniques where multiple stakeholders manage, collaborate, and are aware of each others' work on shared models. Objective: Collaborative MDSE is attracting research efforts from different areas, resulting in a variegated scientific body of knowledge. This study aims at identifying, classifying, and understanding existing collaborative MDSE approaches. Method: We designed and conducted a systematic mapping study. Starting from over 3,000 potentially relevant studies, we applied a rigorous selection procedure resulting in 106 selected papers, further clustered into 48 primary studies along a time span of 19 years. We rigorously defined and applied a classification framework and extracted key information from each selected study for subsequent analysis. Results: Our analysis revealed the following main fidings: (i) there is a growing scientific interest on collaborative MDSE in the last years; (ii) multi-view modeling, validation support, reuse, and branching are more rarely covered with respect to other aspects about collaborative MDSE; (iii) different primary studies focus differently on individual dimensions of collaborative MDSE (i.e., model management, collaboration, and communication); (iv) most approaches are language-specific, with a prominence of UML-based approaches; (v) few approaches support the interplay between synchronous and asynchronous collaboration. Conclusion: This study gives a solid foundation for classifying existing and future approaches for collaborative MDSE. Researchers and practitioners can use our results for identifying existing research/technical gaps to attack, better scoping their own contributions, or understanding existing ones.",
        "keywords": [
            "Collaboration",
            "Analytical models",
            "Software engineering",
            "Stakeholders",
            "Systematics"
        ]
    },
    {
        "title": "EARMO: An Energy-Aware Refactoring Approach for Mobile Apps.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2757486",
        "volume": "44",
        "abstract": "The energy consumption of mobile apps is a trending topic and researchers are actively investigating the role of coding practices on energy consumption. Recent studies suggest that design choices can conflict with energy consumption. Therefore, it is important to take into account energy consumption when evolving the design of a mobile app. In this paper, we analyze the impact of eight type of anti-patterns on a testbed of 20 android apps extracted from F-Droid. We propose EARMO, a novel anti-pattern correction approach that accounts for energy consumption when refactoring mobile anti-patterns. We evaluate EARMO using three multiobjective search-based algorithms. The obtained results show that EARMO can generate refactoring recommendations in less than a minute, and remove a median of 84 percent of anti-patterns. Moreover, EARMO extended the battery life of a mobile phone by up to 29 minutes when running in isolation a refactored multimedia app with default settings (no Wi-Fi, no location services, and minimum screen brightness). Finally, we conducted a qualitative study with developers of our studied apps, to assess the refactoring recommendations made by EARMO. Developers found 68 percent of refactorings suggested by EARMO to be very relevant.",
        "keywords": [
            "Mobile communication",
            "Energy consumption",
            "Software",
            "Androids",
            "Humanoid robots",
            "Energy measurement",
            "Software maintenance"
        ]
    },
    {
        "title": "Entropy Based Software Reliability Analysis of Multi-Version Open Source Software.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2766070",
        "volume": "44",
        "abstract": "The number of issues fixed in the current release of the software is one of the factors which decides the next release of the software. The source code files get changed during fixing of these issues. The uncertainty arises due to these changes is quantified using entropy based measures. We developed a Non-Homogeneous Poisson Process model for Open Source Software to understand the fixing of issues across releases. Based on this model, optimal release-updating using entropy and maximizing the active user's satisfaction level subject to fixing of issues up to a desired level, is investigated as well. The proposed models have been validated on five products of the Apache open source project. The optimal release time estimated from the proposed model is close to the observed release time at different active user's satisfaction levels. The proposed decision model can assist management to appropriately determine the optimal release-update time. The proposed entropy based model for issues estimation shows improvement in performance for 21 releases out of total 23 releases, when compared with well-known traditional software reliability growth models, namely GO model [1] and S-shaped model [2] . The proposed model is also found statistically significant.",
        "keywords": [
            "Entropy",
            "Software reliability",
            "Software product lines",
            "Computer bugs",
            "Open source software"
        ]
    },
    {
        "title": "On the Use of Hidden Markov Model to Predict the Time to Fix Bugs.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2757480",
        "volume": "44",
        "abstract": "A significant amount of time is spent by software developers in investigating bug reports. It is useful to indicate when a bug report will be closed, since it would help software teams to prioritise their work. Several studies have been conducted to address this problem in the past decade. Most of these studies have used the frequency of occurrence of certain developer activities as input attributes in building their prediction models. However, these approaches tend to ignore the temporal nature of the occurrence of these activities. In this paper, a novel approach using Hidden Markov Models and temporal sequences of developer activities is proposed. The approach is empirically demonstrated in a case study using eight years of bug reports collected from the Firefox project. Our proposed model correctly identifies bug reports with expected bug fix times. We also compared our proposed approach with the state of the art technique in the literature in the context of our case study. Our approach results in approximately 33 percent higher F-measure than the contemporary technique based on the Firefox project data.",
        "keywords": [
            "Computer bugs",
            "Hidden Markov models",
            "Predictive models",
            "Software quality",
            "Data science",
            "Stochastic processes"
        ]
    },
    {
        "title": "Revisiting the Performance Evaluation of Automated Approaches for the Retrieval of Duplicate Issue Reports.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2755005",
        "volume": "44",
        "abstract": "Issue tracking systems (ITSs), such as Bugzilla, are commonly used to track reported bugs, improvements and change requests for a software project. To avoid wasting developer resources on previously-reported (i.e., duplicate) issues, it is necessary to identify such duplicates as soon as they are reported. Several automated approaches have been proposed for retrieving duplicate reports, i.e., identifying the duplicate of a new issue report in a list of \n<inline-formula><tex-math notation=\"LaTeX\">$n$</tex-math></inline-formula>\n candidates. These approaches rely on leveraging the textual, categorical, and contextual information in previously-reported issues to decide whether a newly-reported issue has previously been reported. In general, these approaches are evaluated using data that spans a relatively short period of time (i.e., the classical evaluation). However, in this paper, we show that the classical evaluation tends to overestimate the performance of automated approaches for retrieving duplicate issue reports. Instead, we propose a realistic evaluation using all the reports that are available in the ITS of a software project. We conduct experiments in which we evaluate two popular approaches for retrieving duplicate issues (BM25F and REP) using the classical and realistic evaluations. We find that for the issue tracking data of the Mozilla foundation, the Eclipse foundation and OpenOffice, the realistic evaluation shows that previously proposed approaches perform considerably lower than previously reported using the classical evaluation. As a result, we conclude that the reported performance of approaches for retrieving duplicate issue reports is significantly overestimated in literature. In order to improve the performance of the automated retrieval of duplicate issue reports, we propose to leverage the resolution field of issue reports. Our experiments show that a relative improvement in the performance of a median of 7-21.5 percent and a maximum of 19-60 percent can be achieved by leveraging the resolution field of issue reports for the automated retrieval of duplicates.",
        "keywords": [
            "Text analysis",
            "Computer bugs",
            "Frequency measurement",
            "Performance evaluation",
            "Manuals",
            "Ports (Computers)"
        ]
    },
    {
        "title": "Tracking Load-Time Configuration Options.",
        "venue_name": "tse",
        "year": 2018,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2017.2756048",
        "volume": "44",
        "abstract": "Many software systems are highly configurable, despite the fact that configuration options and their interactions make those systems significantly harder to understand and maintain. In this work, we consider load-time configuration options, such as parameters from the command-line or from configuration files. They are particularly hard to reason about: tracking configuration options from the point at which they are loaded to the point at which they influence control-flow decisions is tedious and error-prone, if done manually. We design and implement Lotrack, an extended static taint analysis to track configuration options automatically. Lotrack derives a configuration map that explains for each code fragment under which configurations it may be executed. An evaluation on Android apps and Java applications from different domains shows that Lotrack yields high accuracy with reasonable performance. We use Lotrack to empirically characterize how much of the implementation of Android apps depends on the platform's configuration options or interactions of these options.",
        "keywords": [
            "Androids",
            "Humanoid robots",
            "Java",
            "Static analysis",
            "Bluetooth",
            "Data mining"
        ]
    }
]