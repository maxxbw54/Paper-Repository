[
    {
        "title": "Symbolic Refinement of Extended State Machines with Applications to the Automatic Derivation of Sub-Components and Controllers.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2878728",
        "volume": "47",
        "abstract": "Nowadays, extended state machines are prominent requirements specification techniques due to their capabilities of modeling complex systems in a compact way. These machines extend the standard state machines with variables and have transitions guarded by enabling predicates and may include variable update statements. Given a system modeled as an extended state machine, with possibly infinite state space and some non-controllable (parameterized) interactions, a pruning procedure is proposed to symbolically derive a maximal sub-machine of the original system that satisfies certain conditions; namely, some safeness and absence of undesirable deadlocks which could be produced during pruning. In addition, the user may specify, as predicates associated with states, some general goal assertions that should be preserved in the obtained sub-machine. Further, one may also specify some specific requirements such as the elimination of certain undesirable deadlocks at states, or fail states that should never be reached. Application examples are given considering deadlock avoidance and loops including infinite loops over non-controllable interactions showing that the procedure may not terminate. In addition, the procedure is applied for finding a controller of a system to be controlled. The approach generalizes existing work in respect to the considered extended machine model and the possibility of user defined control objectives written as assertions at states.",
        "keywords": [
            "System recovery",
            "Control systems",
            "Calculators",
            "Facsimile",
            "Electronic mail",
            "Unified modeling language",
            "Computer architecture"
        ]
    },
    {
        "title": "A Systematic Literature Review on Bad Smells-5 W's: Which, When, What, Who, Where.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2880977",
        "volume": "47",
        "abstract": "Bad smells are sub-optimal code structures that may represent problems needing attention. We conduct an extensive literature review on bad smells relying on a large body of knowledge from 1990 to 2017. We show that some smells are much more studied in the literature than others, and also that some of them are intrinsically inter-related (which). We give a perspective on how the research has been driven across time (when). In particular, while the interest in duplicated code emerged before the reference publications by Fowler and Beck and by Brown et al., other types of bad smells only started to be studied after these seminal publications, with an increasing trend in the last decade. We analyzed aims, findings, and respective experimental settings, and observed that the variability of these elements may be responsible for some apparently contradictory findings on bad smells (what). Moreover, we could observe that, in general, papers tend to study different types of smells at once. However, only a small percentage of those papers actually investigate possible relations between the respective smells (co-studies), i.e., each smell tends to be studied in isolation. Despite of a few relations between some types of bad smells have been investigated, there are other possible relations for further investigation. We also report that authors have different levels of interest in the subject, some of them publishing sporadically and others continuously (who). We observed that scientific connections are ruled by a large “small world” connected graph among researchers and several small disconnected graphs. We also found that the communities studying duplicated code and other types of bad smells are largely separated. Finally, we observed that some venues are more likely to disseminate knowledge on Duplicate Code (which often is listed as a conference topic on its own), while others have a more balanced distribution among other smells (where). Finally, we provide a discussion on future directions for bad smell research.",
        "keywords": [
            "Systematics",
            "Bibliographies",
            "Software",
            "Measurement",
            "Organizations",
            "Tools",
            "Cloning"
        ]
    },
    {
        "title": "Automatic Feature Learning for Predicting Vulnerable Software Components.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2881961",
        "volume": "47",
        "abstract": "Code flaws or vulnerabilities are prevalent in software systems and can potentially cause a variety of problems including deadlock, hacking, information loss and system failure. A variety of approaches have been developed to try and detect the most likely locations of such code vulnerabilities in large code bases. Most of them rely on manually designing code features (e.g., complexity metrics or frequencies of code tokens) that represent the characteristics of the potentially problematic code to locate. However, all suffer from challenges in sufficiently capturing both semantic and syntactic representation of source code, an important capability for building accurate prediction models. In this paper, we describe a new approach, built upon the powerful deep learning Long Short Term Memory model, to automatically learn both semantic and syntactic features of code. Our evaluation on 18 Android applications and the Firefox application demonstrates that the prediction power obtained from our learned features is better than what is achieved by state of the art vulnerability prediction models, for both within-project prediction and cross-project prediction.",
        "keywords": [
            "Semantics",
            "Software systems",
            "Predictive models",
            "Security",
            "Feature extraction",
            "System recovery"
        ]
    },
    {
        "title": "CBGA-ES+: A Cluster-Based Genetic Algorithm with Non-Dominated Elitist Selection for Supporting Multi-Objective Test Optimization.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2882176",
        "volume": "47",
        "abstract": "Many real-world test optimization problems (e.g., test case prioritization) are multi-objective intrinsically and can be tackled using various multi-objective search algorithms (e.g., Non-dominated Sorting Genetic Algorithm (NSGA-II)). However, existing multi-objective search algorithms have certain randomness when selecting parent solutions for producing offspring solutions. In a worse case, suboptimal parent solutions may result in offspring solutions with bad quality, and thus affect the overall quality of the solutions in the next generation. To address such a challenge, we propose CBGA-ES\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n, a novel cluster-based genetic algorithm with non-dominated elitist selection to reduce the randomness when selecting the parent solutions to support multi-objective test optimization. We empirically compared CBGA-ES\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n with random search and greedy (as baselines), four commonly used multi-objective search algorithms (i.e., Multi-objective Cellular genetic algorithm (MOCell), NSGA-II, Pareto Archived Evolution Strategy (PAES), and Strength Pareto Evolutionary Algorithm (SPEA2)), and the predecessor of CBGA-ES\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n (named CBGA-ES) using five multi-objective test optimization problems with eight subjects (two industrial, one real world, and five open source). The results showed that CBGA-ES\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n managed to significantly outperform the selected search algorithms for a majority of the experiments. Moreover, for the solutions in the same search space, CBGA-ES\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n managed to perform better than CBGA-ES, MOCell, NSGA-II, PAES, and SPEA2 for 2.2, 13.6, 14.5, 17.4, and 9.9 percent, respectively. Regarding the running time of the algorithm, CBGA-ES\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n was faster than CBGA-ES for all the experiments.",
        "keywords": [
            "Optimization",
            "Genetic algorithms",
            "Sociology",
            "Statistics",
            "Search problems",
            "Clustering algorithms",
            "Software algorithms"
        ]
    },
    {
        "title": "Beyond Technical Aspects: How Do Community Smells Influence the Intensity of Code Smells?",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2883603",
        "volume": "47",
        "abstract": "Code smells are poor implementation choices applied by developers during software evolution that often lead to critical flaws or failure. Much in the same way, community smells reflect the presence of organizational and socio-technical issues within a software community that may lead to additional project costs. Recent empirical studies provide evidence that community smells are often-if not always-connected to circumstances such as code smells. In this paper we look deeper into this connection by conducting a mixed-methods empirical study of 117 releases from 9 open-source systems. The qualitative and quantitative sides of our mixed-methods study were run in parallel and assume a mutually-confirmative connotation. On the one hand, we survey 162 developers of the 9 considered systems to investigate whether developers perceive relationship between community smells and the code smells found in those projects. On the other hand, we perform a fine-grained analysis into the 117 releases of our dataset to measure the extent to which community smells impact code smell intensity (i.e., criticality). We then propose a code smell intensity prediction model that relies on both technical and community-related aspects. The results of both sides of our mixed-methods study lead to one conclusion: community-related factors contribute to the intensity of code smells. This conclusion supports the joint use of community and code smells detection as a mechanism for the joint management of technical and social problems around software development communities.",
        "keywords": [
            "Predictive models",
            "Software engineering",
            "Open source software",
            "Convergence",
            "Tools",
            "Feature extraction"
        ]
    },
    {
        "title": "Evaluating Model-Driven Development Claims with Respect to Quality: A Family of Experiments.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2884706",
        "volume": "47",
        "abstract": "Context: There is a lack of empirical evidence on the differences between model-driven development (MDD), where code is automatically derived from conceptual models, and traditional software development method, where code is manually written. In our previous work, we compared both methods in a baseline experiment concluding that quality of the software developed following MDD was significantly better only for more complex problems (with more function points). Quality was measured through test cases run on a functional system. Objective: This paper reports six replications of the baseline to study the impact of problem complexity on software quality in the context of MDD. Method: We conducted replications of two types: strict replications and object replications. Strict replications were similar to the baseline, whereas we used more complex experimental objects (problems) in the object replications. Results: MDD yields better quality independently of problem complexity with a moderate effect size. This effect is bigger for problems that are more complex. Conclusions: Thanks to the bigger size of the sample after aggregating replications, we discovered an effect that the baseline had not revealed due to the small sample size. The baseline results hold, which suggests that MDD yields better quality for more complex problems.",
        "keywords": [
            "Unified modeling language",
            "Productivity",
            "Complexity theory",
            "Inspection",
            "Model-driven development",
            "Software quality"
        ]
    },
    {
        "title": "A Study of Feature Scattering in the Linux Kernel.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2884911",
        "volume": "47",
        "abstract": "Feature code is often scattered across a software system. Scattering is not necessarily bad if used with care, as witnessed by systems with highly scattered features that evolved successfully. Feature scattering, often realized with a pre-processor, circumvents limitations of programming languages and software architectures. Unfortunately, little is known about the principles governing scattering in large and long-living software systems. We present a longitudinal study of feature scattering in the Linux kernel, complemented by a survey with 74, and interviews with nine Linux kernel developers. We analyzed almost eight years of the kernel's history, focusing on its largest subsystem: device drivers. We learned that the ratio of scattered features remained nearly constant and that most features were introduced without scattering. Yet, scattering easily crosses subsystem boundaries, and highly scattered outliers exist. Scattering often addresses a performance-maintenance tradeoff (alleviating complicated APIs), hardware design limitations, and avoids code duplication. While developers do not consciously enforce scattering limits, they actually improve the system design and refactor code, thereby mitigating pre-processor idiosyncrasies or reducing its use.",
        "keywords": [
            "Scattering",
            "Kernel",
            "Linux",
            "Interviews",
            "Software systems",
            "Maintenance engineering"
        ]
    },
    {
        "title": "Mining Fix Patterns for FindBugs Violations.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2884955",
        "volume": "47",
        "abstract": "Several static analysis tools, such as Splint or FindBugs, have been proposed to the software development community to help detect security vulnerabilities or bad programming practices. However, the adoption of these tools is hindered by their high false positive rates. If the false positive rate is too high, developers may get acclimated to violation reports from these tools, causing concrete and severe bugs being overlooked. Fortunately, some violations are actually addressed and resolved by developers. We claim that those violations that are recurrently fixed are likely to be true positives, and an automated approach can learn to repair similar unseen violations. However, there is lack of a systematic way to investigate the distributions on existing violations and fixed ones in the wild, that can provide insights into prioritizing violations for developers, and an effective way to mine code and fix patterns which can help developers easily understand the reasons of leading violations and how to fix them. In this paper, we first collect and track a large number of fixed and unfixed violations across revisions of software. The empirical analyses reveal that there are discrepancies in the distributions of violations that are detected and those that are fixed, in terms of occurrences, spread and categories, which can provide insights into prioritizing violations. To automatically identify patterns in violations and their fixes, we propose an approach that utilizes convolutional neural networks to learn features and clustering to regroup similar instances. We then evaluate the usefulness of the identified fix patterns by applying them to unfixed violations. The results show that developers will accept and merge a majority (69/116) of fixes generated from the inferred fix patterns. It is also noteworthy that the yielded patterns are applicable to four real bugs in the Defects4J major benchmark for software testing and automated repair.",
        "keywords": [
            "Tools",
            "Static analysis",
            "Computer bugs",
            "Maintenance engineering",
            "Software",
            "Java",
            "Security"
        ]
    },
    {
        "title": "Automatically 'Verifying' Discrete-Time Complex Systems through Learning, Abstraction and Refinement.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2886898",
        "volume": "47",
        "abstract": "Precisely modeling complex systems like cyber-physical systems is challenging, which often renders model-based system verification techniques like model checking infeasible. To overcome this challenge, we propose a method called LAR to automatically `verify' such complex systems through a combination of learning, abstraction and refinement from a set of system log traces. We assume that log traces and sampling frequency are adequate to capture `enough' behaviour of the system. Given a safety property and the concrete system log traces as input, LAR automatically learns and refines system models, and produces two kinds of outputs. One is a counterexample with a bounded probability of being spurious. The other is a probabilistic model based on which the given property is `verified'. The model can be viewed as a proof obligation, i.e., the property is verified if the model is correct. It can also be used for subsequent system analysis activities like runtime monitoring or model-based testing. Our method has been implemented as a self-contained software toolkit. The evaluation on multiple benchmark systems as well as a real-world water treatment system shows promising results.",
        "keywords": [
            "Probabilistic logic",
            "Model checking",
            "Analytical models",
            "Safety",
            "Complex systems",
            "System analysis and design"
        ]
    },
    {
        "title": "Automated Documentation of Android Apps.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2890652",
        "volume": "47",
        "abstract": "Developers do not always have the knowledge needed to understand source code and must refer to different resources (e.g., teammates, documentation, the web). This non-trivial process, called program comprehension, is very time-consuming. While many approaches support the comprehension of a given code at hand, they are mostly focused on defining extractive summaries from the code (i.e., on selecting from a given piece of code the most important statements/comments to comprehend it). However, if the information needed to comprehend the code is not there, their usefulness is limited. We present ADANA, an approach to automatically inject comments describing a given piece of Android code. ADANA reuses the descriptions of similar and well-documented code snippets retrieved from various online resources. Our evaluation has shown that ADANA is able to aid the program comprehension process.",
        "keywords": [
            "Knowledge based systems",
            "Documentation",
            "Java",
            "Cloning",
            "Asia",
            "Task analysis",
            "Data mining"
        ]
    },
    {
        "title": "PPChecker: Towards Accessing the Trustworthiness of Android Apps' Privacy Policies.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2886875",
        "volume": "47",
        "abstract": "Recent years have witnessed a sharp increase of malicious apps that steal users' personal information. To address users' concerns about privacy risks and to comply with data protection laws, more and more apps are supplied with privacy policies written in natural language to help users understand an app's privacy practices. However, little is known whether these privacy policies are trustworthy or not. Questionable privacy policies may be prepared by careless app developers or someone with malicious intention. In this paper, we carry out a systematic study on privacy policy by proposing a novel approach to automatically identify five kinds of problems in privacy policy. After tackling several challenging issues, we implement the approach in a system, named PPChecker, and evaluate it with real apps and their privacy policies. The experimental results show that PPChecker can effectively identify questionable privacy policies with high precision. Applying PPChecker to 2,500 popular apps, we find that 1,850 apps (i.e., 74.0 percent) have at least one kind of problems. This study sheds light on the research of improving and regulating apps' privacy policies.",
        "keywords": [
            "Privacy",
            "Google",
            "Natural languages",
            "Mobile handsets",
            "Data protection",
            "Force"
        ]
    },
    {
        "title": "Fault Analysis and Debugging of Microservice Systems: Industrial Survey, Benchmark System, and Empirical Study.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2887384",
        "volume": "47",
        "abstract": "The complexity and dynamism of microservice systems pose unique challenges to a variety of software engineering tasks such as fault analysis and debugging. In spite of the prevalence and importance of microservices in industry, there is limited research on the fault analysis and debugging of microservice systems. To fill this gap, we conduct an industrial survey to learn typical faults of microservice systems, current practice of debugging, and the challenges faced by developers in practice. We then develop a medium-size benchmark microservice system (being the largest and most complex open source microservice system within our knowledge) and replicate 22 industrial fault cases on it. Based on the benchmark system and the replicated fault cases, we conduct an empirical study to investigate the effectiveness of existing industrial debugging practices and whether they can be further improved by introducing the state-of-the-art tracing and visualization techniques for distributed systems. The results show that the current industrial practices of microservice debugging can be improved by employing proper tracing and visualization techniques and strategies. Our findings also suggest that there is a strong need for more intelligent trace analysis and visualization, e.g., by combining trace visualization and improved fault localization, and employing data-driven and learning-based recommendation for guided visual exploration and comparison of traces.",
        "keywords": [
            "Debugging",
            "Benchmark testing",
            "Companies",
            "Computer architecture",
            "Visualization",
            "Industries",
            "Runtime"
        ]
    },
    {
        "title": "Coverage Prediction for Accelerating Compiler Testing.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2018.2889771",
        "volume": "47",
        "abstract": "Compilers are one of the most fundamental software systems. Compiler testing is important for assuring the quality of compilers. Due to the crucial role of compilers, they have to be well tested. Therefore, automated compiler testing techniques (those based on randomly generated programs) tend to run a large number of test programs (which are test inputs of compilers). The cost for compilation and execution for these test programs is significant. These techniques can take a long period of testing time to detect a relatively small number of compiler bugs. That may cause many practical problems, e.g., bringing a lot of costs including time costs and financial costs, and delaying the development/release cycle. Recently, some approaches have been proposed to accelerate compiler testing by executing test programs that are more likely to trigger compiler bugs earlier according to some criteria. However, these approaches ignore an important aspect in compiler testing: different test programs may have similar test capabilities (i.e., testing similar functionalities of a compiler, even detecting the same compiler bug), which may largely discount their acceleration effectiveness if the test programs with similar test capabilities are executed all the time. Test coverage is a proper approximation to help distinguish them, but collecting coverage dynamically is infeasible in compiler testing since most test programs are generated on the fly by automatic test-generation tools like Csmith. In this paper, we propose the first method to predict test coverage statically for compilers, and then propose to prioritize test programs by clustering them according to the predicted coverage information. The novel approach to accelerating compiler testing through coverage prediction is called COP (short for COverage Prediction). Our evaluation on GCC and LLVM demonstrates that COP significantly accelerates compiler testing, achieving an average of 51.01 percent speedup in test execution time on an existing dataset including three old release versions of the compilers and achieving an average of 68.74 percent speedup on a new dataset including 12 latest release versions. Moreover, COP outperforms the state-of-the-art acceleration approach significantly by improving \n<inline-formula><tex-math notation=\"LaTeX\">$17.16\\%\\sim 82.51\\%$</tex-math></inline-formula>\n speedups in different settings on average.",
        "keywords": [
            "Testing",
            "Program processors",
            "Computer bugs",
            "Life estimation",
            "Acceleration",
            "Optimization",
            "Electromagnetic interference"
        ]
    },
    {
        "title": "Inductive Validity Cores.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2891709",
        "volume": "47",
        "abstract": "Symbolic model checkers can construct proofs of properties over highly complex models. However, the results reported by the tool when a proof succeeds do not generally provide much insight to the user. It is often useful for users to have traceability information related to the proof: which portions of the model were necessary to construct it. This traceability information can be used to diagnose a variety of modeling problems such as overconstrained axioms and underconstrained properties, measure completeness of a set of requirements over a model, and assist with design optimization given a set of requirements for an existing or synthesized implementation. In this paper, we present a comprehensive treatment of a suite of algorithms to compute inductive validity cores (IVCs), minimal sets of model elements necessary to construct inductive proofs of safety properties for sequential systems. The algorithms are based on the UNSAT core support built into current SMT solvers and novel encodings of the inductive problem to generate approximate and guaranteed minimal inductive validity cores as well as all inductive validity cores. We demonstrate that our algorithms are correct, describe their implementation in the JKind model checker for Lustre models, and present several use cases for the algorithms. We then present a substantial experiment in which we benchmark the efficiency and efficacy of the algorithms.",
        "keywords": [
            "Computational modeling",
            "Analytical models",
            "Tools",
            "Safety",
            "Mathematical model",
            "Approximation algorithms",
            "Model checking"
        ]
    },
    {
        "title": "App Store Effects on Software Engineering Practices.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2891715",
        "volume": "47",
        "abstract": "In this paper, we study the app store as a phenomenon from the developers' perspective to investigate the extent to which app stores affect software engineering tasks. Through developer interviews and questionnaires, we uncover findings that highlight and quantify the effects of three high-level app store themes: bridging the gap between developers and users, increasing market transparency and affecting mobile release management. Our findings have implications for testing, requirements engineering and mining software repositories research fields. These findings can help guide future research in supporting mobile app developers through a deeper understanding of the app store-developer interaction.",
        "keywords": [
            "Software engineering",
            "Software",
            "Interviews",
            "Data mining",
            "Testing",
            "Data collection",
            "Business"
        ]
    },
    {
        "title": "The Impact of Correlated Metrics on the Interpretation of Defect Models.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2891758",
        "volume": "47",
        "abstract": "Defect models are analytical models for building empirical theories related to software quality. Prior studies often derive knowledge from such models using interpretation techniques, e.g., ANOVA Type-I. Recent work raises concerns that correlated metrics may impact the interpretation of defect models. Yet, the impact of correlated metrics in such models has not been investigated. In this paper, we investigate the impact of correlated metrics on the interpretation of defect models and the improvement of the interpretation of defect models when removing correlated metrics. Through a case study of 14 publicly- available defect datasets, we find that (1) correlated metrics have the largest impact on the consistency, the level of discrepancy, and the direction of the ranking of metrics, especially for ANOVA techniques. On the other hand, we find that removing all correlated metrics (2) improves the consistency of the produced rankings regardless of the ordering of metrics (except for ANOVA Type-I); (3) improves the consistency of ranking of metrics among the studied interpretation techniques; (4) impacts the model performance by less than 5 percentage points. Thus, when one wishes to derive sound interpretation from defect models, one must (1) mitigate correlated metrics especially for ANOVA analyses; and (2) avoid using ANOVA Type-I even if all correlated metrics are removed.",
        "keywords": [
            "Measurement",
            "Analytical models",
            "Analysis of variance",
            "Complexity theory",
            "Software quality",
            "Computer bugs",
            "Correlation"
        ]
    },
    {
        "title": "An Empirical Study of Fault Localization Families and Their Combinations.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2892102",
        "volume": "47",
        "abstract": "The performance of fault localization techniques is critical to their adoption in practice. This paper reports on an empirical study of a wide range of fault localization techniques on real-world faults. Different from previous studies, this paper (1) considers a wide range of techniques from different families, (2) combines different techniques, and (3) considers the execution time of different techniques. Our results reveal that a combined technique significantly outperforms any individual technique (200 percent increase in faults localized in Top 1), suggesting that combination may be a desirable way to apply fault localization techniques and that future techniques should also be evaluated in the combined setting. Our implementation is publicly available for evaluating and combining fault localization techniques.",
        "keywords": [
            "Switches",
            "Debugging",
            "Software",
            "Fault diagnosis",
            "Task analysis",
            "Computer bugs",
            "History"
        ]
    },
    {
        "title": "Using K-core Decomposition on Class Dependency Networks to Improve Bug Prediction Model's Practical Performance.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2892959",
        "volume": "47",
        "abstract": "In recent years, Complex Network theory and graph algorithms have been proved to be effective in predicting software bugs. On the other hand, as a widely-used algorithm in Complex Network theory, k-core decomposition has been used in software engineering domain to identify key classes. Intuitively, key classes are more likely to be buggy since they participate in more functions or have more interactions and dependencies. However, there is no existing research uses k-core decomposition to analyze software bugs. To fill this gap, we first use k-core decomposition on Class Dependency Networks to analyze software bug distribution from a new perspective. An interesting and widely existed tendency is observed: for classes in k-cores with larger k values, there is a stronger possibility for them to be buggy. Based on this observation, we then propose a simple but effective equation named as top-core which improves the order of classes in the suspicious class list produced by effort-aware bug prediction models. Based on an empirical study on 18 open-source Java systems, we show that the bug prediction models' performances are significantly improved in 85.2 percent experiments in the cross-validation scenario and in 80.95 percent experiments in the forward-release scenario, after using top-core. The models' average performances are improved by 11.5 and 12.6 percent, respectively. It is concluded that the proposed top-core equation can help the testers or code reviewers locate the real bugs more quickly and easily in software bug prediction practices.",
        "keywords": [
            "Computer bugs",
            "Software",
            "Mathematical model",
            "Predictive models",
            "Complex networks",
            "Prediction algorithms",
            "Software algorithms"
        ]
    },
    {
        "title": "Too Many User-Reviews! What Should App Developers Look at First?",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2893171",
        "volume": "47",
        "abstract": "Due to the rapid growth in the number of mobile applications (apps) in the past few years, succeeding in mobile app markets has become ruthless. Online app markets, such as Google Play Store, let users rate apps on a five-star scale and leave feedback. Given the importance of high star-ratings to the success of an app, it is crucial to help developers find the key topics of user-reviews that are significantly related to star-ratings of a given category. Having considered the key topics of user-reviews, app developers can narrow down their effort to the user-reviews that matter to be addressed for receiving higher star-ratings. We study 4,193,549 user-reviews of 623 Android apps that were collected from Google Play Store in ten different categories. The results show that few key topics commonly exist across categories, and each category has a specific set of key topics. We also evaluated the identified key topics with respect to the changes that are made to each version of the apps for 19 months. We observed, for 77 percent of the apps, considering the key topics in the next versions shares a significant relationship with increases in star-ratings.",
        "keywords": [
            "Google",
            "Measurement",
            "Crawlers",
            "Natural language processing",
            "Computer bugs",
            "Tools",
            "Filtering"
        ]
    },
    {
        "title": "Specifying Callback Control Flow of Mobile Apps Using Finite Automata.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2893207",
        "volume": "47",
        "abstract": "Given the event-driven and framework-based architecture of Android apps, finding the ordering of callbacks executed by the framework remains a problem that affects every tool that requires inter-callback reasoning. Previous work has focused on the ordering of callbacks related to the Android components and GUI events. But the execution of callbacks can also come from direct calls of the framework (API calls). This paper defines a novel program representation, called Callback Control Flow Automata (CCFA), that specifies the control flow of callbacks invoked via a variety of sources. We present an analysis to automatically construct CCFAs by combining two callback control flow representations developed from the previous research, namely, Window Transition Graphs (WTGs) and Predicate Callback Summaries (PCSs). To demonstrate the usefulness of our representation, we integrated CCFAs into two client analyses: a taint analysis using FLOWDROID, and a value-flow analysis that computes source and sink pairs of a program. Our evaluation shows that we can compute CCFAs efficiently and that CCFAs improved the callback coverages over WTGs. As a result of using CCFAs, we obtained 33 more true positive security leaks than FLOWDROID over a total of 55 apps we have run. With a low false positive rate, we found that 22.76 percent of source-sink pairs we computed are located in different callbacks and that 31 out of 55 apps contain source-sink pairs spreading across components. Thus, callback control flow graphs and inter-callback analysis are indeed important. Although this paper mainly uses Android, we believe that CCFAs can be useful for modeling control flow of callbacks for other event-driven, framework-based systems.",
        "keywords": [
            "Tools",
            "Automata",
            "Microsoft Windows",
            "Graphical user interfaces",
            "Computer architecture",
            "Static analysis",
            "Cameras"
        ]
    },
    {
        "title": "Mining Treatment-Outcome Constructs from Sequential Software Engineering Data.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2892956",
        "volume": "47",
        "abstract": "Many investigations in empirical software engineering look at sequences of data resulting from development or management processes. In this paper, we propose an analytical approach called the Gandhi-Washington Method (GWM) to investigate the impact of recurring events in software projects. GWM takes an encoding of events and activities provided by a software analyst as input. It uses regular expressions to automatically condense and summarize information and infer treatments. Relating the treatments to the outcome through statistical tests, treatment-outcome constructs are automatically mined from the data. The output of GWM is a set of treatment-outcome constructs. Each treatment in the set of mined constructs is significantly different from the other treatments considering the impact on the outcome and/or is structurally different from other treatments considering the sequence of events. We describe GWM and classes of problems to which GWM can be applied. We demonstrate the applicability of this method for empirical studies on sequences of file editing, code ownership, and release cycle time.",
        "keywords": [
            "Software",
            "Computer bugs",
            "Encoding",
            "Data mining",
            "Software engineering",
            "Testing",
            "Itemsets"
        ]
    },
    {
        "title": "A Theoretical and Empirical Analysis of Program Spectra Diagnosability.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2895640",
        "volume": "47",
        "abstract": "Current metrics for assessing the adequacy of a test-suite plainly focus on the number of components (be it lines, branches, paths) covered by the suite, but do not explicitly check how the tests actually exercise these components and whether they provide enough information so that spectrum-based fault localization techniques can perform accurate fault isolation. We propose a metric, called DDU, aimed at complementing adequacy measurements by quantifying a test-suite's diagnosability, i.e., the effectiveness of applying spectrum-based fault localization to pinpoint faults in the code in the event of test failures. Our aim is to increase the value generated by creating thorough test-suites, so they are not only regarded as error detection mechanisms but also as effective diagnostic aids that help widely-used fault-localization techniques to accurately pinpoint the location of bugs in the system. We have performed a topology-based simulation of thousands of spectra and have found that DDU can effectively establish an upper bound on the effort to diagnose faults. Furthermore, our empirical experiments using the Defects4J dataset show that optimizing a test suite with respect to DDU yields a 34 percent gain in spectrum-based fault localization report accuracy when compared to the standard branch-coverage metric.",
        "keywords": [
            "Software",
            "Measurement uncertainty",
            "Diversity reception",
            "Cognition",
            "Current measurement",
            "Tools"
        ]
    },
    {
        "title": "Mining Likely Analogical APIs Across Third-Party Libraries via Large-Scale Unsupervised API Semantics Embedding.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2896123",
        "volume": "47",
        "abstract": "Establishing API mappings between third-party libraries is a prerequisite step for library migration tasks. Manually establishing API mappings is tedious due to the large number of APIs to be examined. Having an automatic technique to create a database of likely API mappings can significantly ease the task. Unfortunately, existing techniques either adopt supervised learning mechanism that requires already-ported or functionality similar applications across major programming languages or platforms, which are difficult to come by for an arbitrary pair of third-party libraries, or cannot deal with lexical gap in the API descriptions of different libraries. To overcome these limitations, we present an unsupervised deep learning based approach to embed both API usage semantics and API description (name and document) semantics into vector space for inferring likely analogical API mappings between libraries. Based on deep learning models trained using tens of millions of API call sequences, method names and comments of 2.8 millions of methods from 135,127 GitHub projects, our approach significantly outperforms other deep learning or traditional information retrieval (IR) methods for inferring likely analogical APIs. We implement a proof-of-concept website (https://similarapi.appspot.com) which can recommend analogical APIs for 583,501 APIs of 111 pairs of analogical Java libraries with diverse functionalities. This scale of third-party analogical-API database has never been achieved before.",
        "keywords": [
            "Libraries",
            "Semantics",
            "Databases",
            "Task analysis",
            "Recurrent neural networks",
            "Deep learning",
            "Java"
        ]
    },
    {
        "title": "Which Commits Can Be CI Skipped?",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2897300",
        "volume": "47",
        "abstract": "Continuous Integration (CI) frameworks such as Travis CI, automatically build and run tests whenever a new commit is submitted/pushed. Although there are many advantages in using CI, e.g., speeding up the release cycle and automating the test execution process, it has been noted that the CI process can take a very long time to complete. One of the possible reasons for such delays is the fact that some commits (e.g., changes to readme files) unnecessarily kick off the CI process. Therefore, the goal of this paper is to automate the process of determining which commits can be CI skipped. We start by examining the commits of 58 Java projects and identify commits that were explicitly CI skipped by developers. Based on the manual investigation of 1,813 explicitly CI skipped commits, we first devise an initial model of a CI skipped commit and use this model to propose a rule-based technique that automatically identifies commits that should be CI skipped. To evaluate the rule-based technique, we perform a study on unseen datasets extracted from ten projects and show that the devised rule-based technique is able to detect and label CI skip commits, achieving Areas Under the Curve (AUC) values between 0.56 and 0.98 (average of 0.73). Additionally, we show that, on average, our technique can reduce the number of commits that need to trigger the CI process by 18.16 percent. We also qualitatively triangulated our analysis on the importance of skipping the CI process through a survey with 40 developers. The survey results showed that 75 percent of the surveyed developers consider it to be nice, important or very important to have a technique that automatically flags CI skip commits. To operationalize our technique, we develop a publicly available prototype tool, called CI-Skipper, that can be integrated with any git repository and automatically mark commits that can be CI skipped.",
        "keywords": [
            "Java",
            "Software",
            "Prototypes",
            "Tools",
            "Virtual machining",
            "Data collection",
            "Manuals"
        ]
    },
    {
        "title": "Generic Adaptive Scheduling for Efficient Context Inconsistency Detection.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2898976",
        "volume": "47",
        "abstract": "Many applications use contexts to understand their environments and make adaptation. However, contexts are often inaccurate or even conflicting with each other (a.k.a. context inconsistency). To prevent applications from behaving abnormally or even failing, one promising approach is to deploy constraint checking to detect context inconsistencies. A variety of constraint checking techniques have been proposed, based on different incremental or parallel mechanisms for the efficiency. They are commonly deployed with the strategy that schedules constraint checking immediately upon context changes. This assures no missed inconsistency, but also limits the detection efficiency. One may break the limit by grouping context changes for checking together, but this can cause severe inconsistency missing problem (up to 79.2 percent). In this article, we propose a novel strategy GEAS to isolate latent interferences among context changes and schedule constraint checking with adaptive group sizes. This makes GEAS not only improve the detection efficiency, but also assure no missed inconsistency with theoretical guarantee. We experimentally evaluated GEAS with large-volume real-world context data. The results show that GEAS achieved significant efficiency gains for context inconsistency detection by 38.8-566.7 percent (or 1.4x-6.7x). When enhanced with an extended change-cancellation optimization, the gains were up to 2,755.9 percent (or 28.6x).",
        "keywords": [
            "Unified modeling language",
            "Software",
            "Public transportation",
            "Schedules",
            "Adaptive scheduling",
            "XML"
        ]
    },
    {
        "title": "A Progression Model of Software Engineering Goals, Challenges, and Practices in Start-Ups.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2900213",
        "volume": "47",
        "abstract": "Context: Software start-ups are emerging as suppliers of innovation and software-intensive products. However, traditional software engineering practices are not evaluated in the context, nor adopted to goals and challenges of start-ups. As a result, there is insufficient support for software engineering in the start-up context. Objective: We aim to collect data related to engineering goals, challenges, and practices in start-up companies to ascertain trends and patterns characterizing engineering work in start-ups. Such data allows researchers to understand better how goals and challenges are related to practices. This understanding can then inform future studies aimed at designing solutions addressing those goals and challenges. Besides, these trends and patterns can be useful for practitioners to make more informed decisions in their engineering practice. Method: We use a case survey method to gather first-hand, in-depth experiences from a large sample of software start-ups. We use open coding and cross-case analysis to describe and identify patterns, and corroborate the findings with statistical analysis. Results: We analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16 engineering practices that are common among start-ups. We have mapped these goals, challenges, and practices to start-up life-cycle stages (inception, stabilization, growth, and maturity). Thus, creating the progression model guiding software engineering efforts in start-ups. Conclusions: We conclude that start-ups to a large extent face the same challenges and use the same practices as established companies. However, the primary software engineering challenge in start-ups is to evolve multiple process areas at once, with a little margin for serious errors.",
        "keywords": [
            "Software",
            "Software engineering",
            "Companies",
            "Market opportunities",
            "Requirements engineering",
            "Analytical models"
        ]
    },
    {
        "title": "Automatic Mining of Opinions Expressed About APIs in Stack Overflow.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2900245",
        "volume": "47",
        "abstract": "With the proliferation of online developer forums, developers share their opinions about the APIs they use. The plethora of such information can present challenges to the developers to get quick but informed insights about the APIs. To understand the potential benefits of such API reviews, we conducted a case study of opinions in Stack Overflow using a benchmark dataset of 4,522 sentences. We observed that opinions about diverse API aspects (e.g., usability) are prevalent and offer insights that can shape developers' perception and decisions related to software development. Motivated by the finding, we built a suite of techniques to automatically mine and categorize opinions about APIs from forum posts. First, we detect opinionated sentences in the forum posts. Second, we associate the opinionated sentences to the API mentions. Third, we detect API aspects (e.g., performance, usability) in the reviews. We developed and deployed a tool called Opiner, supporting the above techniques. Opiner is available online as a search engine, where developers can search for APIs by their names to see all the aggregated opinions about the APIs that are automatically mined and summarized from developer forums.",
        "keywords": [
            "Benchmark testing",
            "Usability",
            "Search engines",
            "Java",
            "Data mining",
            "Tools"
        ]
    },
    {
        "title": "Toxic Code Snippets on Stack Overflow.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2900307",
        "volume": "47",
        "abstract": "Online code clones are code fragments that are copied from software projects or online sources to Stack Overflow as examples. Due to an absence of a checking mechanism after the code has been copied to Stack Overflow, they can become toxic code snippets, e.g., they suffer from being outdated or violating the original software license. We present a study of online code clones on Stack Overflow and their toxicity by incorporating two developer surveys and a large-scale code clone detection. A survey of 201 high-reputation Stack Overflow answerers (33 percent response rate) showed that 131 participants (65 percent) have ever been notified of outdated code and 26 of them (20 percent) rarely or never fix the code. 138 answerers (69 percent) never check for licensing conflicts between their copied code snippets and Stack Overflow's CC BY-SA 3.0. A survey of 87 Stack Overflow visitors shows that they experienced several issues from Stack Overflow answers: mismatched solutions, outdated solutions, incorrect solutions, and buggy code. 85 percent of them are not aware of CC BY-SA 3.0 license enforced by Stack Overflow, and 66 percent never check for license conflicts when reusing code snippets. Our clone detection found online clone pairs between 72,365 Java code snippets on Stack Overflow and 111 open source projects in the curated Qualitas corpus. We analysed 2,289 non-trivial online clone candidates. Our investigation revealed strong evidence that 153 clones have been copied from a Qualitas project to Stack Overflow. We found 100 of them (66 percent) to be outdated, of which 10 were buggy and harmful for reuse. Furthermore, we found 214 code snippets that could potentially violate the license of their original software and appear 7,112 times in 2,427 GitHub projects.",
        "keywords": [
            "Cloning",
            "Licenses",
            "Software",
            "Programming",
            "Computer bugs",
            "Security",
            "Tutorials"
        ]
    },
    {
        "title": "What Predicts Software Developers' Productivity?",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2900308",
        "volume": "47",
        "abstract": "Organizations have a variety of options to help their software developers become their most productive selves, from modifying office layouts, to investing in better tools, to cleaning up the source code. But which options will have the biggest impact? Drawing from the literature in software engineering and industrial/organizational psychology to identify factors that correlate with productivity, we designed a survey that asked 622 developers across 3 companies about these productivity factors and about self-rated productivity. Our results suggest that the factors that most strongly correlate with self-rated productivity were non-technical factors, such as job enthusiasm, peer support for new ideas, and receiving useful feedback about job performance. Compared to other knowledge workers, our results also suggest that software developers' self-rated productivity is more strongly related to task variety and ability to work remotely.",
        "keywords": [
            "Productivity",
            "Software",
            "Companies",
            "Google",
            "Tools",
            "Task analysis",
            "Time measurement"
        ]
    },
    {
        "title": "Automatically Assessing Code Understandability.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2901468",
        "volume": "47",
        "abstract": "Understanding software is an inherent requirement for many maintenance and evolution tasks. Without a thorough understanding of the code, developers would not be able to fix bugs or add new features timely. Measuring code understandability might be useful to guide developers in writing better code, and could also help in estimating the effort required to modify code components. Unfortunately, there are no metrics designed to assess the understandability of code snippets. In this work, we perform an extensive evaluation of 121 existing as well as new code-related, documentation-related, and developer-related metrics. We try to (i) correlate each metric with understandability and (ii) build models combining metrics to assess understandability. To do this, we use 444 human evaluations from 63 developers and we obtained a bold negative result: none of the 121 experimented metrics is able to capture code understandability, not even the ones assumed to assess quality attributes apparently related, such as code readability and complexity. While we observed some improvements while combining metrics in models, their effectiveness is still far from making them suitable for practical applications. Finally, we conducted interviews with five professional developers to understand the factors that influence their ability to understand code snippets, aiming at identifying possible new metrics.",
        "keywords": [
            "Complexity theory",
            "Software",
            "Computer bugs",
            "Readability metrics",
            "Software measurement",
            "Indexes"
        ]
    },
    {
        "title": "Topology-Specific Synthesis of Self-Stabilizing Parameterized Systems with Constant-Space Processes.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2901485",
        "volume": "47",
        "abstract": "This paper investigates the synthesis of parameterized systems that are self-stabilizing by construction. To this end, we present several significant results. First, we show a counterintuitive result that despite the undecidability of verifying self-stabilization for parameterized unidirectional rings, synthesizing self-stabilizing unidirectional rings is decidable! This is surprising because it is known that, in general, the synthesis of distributed systems is harder than their verification. Second, we present a topology-specific synthesis method (derived from our proof of decidability) that generates the state transition system of template processes of parameterized self-stabilizing systems with elementary unidirectional topologies (e.g., rings, chains, trees). We also provide a software tool that implements our synthesis algorithms and generates interesting self-stabilizing parameterized unidirectional rings in less than 50 microseconds on a regular laptop. We validate the proposed synthesis algorithms for decidable cases in the context of several interesting distributed protocols. Third, we show that synthesis of self-stabilizing bidirectional rings remains undecidable.",
        "keywords": [
            "Topology",
            "Protocols",
            "Convergence",
            "Software algorithms",
            "Portable computers",
            "Automata",
            "Transforms"
        ]
    },
    {
        "title": "Exploring Community Smells in Open-Source: An Automated Approach.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2901490",
        "volume": "47",
        "abstract": "Software engineering is now more than ever a community effort. Its success often weighs on balancing distance, culture, global engineering practices and more. In this scenario many unforeseen socio-technical events may result into additional project cost or “social” debt, e.g., sudden, collective employee turnover. With industrial research we discovered community smells, that is, sub-optimal patterns across the organisational and social structure in a software development community that are precursors of such nasty socio-technical events. To understand the impact of community smells at large, in this paper we first introduce CodeFace4Smells, an automated approach able to identify four community smell types that reflect socio-technical issues that have been shown to be detrimental both the software engineering and organisational research fields. Then, we perform a large-scale empirical study involving over 100 years worth of releases and communication structures data of 60 open-source communities: we evaluate (i) their diffuseness, i.e., how much are they distributed in open-source, (ii) how developers perceive them, to understand whether practitioners recognize their presence and their negative effects in practice, and (iii) how community smells relate to existing socio-technical factors, with the aim of assessing the inter-relations between them. The key findings of our study highlight that community smells are highly diffused in open-source and are perceived by developers as relevant problems for the evolution of software communities. Moreover, a number of state-of-the-art socio-technical indicators (e.g., socio-technical congruence) can be used to monitor how healthy a community is and possibly avoid the emergence of social debt.",
        "keywords": [
            "Software engineering",
            "Open source software",
            "Organizational aspects",
            "Social networking (online)",
            "Tools",
            "Microstructure"
        ]
    },
    {
        "title": "Automatic Detection and Update Suggestion for Outdated API Names in Documentation.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2901459",
        "volume": "47",
        "abstract": "Application programming interfaces (APIs) continually evolve to meet ever-changing user needs, and documentation provides an authoritative reference for their usage. However, API documentation is commonly outdated because nearly all of the associated updates are performed manually. Such outdated documentation, especially with regard to API names, causes major software development issues. In this paper, we propose a method for automatically updating outdated API names in API documentation. Our insight is that API updates in documentation can be derived from API implementation changes between code revisions. To evaluate the proposed method, we applied it to four open source projects. Our evaluation results show that our method, FreshDoc, detects outdated API names in API documentation with 48 percent higher accuracy than the existing state-of-the-art methods do. Moreover, when we checked the updates suggested by FreshDoc against the developers' manual updates in the revised documentation, FreshDoc detected 82 percent of the outdated names. When we reported 40 outdated API names found by FreshDoc via issue tracking systems, developers accepted 75 percent of the suggestions. These evaluation results indicate that FreshDoc can be used as a practical method for the detection and updating of API names in the associated documentation.",
        "keywords": [
            "Documentation",
            "Computer bugs",
            "Tools",
            "History",
            "Libraries",
            "Software systems"
        ]
    },
    {
        "title": "Rebooting Research on Detecting Repackaged Android Apps: Literature Review and Benchmark.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2901679",
        "volume": "47",
        "abstract": "Repackaging is a serious threat to the Android ecosystem as it deprives app developers of their benefits, contributes to spreading malware on users' devices, and increases the workload of market maintainers. In the space of six years, the research around this specific issue has produced 57 approaches which do not readily scale to millions of apps or are only evaluated on private datasets without, in general, tool support available to the community. Through a systematic literature review of the subject, we argue that the research is slowing down, where many state-of-the-art approaches have reported high-performance rates on closed datasets, which are unfortunately difficult to replicate and to compare against. In this work, we propose to reboot the research in repackaged app detection by providing a literature review that summarises the challenges and current solutions for detecting repackaged apps and by providing a large dataset that supports replications of existing solutions and implications of new research directions. We hope that these contributions will re-activate the direction of detecting repackaged apps and spark innovative approaches going beyond the current state-of-the-art.",
        "keywords": [
            "Bibliographies",
            "Malware",
            "Cloning",
            "Systematics",
            "Tools",
            "Aging",
            "Libraries"
        ]
    },
    {
        "title": "Understanding How and Why Developers Seek and Analyze API-Related Opinions.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2903039",
        "volume": "47",
        "abstract": "With the advent and proliferation of online developer forums as informal documentation, developers often share their opinions about the APIs they use. Thus, opinions of others often shape the developer's perception and decisions related to software development. For example, the choice of an API or how to reuse the functionality the API offers are, to a considerable degree, conditioned upon what other developers think about the API. While many developers refer to and rely on such opinion-rich information about APIs, we found little research that investigates the use and benefits of public opinions. To understand how developers seek and evaluate API opinions, we conducted two surveys involving a total of 178 software developers. We analyzed the data in two dimensions, each corresponding to specific needs related to API reviews: (1) Needs for seeking API reviews, and (2) Needs for automated tool support to assess the reviews. We observed that developers seek API reviews and often have to summarize those for diverse development needs (e.g., API suitability). Developers also make conscious efforts to judge the trustworthiness of the provided opinions and believe that automated tool support for API reviews analysis can assist in diverse development scenarios, including, for example, saving time in API selection as well as making informed decisions on a particular API features.",
        "keywords": [
            "Tools",
            "Documentation",
            "Task analysis",
            "Java",
            "Data mining",
            "Open source software"
        ]
    },
    {
        "title": "The Effect of Work Environments on Productivity and Satisfaction of Software Engineers.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2903053",
        "volume": "47",
        "abstract": "The physical work environment of software engineers can have various effects on their satisfaction and the ability to get the work done. To better understand the factors of the environment that affect productivity and satisfaction of software engineers, we explored different work environments at Microsoft. We used a mixed-methods, multiple stage research design with a total of 1,159 participants: two surveys with 297 and 843 responses respectively and interviews with 19 employees. We found several factors that were considered as important for work environments: personalization, social norms and signals, room composition and atmosphere, work-related environment affordances, work area and furniture, and productivity strategies. We built statistical models for satisfaction with the work environment and perceived productivity of software engineers and compared them to models for employees in the Program Management, IT Operations, Marketing, and Business Program & Operations disciplines. In the satisfaction models, the ability to work privately with no interruptions and the ability to communicate with the team and leads were important factors among all disciplines. In the productivity models, the overall satisfaction with the work environment and the ability to work privately with no interruptions were important factors among all disciplines. For software engineers, another important factor for perceived productivity was the ability to communicate with the team and leads. We found that private offices were linked to higher perceived productivity across all disciplines.",
        "keywords": [
            "Software",
            "Productivity",
            "Organizations",
            "Software engineering",
            "Interviews",
            "Collaboration",
            "Knowledge engineering"
        ]
    },
    {
        "title": "Lightweight Assessment of Test-Case Effectiveness Using Source-Code-Quality Indicators.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2903057",
        "volume": "47",
        "abstract": "Test cases are crucial to help developers preventing the introduction of software faults. Unfortunately, not all the tests are properly designed or can effectively capture faults in production code. Some measures have been defined to assess test-case effectiveness: the most relevant one is the mutation score, which highlights the quality of a test by generating the so-called mutants, i.e., variations of the production code that make it faulty and that the test is supposed to identify. However, previous studies revealed that mutation analysis is extremely costly and hard to use in practice. The approaches proposed by researchers so far have not been able to provide practical gains in terms of mutation testing efficiency. This leaves the problem of efficiently assessing test-case effectiveness as still open. In this paper, we investigate a novel, orthogonal, and lightweight methodology to assess test-case effectiveness: in particular, we study the feasibility to exploit production and test-code-quality indicators to estimate the mutation score of a test case. We first select a set of 67 factors and study their relation with test-case effectiveness. Then, we devise a mutation score estimation model exploiting such factors and investigate its performance as well as its most relevant features. The key results of the study reveal that our estimation model only based on static features has 86 percent of both F-Measure and AUC-ROC. This means that we can estimate the test-case effectiveness, using source-code-quality indicators, with high accuracy and without executing the tests. As a consequence, we can provide a practical approach that is beyond the typical limitations of current mutation testing techniques.",
        "keywords": [
            "Testing",
            "Production",
            "Estimation",
            "Measurement",
            "Predictive models",
            "Machine learning",
            "Computational modeling"
        ]
    },
    {
        "title": "A Layered Reference Architecture for Metamodels to Tailor Quality Modeling and Analysis.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2903797",
        "volume": "47",
        "abstract": "Nearly all facets of our everyday life strongly depend on software-intensive systems. Besides correctness, highly relevant quality properties of these systems include performance, as directly perceived by the user, and maintainability, as an important decision factor for evolution. These quality properties strongly depend on architectural design decisions. Hence, to ensure high quality, research and practice is interested in approaches to analyze the system architecture for quality properties. Therefore, models of the system architecture are created and used for analysis. Many different languages (often defined by metamodels) exist to model the systems and reason on their quality. Such languages are mostly specific to quality properties, tools or development paradigms. Unfortunately, the creation of a specific model for any quality property of interest and any different tool used is simply infeasible. Current metamodels for quality modeling and analysis are often not designed to be extensible and reusable. Experience from generalizing and extending metamodels result in hard to evolve and overly complex metamodels. A systematic way of creating, extending and reusing metamodels for quality modeling and analysis, or parts of them, does not exist yet. When comparing metamodels for different quality properties, however, substantial parts show quite similar language features. This leads to our approach to define the first reference architecture for metamodels for quality modeling and analysis. A reference architecture in software engineering provides a general architecture for a given application domain. In this paper, we investigate the applicability of modularization concepts from object-oriented design and the idea of a reference architecture to metamodels for quality modeling and analysis to systematically create, extend and reuse metamodel parts. Thus, the reference architecture allows to tailor metamodels. Requirements on the reference architecture are gathered from a historically grown metamodel. We specify modularization concepts as a foundation of the reference architecture. Detailed application guidelines are described. We argue the reference architecture supports instance compatibility and non-intrusive, independent extension of metamodels. In four case studies, we refactor historically grown metamodels and compare them to the original metamodels. The study results show the reference architecture significantly improves evolvability as well as need-specific use and reuse of metamodels.",
        "keywords": [
            "Computer architecture",
            "Object oriented modeling",
            "Analytical models",
            "Biological system modeling",
            "Tools",
            "Software",
            "Systematics"
        ]
    },
    {
        "title": "Studying Task Processes for Improving Programmer Productivity.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2904230",
        "volume": "47",
        "abstract": "Productivity of a software development organization can be enhanced by improving the software process, using better tools/technology, and enhancing the productivity of programmers. This work focuses on improving programmer productivity by studying the process used by a programmer for executing an assigned task, which we call the task process. We propose a general framework for studying the impact of task processes on programmer productivity and also the impact of transferring task processes of high-productivity programmers to average-productivity peers. We applied the framework to a few live projects in Robert Bosch Engineering and Business Solutions Limited, a CMMI Level 5 company. In each project, we identified two groups of programmers: high-productivity and average-productivity programmers. We requested each programmer to video capture their computer screen while executing his/her assigned tasks. We then analyzed these task videos to extract the task processes and then used them to identify the differences between the task processes used by the two groups. Some key differences were found between the task processes, which could account for the difference in productivities of the two groups. Similarities between the task processes were also analyzed quantitatively by modeling each task process as a Markov chain. We found that programmers from the same group used similar task processes, but the task processes of the two groups differed considerably. The task processes of high-productivity programmers were transferred to the average-productivity programmers by training them on the key steps missing in their process but commonly present in the work of their high-productivity peers. A substantial productivity gain was found in the average-productivity programmers as a result of this transfer. The study shows that task processes of programmers impact their productivity, and it is possible to improve the productivity of average-productivity programmers by transferring task processes from high-productivity programmers to them.",
        "keywords": [
            "Task analysis",
            "Productivity",
            "Software",
            "Companies",
            "Markov processes"
        ]
    },
    {
        "title": "Dealing with Non-Functional Requirements in Model-Driven Development: A Survey.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2904476",
        "volume": "47",
        "abstract": "Context: Managing Non-Functional Requirements (NFRs) in software projects is challenging, and projects that adopt Model-Driven Development (MDD) are no exception. Although several methods and techniques have been proposed to face this challenge, there is still little evidence on how NFRs are handled in MDD by practitioners. Knowing more about the state of the practice may help researchers to steer their research and practitioners to improve their daily work. Objective: In this paper, we present our findings from an interview-based survey conducted with practitioners working in 18 different companies from 6 European countries. From a practitioner's point of view, the paper shows what barriers and benefits the management of NFRs as part of the MDD process can bring to companies, how NFRs are supported by MDD approaches, and which strategies are followed when (some) types of NFRs are not supported by MDD approaches. Results: Our study shows that practitioners perceive MDD adoption as a complex process with little to no tool support for NFRs, reporting productivity and maintainability as the types of NFRs expected to be supported when MDD is adopted. But in general, companies adapt MDD to deal with NFRs. When NFRs are not supported, the generated code is sometimes changed manually, thus compromising the maintainability of the software developed. However, the interviewed practitioners claim that the benefits of using MDD outweight the extra effort required by these manual adaptations. Conclusion: Overall, the results indicate that it is important for practitioners to handle `NFRs in MDD, but further research is necessary in order to lower the barrier for supporting a broad spectrum of NFRs with MDD. Still, much conceptual and tool implementation work seems to be necessary to lower the barrier of integrating the broad spectrum of NFRs in practice.",
        "keywords": [
            "Unified modeling language",
            "Software",
            "Companies",
            "Productivity",
            "Software engineering",
            "Security",
            "Analytical models"
        ]
    },
    {
        "title": "Software Development Process Ambidexterity and Project Performance: A Coordination Cost-Effectiveness View.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2904571",
        "volume": "47",
        "abstract": "Software development process ambidexterity (SDPA) is the ability to demonstrate both process alignment and process adaptability simultaneously. Realizing process ambidexterity has recently been suggested as an effective approach to improving the performance of software development (SD) projects. To understand the mechanisms underlying the effects of ambidexterity, we focus in this study on the mediating effects of coordination, one of the most important activity in SD projects. Specifically, we hypothesize a mediating effect of coordination costs and coordination effectiveness on the relationship between SDPA and project performance. We conducted a quantitative study involving 104 SD projects across 10 firms to test the model. The results strongly suggest that the positive relationship between SDPA and project performance is negatively mediated by coordination costs and positively mediated by coordination effectiveness. We validate our research model with a case study in an organization employing several hundred IT professionals and derive several practical implications on this basis.",
        "keywords": [
            "Software",
            "Organizations",
            "Technological innovation",
            "Information systems",
            "Sensors",
            "Software engineering"
        ]
    },
    {
        "title": "An Empirical Study of Obsolete Answers on Stack Overflow.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2906315",
        "volume": "47",
        "abstract": "Stack Overflow accumulates an enormous amount of software engineering knowledge. However, as time passes, certain knowledge in answers may become obsolete. Such obsolete answers, if not identified or documented clearly, may mislead answer seekers and cause unexpected problems (e.g., using an out-dated security protocol). In this paper, we investigate how the knowledge in answers becomes obsolete and identify the characteristics of such obsolete answers. We find that: 1) More than half of the obsolete answers (58.4 percent) were probably already obsolete when they were first posted. 2) When an obsolete answer is observed, only a small proportion (20.5 percent) of such answers are ever updated. 3) Answers to questions in certain tags (e.g., node.js, ajax, android, and objective-c) are more likely to become obsolete. Our findings suggest that Stack Overflow should develop mechanisms to encourage the whole community to maintain answers (to avoid obsolete answers) and answer seekers are encouraged to carefully go through all information (e.g., comments) in answer threads.",
        "keywords": [
            "Aging",
            "Knowledge engineering",
            "Message systems",
            "Google",
            "Computer languages",
            "Software engineering",
            "Security"
        ]
    },
    {
        "title": "Today Was a Good Day: The Daily Life of Software Developers.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2904957",
        "volume": "47",
        "abstract": "What is a good workday for a software developer? What is a typical workday? We seek to answer these two questions to learn how to make good days typical. Concretely, answering these questions will help to optimize development processes and select tools that increase job satisfaction and productivity. Our work adds to a large body of research on how software developers spend their time. We report the results from 5,971 responses of professional developers at Microsoft, who reflected about what made their workdays good and typical, and self-reported about how they spent their time on various activities at work. We developed conceptual frameworks to help define and characterize developer workdays from two new perspectives: good and typical. Our analysis confirms some findings in previous work, including the fact that developers actually spend little time on development and developers' aversion for meetings and interruptions. It also discovered new findings, such as that only 1.7 percent of survey responses mentioned emails as a reason for a bad workday, and that meetings and interruptions are only unproductive during development phases; during phases of planning, specification and release, they are common and constructive. One key finding is the importance of agency, developers' control over their workday and whether it goes as planned or is disrupted by external factors. We present actionable recommendations for researchers and managers to prioritize process and tool improvements that make good workdays typical. For instance, in light of our finding on the importance of agency, we recommend that, where possible, managers empower developers to choose their tools and tasks.",
        "keywords": [
            "Software",
            "Productivity",
            "Task analysis",
            "Encoding",
            "Tools",
            "Collaboration",
            "Birds"
        ]
    },
    {
        "title": "Adaptive Test Case Allocation, Selection and Generation Using Coverage Spectrum and Operational Profile.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2906187",
        "volume": "47",
        "abstract": "We present an adaptive software testing strategy for test case allocation, selection and generation, based on the combined use of operational profile and coverage spectrum, aimed at achieving high delivered reliability of the program under test. Operational profile-based testing is a black-box technique considered well suited when reliability is a major concern, as it selects the test cases having the largest impact on failure probability in operation. Coverage spectrum is a characterization of a program's behavior in terms of the code entities (e.g., branches, statements, functions) that are covered as the program executes. The proposed strategy - named covrel+ - complements operational profile information with white-box coverage measures, so as to adaptively select/generate the most effective test cases for improving reliability as testing proceeds. We assess covrel+ through experiments with subjects commonly used in software testing research, comparing results with traditional operational testing. The results show that exploiting operational and coverage data in an integrated adaptive way allows generally to outperform operational testing at achieving a given reliability target, or at detecting faults under the same testing budget, and that covrel+ has greater ability than operational testing in detecting hard-to-detect faults.",
        "keywords": [
            "Software reliability",
            "Resource management",
            "Software testing",
            "Subspace constraints",
            "Test pattern generators"
        ]
    },
    {
        "title": "Interlocking Safety Cases for Unmanned Autonomous Systems in Shared Airspaces.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2907595",
        "volume": "47",
        "abstract": "The growing adoption of unmanned aerial vehicles (UAVs) for tasks such as eCommerce, aerial surveillance, and environmental monitoring introduces the need for new safety mechanisms in an increasingly cluttered airspace. In our work we thus emphasize safety issues that emerge at the intersection of infrastructures responsible for controlling the airspace, and the diverse UAVs operating in their space. We build on safety assurance cases (SAC) - a state-of-the-art solution for reasoning about safety - and propose a novel approach based on interlocking SACs. The infrastructure safety case (ISAC) specifies assumptions upon UAV behavior, while each UAV demonstrates compliance to the ISAC by presenting its own (pluggable) safety case (pSAC) which connects to the ISAC through a set of interlock points. To collect information on each UAV we enforce a “trust but monitor” policy, supported by runtime monitoring and an underlying reputation model. We evaluate our approach in three ways: first by developing ISACs for two UAV infrastructures, second by running simulations to evaluate end-to-end effectiveness, and finally via an outdoor field-study with physical UAVs. The results show that interlocking SACs can be effective for identifying, specifying, and monitoring safety-related constraints upon UAVs flying in a controlled airspace.",
        "keywords": [
            "Safety",
            "Unmanned aerial vehicles",
            "Monitoring",
            "Runtime",
            "Software",
            "Atmospheric modeling",
            "NASA"
        ]
    },
    {
        "title": "Modeling and Recommending Open Source Licenses with findOSSLicense.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2909021",
        "volume": "47",
        "abstract": "Open source software is widely used in the software industry and the academia. Licenses applied to open source software provide the terms for its further use and distribution. Decisions regarding licensing for new software systems are essential for the system's future use. In this paper, we introduce findOSSLicense, a license recommender that guides users into choosing the appropriate open source license for their software under creation. We also introduce our license modeling concept that is used in the recommendation process. The license modeling captures the properties usually found in existing open source licenses following an analysis performed on license texts. The recommendation process of findOSSLicense is based on a hybrid recommender that uses constraint-based, content-based and collaborative filtering giving also space for flexibility in the use of the system by its end-users who can adapt some system properties. User input, but also external sources of information including existing open source projects, are considered for the creation of the recommendations, whereas licenses used in third party software employed in the software are examined on a limited basis. findOSSLicense has been evaluated with the participation of users of various expertise.",
        "keywords": [
            "Licenses",
            "Task analysis",
            "Encoding",
            "Analytical models",
            "Open source software",
            "Law"
        ]
    },
    {
        "title": "Requirements Framing Affects Design Creativity.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2909033",
        "volume": "47",
        "abstract": "Design creativity, the originality and practicality of a solution concept, is critical for the success of many software projects. However, little research has investigated the relationship between the way desiderata are presented and design creativity. This study therefore investigates the impact of presenting desiderata as ideas, requirements or prioritized requirements on design creativity. Two between-subjects randomized controlled experiments were conducted with 42 and 34 participants. Participants were asked to create design concepts from a list of desiderata. Participants who received desiderata framed as requirements or prioritized requirements created designs that are, on average, less original but more practical than the designs created by participants who received desiderata framed as ideas. This suggests that more formal, structured presentations of desiderata are less appropriate where more innovative solutions are desired. The results also show that design performance is highly susceptible to minor changes in the vernacular used to communicate desiderata.",
        "keywords": [
            "Creativity",
            "Software",
            "Task analysis",
            "Requirements engineering",
            "Random access memory",
            "Ferroelectric films",
            "Nonvolatile memory"
        ]
    },
    {
        "title": "Reusing Solutions Modulo Theories.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2898199",
        "volume": "47",
        "abstract": "In this paper we propose an approach for reusing formula solutions to reduce the impact of Satisfiability Modulo Theories (SMT) solvers on the scalability of symbolic program analysis. SMT solvers can efficiently handle huge expressions in relevant logic theories, but they still represent a main bottleneck to the scalability of symbolic analyses, like symbolic execution and symbolic model checking. Reusing proofs of formulas solved during former analysis sessions can reduce the amount of invocations of SMT solvers, thus mitigating the impact of SMT solvers on symbolic program analysis. Early approaches to reuse formula solutions exploit equivalence and inclusion relations among structurally similar formulas, and are strongly tighten to the specific target logics. In this paper, we present an original approach that reuses both satisfiability and unsatisfiability proofs shared among many formulas beyond only equivalent or related-by-implication formulas. Our approach straightforwardly generalises across multiple logics. It is based on the original concept of distance between formulas, which heuristically approximates the likelihood of formulas to share either satisfiability or unsatisfiability proofs. We show the efficiency and the generalisability of our approach, by instantiating the underlying distance function for formulas that belong to most popular logic theories handled by current SMT solvers, and confirm the effectiveness of the approach, by reporting experimental results on over nine millions formulas from five logic theories.",
        "keywords": [
            "Scalability",
            "Software engineering",
            "Prototypes",
            "Terminology",
            "Model checking",
            "Indexes"
        ]
    },
    {
        "title": "Characterizing the Usage, Evolution and Impact of Java Annotations in Practice.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2910516",
        "volume": "47",
        "abstract": "Annotations have been formally introduced into Java since Java 5. Since then, annotations have been widely used by the Java community for different purposes, such as compiler guidance and runtime processing. Despite the ever-growing use, there is still limited empirical knowledge about the actual usage of annotations in practice, the changes made to annotations during software evolution, and the potential impact of annotations on code quality. To fill this gap, we perform the first large-scale empirical study about Java annotations on 1,094 notable open-source projects hosted on GitHub. Our study systematically investigates annotation usage, annotation evolution, and annotation impact, and generates 10 novel and important findings. We also present the implications of our findings, which shed light for developers, researchers, tool builders, and language or library designers in order to improve all facets of Java annotation engineering.",
        "keywords": [
            "Annotations",
            "Java",
            "Tools",
            "Libraries",
            "Runtime",
            "Open source software"
        ]
    },
    {
        "title": "Service Candidate Identification from Monolithic Systems Based on Execution Traces.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2910531",
        "volume": "47",
        "abstract": "Monolithic systems increasingly suffer from maintainability and scalability issues as they grow in functionality, size, and complexity. It is widely believed that (micro)service-based architectures can alleviate these problems as each service is supposed to have the following characteristics: clearly defined functionality, sufficient modularity, and the ability to evolve independently. Industrial practices show that service extraction from a legacy monolithic system is labor-intensive and complex. Existing work on service candidate identification aims to group entities of a monolithic system into potential service candidates, but this process has two major challenges: first, it is difficult to extract service candidates with consistent quality; second, it is hard to evaluate the identified service candidates regarding the above three characteristics. To address these challenges, this paper proposes the Functionality-oriented Service Candidate Identification (FoSCI) framework to identify service candidates from a monolithic system. Our approach is to record the monolith's execution traces, and extract services candidates using a search-based functional atom grouping algorithm. We also contribute a comprehensive service candidate evaluation suite that uses interface information, structural/conceptual dependency, and commit history. This evaluation system consists of 8 metrics, measuring functionality, modularity, and evolvability respectively of identified service candidates. We compare FoSCI with three existing methods, using 6 widely-used open-source projects as our evaluation subjects. Our results show that FoSCI outperforms existing methods in most measures.",
        "keywords": [
            "Software",
            "Atomic measurements",
            "Frequency measurement",
            "Testing",
            "Computer architecture",
            "History"
        ]
    },
    {
        "title": "Architecture Anti-Patterns: Automatically Detectable Violations of Design Principles.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2910856",
        "volume": "47",
        "abstract": "In large-scale software systems, error-prone or change-prone files rarely stand alone. They are typically architecturally connected and their connections usually exhibit architecture problems causing the propagation of error-proneness or change-proneness. In this paper, we propose and empirically validate a suite of architecture anti-patterns that occur in all large-scale software systems and are involved in high maintenance costs. We define these architecture anti-patterns based on fundamental design principles and Baldwin and Clark's design rule theory. We can automatically detect these anti-patterns by analyzing a project's structural relationships and revision history. Through our analyses of 19 large-scale software projects, we demonstrate that these architecture anti-patterns have significant impact on files' bug-proneness and change-proneness. In particular, we show that 1) files involved in these architecture anti-patterns are more error-prone and change-prone; 2) the more anti-patterns a file is involved in, the more error-prone and change-prone it is; and 3) while all of our defined architecture anti-patterns contribute to file's error-proneness and change-proneness, Unstable Interface and Crossing contribute the most by far.",
        "keywords": [
            "Computer architecture",
            "Maintenance engineering",
            "History",
            "Software systems",
            "Tools",
            "Observers",
            "Java"
        ]
    },
    {
        "title": "$\\mathcal K$K-Branching UIO Sequences for Partially Specified Observable Non-Deterministic FSMs.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2911076",
        "volume": "47",
        "abstract": "In black-box testing, test sequences may be constructed from systems modelled as deterministic finite-state machines (DFSMs) or, more generally, observable non-deterministic finite state machines (ONFSMs). Test sequences usually contain state identification sequences, with unique input output sequences (\n<small>UIOs</small>\n) often being used with DFSMs. This paper extends the notion of \n<small>UIOs</small>\n to ONFSMs. One challenge is that, as a result of non-determinism, the application of an input sequence can lead to exponentially many expected output sequences. To address this scalability problem, we introduce \n<inline-formula><tex-math notation=\"LaTeX\">${\\mathcal K}$</tex-math></inline-formula>\n-\n<small>UIOs</small>\n: \n<small>UIOs</small>\n that lead to at most \n<inline-formula><tex-math notation=\"LaTeX\">${\\mathcal K}$</tex-math></inline-formula>\n output sequences from states of \n<inline-formula><tex-math notation=\"LaTeX\">$M$</tex-math></inline-formula>\n. We show that checking \n<inline-formula><tex-math notation=\"LaTeX\">${\\mathcal K}$</tex-math></inline-formula>\n-\n<small>UIO</small>\n existence is PSPACE-Complete if the problem is suitably bounded; otherwise it is in EXPSPACE and PSPACE-Hard. We provide a massively parallel algorithm for constructing \n<inline-formula><tex-math notation=\"LaTeX\">${\\mathcal K}$</tex-math></inline-formula>\n-\n<small>UIOs</small>\n and the results of experiments on randomly generated and real FSM specifications. The proposed algorithm was able to construct \n<small>UIOs</small>\n in cases where the existing \n<small>UIO</small>\n generation algorithm could not and was able to construct \n<small>UIOs</small>\n from FSMs with 38K states and 400K transitions.",
        "keywords": [
            "Testing",
            "Object oriented modeling",
            "Software algorithms",
            "Software",
            "Integrated circuit modeling",
            "Scalability",
            "Parallel algorithms"
        ]
    },
    {
        "title": "The Impact of Code Review on Architectural Changes.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2912113",
        "volume": "47",
        "abstract": "Although considered one of the most important decisions in the software development lifecycle, empirical evidence on how developers perform and perceive architectural changes remains scarce. Architectural decisions have far-reaching consequences yet, we know relatively little about the level of developers' awareness of their changes' impact on the software's architecture. We also know little about whether architecture-related discussions between developers lead to better architectural changes. To provide a better understanding of these questions, we use the code review data from 7 open source systems to investigate developers' intent and awareness when performing changes alongside the evolution of the changes during the reviewing process. We extracted the code base of 18,400 reviews and 51,889 revisions. 4,171 of the reviews have changes in their computed architectural metrics, and 731 present significant changes to the architecture. We manually inspected all reviews that caused significant changes and found that developers are discussing the impact of their changes on the architectural structure in only 31% of the cases, suggesting a lack of awareness. Moreover, we noticed that in 73% of the cases in which developers provided architectural feedback during code review, the comments were addressed, where the final merged revision tended to exhibit higher architectural improvement than reviews in which the system's structure is not discussed.",
        "keywords": [
            "Computer architecture",
            "Couplings",
            "Software systems",
            "Measurement",
            "Software architecture",
            "Agriculture",
            "Java"
        ]
    },
    {
        "title": "The Mutation and Injection Framework: Evaluating Clone Detection Tools with Mutation Analysis.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2912962",
        "volume": "47",
        "abstract": "An abundant number of clone detection tools have been proposed in the literature due to the many applications and benefits of clone detection. However, there has been difficulty in the performance evaluation and comparison of these clone detectors. This is due to a lack of reliable benchmarks, and the manual efforts required to validate a large number of candidate clones. In particular, there has been a lack of a synthetic benchmark that can precisely and comprehensively measure clone-detection recall. In this paper, we present a mutation-analysis based benchmarking framework that can be used not only to evaluate the recall of clone detection tools for different types of clones but also for specific kinds of clone edits and without any manual efforts. The framework uses an editing taxonomy of clone synthesis for generating thousands of artificial clones, injects into code bases and automatically evaluates the subject clone detection tools following the mutation analysis approach. Additionally, the framework has features where custom clone pairs could also be used in the framework for evaluating the subject tools. This gives the opportunity of evaluating specialized tools for specialized contexts such as evaluating a tool's capability for the detection of complex Type-4 clones or real world clones without writing complex mutation operators for them. We demonstrate this framework by evaluating the performance of ten modern clone detection tools across two clone granularities (function and block) and three programming languages (Java, C and C#). Furthermore, we provide a variant of the framework that can be used to evaluate specialized tools such as for large gaped clone detection. Our experiments demonstrate confidence in the accuracy of our Mutation and Injection Framework when comparing against the expected results of the corresponding tools, and widely used real-world benchmarks such as Bellon's benchmark and BigCloneBench. We provide features so that most clone detection tools that report clones in the form of clone pairs (either in filename/line numbers or filename/tokens) could be evaluated using the framework.",
        "keywords": [
            "Cloning",
            "Tools",
            "Benchmark testing",
            "Software systems",
            "Detectors",
            "Atmospheric measurements",
            "Particle measurements"
        ]
    },
    {
        "title": "Erratum to \"Accurate and Scalable Cross-Architecture Cross-OS Binary Code Search With Emulation\".",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2021.3069529",
        "volume": "47",
        "abstract": "Presents corrections to author information for the above named paper.",
        "keywords": [
            "Emulation",
            "Binary codes"
        ]
    },
    {
        "title": "An Empirical Study of Boosting Spectrum-Based Fault Localization via PageRank.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2911283",
        "volume": "47",
        "abstract": "Manual debugging is notoriously tedious and time-consuming. Therefore, various automated fault localization techniques have been proposed to help with manual debugging. Among the existing fault localization techniques, spectrum-based fault localization (SBFL) is one of the most widely studied techniques due to being lightweight. The focus of the existing SBFL techniques is to consider how to differentiate program entities (i.e., one dimension in program spectra); indeed, this focus is aligned with the ultimate goal of finding the faulty lines of code. Our key insight is to enhance the existing SBFL techniques by additionally considering how to differentiate tests (i.e., the other dimension in program spectra), which, to the best of our knowledge, has not been studied in prior work. We present our basic approach, PRFL, a lightweight technique that boosts SBFL by differentiating tests using PageRank algorithm. Specifically, given the original program spectrum information, PRFL uses PageRank to recompute the spectrum by considering the contributions of different tests. Next, traditional SBFL techniques are applied on the recomputed spectrum to achieve more effective fault localization. On top of PRFL, we explore PRFL+ and PRFL\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">MA</sub>\n, two variants which extend PRFL by optimizing its components and integrating Method-level Aggregation technique, respectively. Though being simple and lightweight, PRFL has been demonstrated to outperform state-of-the-art SBFL techniques significantly (e.g., ranking 39.2% / 82.3% more real/artificial faults at Top-1 compared with the most effective traditional SBFL technique) with low overhead (e.g., around 6 minutes average extra overhead on real faults) on 395 real faults from 6 Defects4J projects and 96925 artificial (i.e., mutation) faults from 240 GitHub projects. To further validate PRFL's effectiveness, we compare PRFL with multiple recent proposed fault localization techniques (e.g., Multric, Metallaxis and MBFL-hybrid-avg), and the experimental results show that PRFL outperforms them as well. Furthermore, we study the performance of PRFL\n<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">MA</sub>\n, and the experimental results present it can locate 137 real faults (73.4% / 24.5% more compared with the most effective SBFL/PRFL technique) and 35058 artificial faults (159.6% / 28.1% more than SBFL/PRFL technique) at Top-1. At last, we study the generalizability of PRFL on another benchmark, Bugs.jar, and the result shows PRFL can help locate around 30 percent more faults at Top 1.",
        "keywords": [
            "Debugging",
            "Benchmark testing",
            "Spectral analysis",
            "Java",
            "Boosting",
            "Manuals"
        ]
    },
    {
        "title": "Efficient Parametric Model Checking Using Domain Knowledge.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2912958",
        "volume": "47",
        "abstract": "We introduce an efficient parametric model checking (ePMC) method for the analysis of reliability, performance and other quality-of-service (QoS) properties of software systems. ePMC speeds up the analysis of parametric Markov chains modelling the behaviour of software by exploiting domain-specific modelling patterns for the software components (e.g., patterns modelling the invocation of functionally-equivalent services used to jointly implement the same operation within service-based systems, or the deployment of the components of multi-tier software systems across multiple servers). To this end, ePMC precomputes closed-form expressions for key QoS properties of such patterns, and uses these expressions in the analysis of whole-system models. To evaluate ePMC, we show that its application to service-based systems and multi-tier software architectures reduces the analysis time by several orders of magnitude compared to current parametric model checking methods.",
        "keywords": [
            "Markov processes",
            "Quality of service",
            "Analytical models",
            "Unified modeling language",
            "Software",
            "Probabilistic logic",
            "Parametric statistics"
        ]
    },
    {
        "title": "Evolution of the Unix System Architecture: An Exploratory Case Study.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2892149",
        "volume": "47",
        "abstract": "Unix has evolved for almost five decades, shaping modern operating systems, key software technologies, and development practices. Studying the evolution of this remarkable system from an architectural perspective can provide insights on how to manage the growth of large, complex, and long-lived software systems. Along main Unix releases leading to the FreeBSD lineage we examine core architectural design decisions, the number of features, and code complexity, based on the analysis of source code, reference documentation, and related publications. We report that the growth in size has been uniform, with some notable outliers, while cyclomatic complexity has been religiously safeguarded. A large number of Unix-defining design decisions were implemented right from the very early beginning, with most of them still playing a major role. Unix continues to evolve from an architectural perspective, but the rate of architectural innovation has slowed down over the system's lifetime. Architectural technical debt has accrued in the forms of functionality duplication and unused facilities, but in terms of cyclomatic complexity it is systematically being paid back through what appears to be a self-correcting process. Some unsung architectural forces that shaped Unix are the emphasis on conventions over rigid enforcement, the drive for portability, a sophisticated ecosystem of other operating systems and development organizations, and the emergence of a federated architecture, often through the adoption of third-party subsystems. These findings have led us to form an initial theory on the architecture evolution of large, complex operating system software.",
        "keywords": [
            "Computer architecture",
            "Complexity theory",
            "Evolution (biology)",
            "Linux",
            "Kernel"
        ]
    },
    {
        "title": "Metamorphic Robustness Testing: Exposing Hidden Defects in Citation Statistics and Journal Impact Factors.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2915065",
        "volume": "47",
        "abstract": "We propose a robustness testing approach for software systems that process large amounts of data. Our method uses metamorphic relations to check software output for erroneous input in the absence of a tangible test oracle. We use this technique to test two major citation database systems: Scopus and the Web of Science. We report a surprising finding that the inclusion of hyphens in paper titles impedes citation counts, and that this is a result of the lack of robustness of the citation database systems in handling hyphenated paper titles. Our results are valid for the entire literature as well as for individual fields such as chemistry. We further find a strong and significant negative correlation between the journal impact factor (JIF) of IEEE Transactions on Software Engineering (TSE) and the percentage of hyphenated paper titles published in TSE. Similar results are found for ACM Transactions on Software Engineering and Methodology. A software engineering field-wide study reveals that the higher JIF-ranked journals are publishing a lower percentage of papers with hyphenated titles. Our results challenge the common belief that citation counts and JIFs are reliable measures of the impact of papers and journals, as they can be distorted simply by the presence of hyphens in paper titles.",
        "keywords": [
            "Robustness",
            "Database systems",
            "Software",
            "Fuzzing",
            "Google"
        ]
    },
    {
        "title": "Debugging of Behavioural Models using Counterexample Analysis.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2915303",
        "volume": "47",
        "abstract": "Model checking is an established technique for automatically verifying that a model satisfies a given temporal property. When the model violates the property, the model checker returns a counterexample, which is a sequence of actions leading to a state where the property is not satisfied. Understanding this counterexample for debugging the specification is a complicated task for several reasons: (i) the counterexample can contain a large number of actions, (ii) the debugging task is mostly achieved manually, and (iii) the counterexample does not explicitly highlight the source of the bug that is hidden in the model. This article presents a new approach that improves the usability of model checking by simplifying the comprehension of counterexamples. To do so, we first extract in the model all the counterexamples. Second, we define an analysis algorithm that identifies actions that make the model skip from incorrect to correct behaviours, making these actions relevant from a debugging perspective. Third, we develop a set of abstraction techniques to extract these actions from counterexamples. Our approach is fully automated by a tool we implemented and was applied on real-world case studies from various application areas for evaluation purposes.",
        "keywords": [
            "Computer bugs",
            "Debugging",
            "Safety",
            "Model checking",
            "Task analysis",
            "Tools",
            "Analytical models"
        ]
    },
    {
        "title": "Recommending Participants for Collaborative Merge Sessions.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2917191",
        "volume": "47",
        "abstract": "Development of large projects often involves parallel work performed in multiple branches. Eventually, these branches need to be reintegrated through a merge operation. During merge, conflicts may arise and developers need to communicate to reach consensus about the desired resolution. For this reason, including the right developers to a collaborative merge session is fundamental. However, this task can be difficult especially when many different developers have made significant changes on each branch over a large number of files. In this paper, we present TIPMerge, an approach designed to recommend participants for collaborative merge sessions. TIPMerge analyzes the project history and builds a ranked list of developers who are the most appropriate to integrate a pair of branches (Developer Ranking) by considering developers' changes in the branches, in the previous history, and in the dependencies among files across branches. Simply selecting the top developers in such a ranking is easy, but is not effective for collaborative merge sessions as the top developers may have overlapping knowledge. To support collaborative merge, TIPMerge employs optimization techniques to recommend developers with complementary knowledge (Team Recommendation) aiming to maximize joint knowledge coverage. Our results show a mean normalized improvement of 49.5% (median 50.4%) for the joint knowledge coverage with the optimization techniques for assembling teams of three developers for collaborative merge in comparison to choosing the top-3 developers in the ranked list.",
        "keywords": [
            "Collaboration",
            "History",
            "Optimization",
            "Data mining",
            "Merging",
            "Task analysis",
            "Software"
        ]
    },
    {
        "title": "The ORIS Tool: Quantitative Evaluation of Non-Markovian Systems.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2917202",
        "volume": "47",
        "abstract": "We present the next generation of ORIS, a toolbox for quantitative evaluation of concurrent models with non-Markovian timers. The tool shifts its focus from timed models to stochastic ones, it includes a new graphical user interface, new analysis methods and a Java Application Programming Interface (API). Models can be specified as Stochastic Time Petri Nets (STPNs) through the graphical editor, validated using an interactive token game, and analyzed through several techniques to compute instantaneous or cumulative rewards. STPNs can also be exported as Java code to conduct extensive parametric studies through the Java library, now distributed as open-source. A well-engineered software architecture allows the user to implement new features for STPNs, new modeling formalisms, and new analysis methods. The most distinctive features of ORIS include transient and steady-state analysis of STPNs modeling Markov Regenerative Processes (MRPs), and transient analysis of STPNs modeling generalized semi-Markov processes. ORIS also supports state-space analysis of Time Petri Nets (TPNs), simulation of STPNs, and standard analysis techniques for continuous-time Markov chains or MRPs with at most one non-exponential timer in each state. We illustrate the general workflow for the application of ORIS to the modeling and evaluation of non-functional requirements of software-intensive systems.",
        "keywords": [
            "Analytical models",
            "Stochastic processes",
            "Transient analysis",
            "Java",
            "Petri nets",
            "Numerical models",
            "Graphical user interfaces"
        ]
    },
    {
        "title": "What Do Package Dependencies Tell Us About Semantic Versioning?",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2918315",
        "volume": "47",
        "abstract": "The semantic versioning (\n<b xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">semver</b>\n) policy is commonly accepted by open source package management systems to inform whether new releases of software packages introduce possibly backward incompatible changes. Maintainers depending on such packages can use this information to avoid or reduce the risk of breaking changes in their own packages by specifying version constraints on their dependencies. Depending on the amount of control a package maintainer desires to have over her package dependencies, these constraints can range from very permissive to very restrictive. This article empirically compares \n<b xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">semver</b>\n compliance of four software packaging ecosystems (Cargo, npm, Packagist and Rubygems), and studies how this compliance evolves over time. We explore to what extent ecosystem-specific characteristics or policies influence the degree of compliance. We also propose an evaluation based on the “wisdom of the crowds” principle to help package maintainers decide which type of version constraints they should impose on their dependencies.",
        "keywords": [
            "Ecosystems",
            "Software",
            "Semantics",
            "Packaging",
            "Libraries",
            "Java",
            "Computer bugs"
        ]
    },
    {
        "title": "A Semantics-Based Hybrid Approach on Binary Code Similarity Comparison.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2918326",
        "volume": "47",
        "abstract": "Binary code similarity comparison is a methodology for identifying similar or identical code fragments in binary programs. It is indispensable in fields of software engineering and security, which has many important applications (e.g., plagiarism detection, bug detection). With the widespread of smart and Internet of Things (IoT) devices, an increasing number of programs are ported to multiple architectures (e.g., ARM, MIPS). It becomes necessary to detect similar binary code across architectures as well. The main challenge of this topic lies in the semantics-equivalent code transformation resulting from different compilation settings, code obfuscation, and varied instruction set architectures. Another challenge is the trade-off between comparison accuracy and coverage. Unfortunately, existing methods still heavily rely on semantics-less code features which are susceptible to the code transformation. Additionally, they perform the comparison merely either in a static or in a dynamic manner, which cannot achieve high accuracy and coverage simultaneously. In this paper, we propose a semantics-based hybrid method to compare binary function similarity. We execute the reference function with test cases, then emulate the execution of every target function with the runtime information migrated from the reference function. Semantic signatures are extracted during the execution as well as the emulation. Lastly, similarity scores are calculated from the signatures to measure the likeness of functions. We have implemented the method in a prototype system designated as BinMatch which performs binary code similarity comparison across architectures of x86, ARM and MIPS on the Linux platform. We evaluate BinMatch with nine real-word projects compiled with different compilation settings, on variant architectures, and with commonly-used obfuscation methods, totally performing over 100 million pairs of function comparison. The experimental results show that BinMatch is resilient to the semantics-equivalent code transformation. Besides, it not only covers all target functions for similarity comparison, but also improves the accuracy comparing to the state-of-the-art solutions.",
        "keywords": [
            "Binary codes",
            "Semantics",
            "Computer architecture",
            "Runtime",
            "Computer science",
            "Feature extraction",
            "Internet of Things"
        ]
    },
    {
        "title": "Characterizing Crowds to Better Optimize Worker Recommendation in Crowdsourced Testing.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2918520",
        "volume": "47",
        "abstract": "Crowdsourced testing is an emerging trend, in which test tasks are entrusted to the online crowd workers. Typically, a crowdsourced test task aims to detect as many bugs as possible within a limited budget. However not all crowd workers are equally skilled at finding bugs; Inappropriate workers may miss bugs, or report duplicate bugs, while hiring them requires nontrivial budget. Therefore, it is of great value to recommend a set of appropriate crowd workers for a test task so that more software bugs can be detected with fewer workers. This paper first presents a new characterization of crowd workers and characterizes them with testing context, capability, and domain knowledge. Based on the characterization, we then propose Multi-Objective Crowd wOrker recoMmendation approach (MOCOM), which aims at recommending a minimum number of crowd workers who could detect the maximum number of bugs for a crowdsourced testing task. Specifically, MOCOM recommends crowd workers by maximizing the bug detection probability of workers, the relevance with the test task, the diversity of workers, and minimizing the test cost. We experimentally evaluate MOCOM on 532 test tasks, and results show that MOCOM significantly outperforms five commonly-used and state-of-the-art baselines. Furthermore, MOCOM can reduce duplicate reports and recommend workers with high relevance and larger bug detection probability; because of this it can find more bugs with fewer workers.",
        "keywords": [
            "Task analysis",
            "Computer bugs",
            "Testing",
            "Software",
            "Videos",
            "Software engineering",
            "Optimization"
        ]
    },
    {
        "title": "A Large Scale Study of Long-Time Contributor Prediction for GitHub Projects.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2918536",
        "volume": "47",
        "abstract": "The continuous contributions made by long time contributors (LTCs) are a key factor enabling open source software (OSS) projects to be successful and survival. We study Github as it has a large number of OSS projects and millions of contributors, which enables the study of the transition from newcomers to LTCs. In this paper, we investigate whether we can effectively predict newcomers in OSS projects to be LTCs based on their activity data that is collected from Github. We collect Github data from GHTorrent, a mirror of Github data. We select the most popular 917 projects, which contain 75,046 contributors. We determine a developer as a LTC of a project if the time interval between his/her first and last commit in the project is larger than a certain time \n<i xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">T</i>\n. In our experiment, we use three different settings on the time interval: 1, 2, and 3 years. There are 9,238, 3,968, and 1,577 contributors who become LTCs of a project in three settings of time interval, respectively. To build a prediction model, we extract many features from the activities of developers on Github, which group into five dimensions: developer profile, repository profile, developer monthly activity, repository monthly activity, and collaboration network. We apply several classifiers including naive Bayes, SVM, decision tree, kNN and random forest. We find that random forest classifier achieves the best performance with AUCs of more than 0.75 in all three settings of time interval for LTCs. We also investigate the most important features that differentiate newcomers who become LTCs from newcomers who stay in the projects for a short time. We find that the number of followers is the most important feature in all three settings of the time interval studied. We also find that the programming language and the average number of commits contributed by other developers when a newcomer joins a project also belong to the top 10 most important features in all three settings of time interval for LTCs. Finally, we provide several implications for action based on our analysis results to help OSS projects retain newcomers.",
        "keywords": [
            "Predictive models",
            "Feature extraction",
            "Computer languages",
            "Task analysis",
            "Computer bugs",
            "Mirrors"
        ]
    },
    {
        "title": "Enriching API Documentation with Code Samples and Usage Scenarios from Crowd Knowledge.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2919304",
        "volume": "47",
        "abstract": "As one key resource to learn Application Programming Interfaces (APIs), a lot of API reference documentation lacks code samples with usage scenarios, thus heavily hindering developers from programming with APIs. Although researchers have investigated how to enrich API documentation with code samples from general code search engines, two main challenges remain to be resolved, including the quality challenge of acquiring high-quality code samples and the mapping challenge of matching code samples to usage scenarios. In this study, we propose a novel approach named ADECK towards enriching API documentation with code samples and corresponding usage scenarios by leveraging crowd knowledge from Stack Overflow, a popular technical Question and Answer (Q&A) website attracting millions of developers. Given an API related Q&A pair, a code sample in the answer is extensively evaluated by developers and targeted towards resolving the question under the specified usage scenario. Hence, ADECK can obtain high-quality code samples and map them to corresponding usage scenarios to address the above challenges. Extensive experiments on the Java SE and Android API documentation show that the number of code-sample-illustrated API types in the ADECK-enriched API documentation is 3.35 and 5.76 times as many as that in the raw API documentation. Meanwhile, the quality of code samples obtained by ADECK is better than that of code samples by the baseline approach eXoaDocs in terms of correctness, conciseness, and usability, e.g., the average correctness values of representative code samples obtained by ADECK and eXoaDocs are 4.26 and 3.28 on a 5-point scale in the enriched Java SE API documentation. In addition, an empirical study investigating the impacts of different types of API documentation on the productivity of developers shows that, compared against the raw and the eXoaDocs-enriched API documentation, the ADECK-enriched API documentation can help developers complete 23.81 and 14.29 percent more programming tasks and reduce the average completion time by 9.43 and 11.03 percent.",
        "keywords": [
            "Documentation",
            "Programming",
            "Java",
            "Knowledge engineering",
            "Search engines",
            "Productivity",
            "Task analysis"
        ]
    },
    {
        "title": "A Controlled Experiment with Novice Developers on the Impact of Task Description Granularity on Software Quality in Test-Driven Development.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2920377",
        "volume": "47",
        "abstract": "Background: Test-Driven Development (TDD) is an iterative software development process characterized by test-code-refactor cycle. TDD recommends that developers work on small and manageable tasks at each iteration. However, the ability to break tasks into small work items effectively is a learned skill that improves with experience. In experimental studies of TDD, the granularity of task descriptions is an overlooked factor. In particular, providing a more granular task description in terms of a set of sub-tasks versus providing a coarser-grained, generic description. Objective: We aim to investigate the impact of task description granularity on the outcome of TDD, as implemented by novice developers, with respect to software quality, as measured by functional correctness and functional completeness. Method: We conducted a one-factor crossover experiment with 48 graduate students in an academic environment. Each participant applied TDD and implemented two tasks, where one of the tasks was presented using a more granular task description. Resulting artifacts were evaluated with acceptance tests to assess functional correctness and functional completeness. Linear mixed-effects models (LMM) were used for analysis. Results: Software quality improved significantly when participants applied TDD using more granular task descriptions. The effect of task description granularity is statistically significant and had a medium to large effect size. Moreover, the task was found to be a significant predictor of software quality which is an interesting result (because two tasks used in the experiment were considered to be of similar complexity). Conclusion: For novice TDD practitioners, the outcome of TDD is highly coupled with the ability to break down the task into smaller parts. For researchers, task selection and task description granularity requires more attention in the design of TDD experiments. Task description granularity should be taken into account in secondary studies. Further comparative studies are needed to investigate whether task descriptions affect other development processes similarly.",
        "keywords": [
            "Task analysis",
            "Software quality",
            "Productivity",
            "Process control",
            "Atmospheric measurements",
            "Particle measurements"
        ]
    },
    {
        "title": "What Do Programmers Discuss About Blockchain? A Case Study on the Use of Balanced LDA and the Reference Architecture of a Domain to Capture Online Discussions About Blockchain Platforms Across Stack Exchange Communities.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2921343",
        "volume": "47",
        "abstract": "Blockchain-related discussions have become increasingly prevalent in programming Q&A websites, such as Stack Overflow and other Stack Exchange communities. Analyzing and understanding those discussions could provide insights about the topics of interest to practitioners, and help the software development and research communities better understand the needs and challenges facing developers as they work in this new domain. Prior studies propose the use of LDA to study the Stack Exchange discussions. However, a simplistic use of LDA would capture the topics in discussions blindly without keeping in mind the variety of the dataset and domain-specific concepts. Specifically, LDA is biased towards larger sized corpora; and LDA-derived topics are not linked to higher level domain-specific concepts. We propose an approach that combines balanced LDA (which ensures that the topics are balanced across a domain) with the reference architecture of a domain to capture and compare the popularity and impact of discussion topics across the Stack Exchange communities. Popularity measures the distribution of interest in discussions, and impact gauges the trend of popularity over time. We made a number of interesting observations, including: (1) Bitcoin, Ethereum, Hyperledger Fabric and Corda are the four most commonly-discussed blockchain platforms on the Stack Exchange communities. (2) A broad range of topics are discussed across the various platforms of distinct layers in our derived reference architecture. (3) The Application layer topics exhibit the highest popularity (33.2 percent) and fastest growth in topic impact since November 2015. (4) The Application, API, Consensus and Network layer topics are discussed across the studied blockchain platforms, but exhibit different distributions in popularity. (5) The impact of architectural layer topics exhibits an upward trend, but is growing at different speeds across the studied blockchain platforms. The breakdown of the topic impact across the architectural layers is relatively stable over time except for the Hyperledger Fabric platform. Based on our findings, we highlighted future directions and provided recommendations for practitioners and researchers.",
        "keywords": [
            "Blockchain",
            "Peer-to-peer computing",
            "Computer architecture",
            "Smart contracts",
            "Programming",
            "Bitcoin"
        ]
    },
    {
        "title": "An Integration Test Order Strategy to Consider Control Coupling.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2921965",
        "volume": "47",
        "abstract": "Integration testing is a very important step in software testing. Existing methods evaluate the stubbing cost for class integration test orders by considering only the interclass direct relationships such as inheritance, aggregation, and association, but they omit the interclass indirect relationship caused by control coupling, which can also affect the test orders and the stubbing cost. In this paper, we introduce an integration test order strategy to consider control coupling. We advance the concept of transitive relationship to describe this kind of interclass dependency and propose a new measurement method to estimate the complexity of control coupling, which is the complexity of stubs created for a transitive relationship. We evaluate our integration test order strategy on 10 programs on various scales. The results show that considering the transitive relationship when generating class integration test orders can significantly reduce the stubbing cost for most programs and that our integration test order strategy obtains satisfactory results more quickly than other methods.",
        "keywords": [
            "Couplings",
            "Complexity theory",
            "Measurement",
            "Marine vehicles",
            "Mathematical model",
            "Software testing"
        ]
    },
    {
        "title": "Deep Transfer Bug Localization.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2920771",
        "volume": "47",
        "abstract": "Many projects often receive more bug reports than what they can handle. To help debug and close bug reports, a number of bug localization techniques have been proposed. These techniques analyze a bug report and return a ranked list of potentially buggy source code files. Recent development on bug localization has resulted in the construction of effective supervised approaches that use historical data of manually localized bugs to boost performance. Unfortunately, as highlighted by Zimmermann et al., sufficient bug data is often unavailable for many projects and companies. This raises the need for cross-project bug localization - the use of data from a project to help locate bugs in another project. To fill this need, we propose a deep transfer learning approach for cross-project bug localization. Our proposed approach named TRANP-CNN extracts transferable semantic features from source project and fully exploits labeled data from target project for effective cross-project bug localization. We have evaluated TRANP-CNN on curated high-quality bug datasets and our experimental results show that TRANP-CNN can locate buggy files correctly at top 1, top 5, and top 10 positions for 29.9, 51.7, 61.3 percent of the bugs respectively, which significantly outperform state-of-the-art bug localization solution based on deep learning and several other advanced alternative solutions considering various standard evaluation metrics.",
        "keywords": [
            "Computer bugs",
            "Feature extraction",
            "Task analysis",
            "Encoding",
            "Computer languages",
            "Semantics",
            "Data models"
        ]
    },
    {
        "title": "On Company Contributions to Community Open Source Software Projects.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2919305",
        "volume": "47",
        "abstract": "The majority of contributions to community open source software (OSS) projects are made by practitioners acting on behalf of companies and other organisations. Previous research has addressed the motivations of both individuals and companies to engage with OSS projects. However, limited research has been undertaken that examines and explains the practical mechanisms or work practices used by companies and their developers to pursue their commercial and technical objectives when engaging with OSS projects. This research investigates the variety of work practices used in public communication channels by company contributors to engage with and contribute to eight community OSS projects. Through interviews with contributors to the eight projects we draw on their experiences and insights to explore the motivations to use particular methods of contribution. We find that companies utilise work practices for contributing to community projects which are congruent with the circumstances and their capabilities that support their short- and long-term needs. We also find that companies contribute to community OSS projects in ways that may not always be apparent from public sources, such as employing core project developers, making donations, and joining project steering committees in order to advance strategic interests. The factors influencing contributor work practices can be complex and are often dynamic arising from considerations such as company and project structure, as well as technical concerns and commercial strategies. The business context in which software created by the OSS project is deployed is also found to influence contributor work practices.",
        "keywords": [
            "Companies",
            "Software",
            "Technological innovation",
            "Collaboration",
            "Interviews",
            "Licenses"
        ]
    },
    {
        "title": "Locating Latent Design Information in Developer Discussions: A Study on Pull Requests.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2924006",
        "volume": "47",
        "abstract": "A software system's design determines many of its properties, such as maintainability and performance. An understanding of design is needed to maintain system properties as changes to the system occur. Unfortunately, many systems do not have up-to-date design documentation and approaches that have been developed to recover design often focus on how a system works by extracting structural and behaviour information rather than information about the desired design properties, such as robustness or performance. In this paper, we explore whether it is possible to automatically locate where design is discussed in on-line developer discussions. We investigate and introduce a classifier that can locate paragraphs in pull request discussions that pertain to design with an average AUC score of 0.87. We show that this classifier, when applied to projects on which it was not trained, agrees with the identification of design points by humans with an average AUC score of 0.79. We describe how this classifier could be used as the basis of tools to improve such tasks as reviewing code and implementing new features.",
        "keywords": [
            "System analysis and design",
            "Tools",
            "Documentation",
            "Robustness",
            "Predictive models",
            "Software systems"
        ]
    },
    {
        "title": "Impact of Discretization Noise of the Dependent Variable on Machine Learning Classifiers in Software Engineering.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2924371",
        "volume": "47",
        "abstract": "Researchers usually discretize a continuous dependent variable into two target classes by introducing an artificial discretization threshold (e.g., median). However, such discretization may introduce noise (i.e., discretization noise) due to ambiguous class loyalty of data points that are close to the artificial threshold. Previous studies do not provide a clear directive on the impact of discretization noise on the classifiers and how to handle such noise. In this paper, we propose a framework to help researchers and practitioners systematically estimate the impact of discretization noise on classifiers in terms of its impact on various performance measures and the interpretation of classifiers. Through a case study of 7 software engineering datasets, we find that: 1) discretization noise affects the different performance measures of a classifier differently for different datasets; 2) Though the interpretation of the classifiers are impacted by the discretization noise on the whole, the top 3 most important features are not affected by the discretization noise. Therefore, we suggest that practitioners and researchers use our framework to understand the impact of discretization noise on the performance of their built classifiers and estimate the exact amount of discretization noise to be discarded from the dataset to avoid the negative impact of such noise.",
        "keywords": [
            "Software engineering",
            "Computer bugs",
            "Noise measurement",
            "Software",
            "Machine learning",
            "Regression tree analysis",
            "Logistics"
        ]
    },
    {
        "title": "Reactive Auto-Completion of Modeling Activities.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2924886",
        "volume": "47",
        "abstract": "Assisting and automating software engineering tasks is a state-of-the-art way to support stakeholders of development projects. A common assistance function of IDEs is the auto-completion of source code. Assistance functions, such as auto-completion, are almost entirely missing in modeling tools though auto-completion in general gains continuously more importance in software development. We analyze a user’s performed editing operations in order to anticipate modeling activities and to recommend appropriate auto-completions for them. Editing operations are captured as events and modeling activities are defined as complex event patterns, facilitating the matching by complex-event-processing. The approach provides adapted auto-completions reactively upon each editing operation of the user. We implemented the \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">RapMOD</i>\n prototype as add-in for the modeling tool Sparx Enterprise Architect™ . A controlled user experiment with 37 participants performing modeling tasks demonstrated the approach’s potential to reduce modeling effort significantly. Users having auto-completions available for a modeling scenario performed the task 27 percent faster, needed to perform 56 percent less actions, and perceived the task 29 percent less difficult.",
        "keywords": [
            "Unified modeling language",
            "Tools",
            "Task analysis",
            "Computational modeling",
            "Adaptation models",
            "Analytical models",
            "Engines"
        ]
    },
    {
        "title": "What's Wrong with My Benchmark Results? Studying Bad Practices in JMH Benchmarks.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2925345",
        "volume": "47",
        "abstract": "Microbenchmarking frameworks, such as Java's Microbenchmark Harness (JMH), allow developers to write fine-grained performance test suites at the method or statement level. However, due to the complexities of the Java Virtual Machine, developers often struggle with writing expressive JMH benchmarks which accurately represent the performance of such methods or statements. In this paper, we empirically study bad practices of JMH benchmarks. We present a tool that leverages static analysis to identify 5 bad JMH practices. Our empirical study of 123 open source Java-based systems shows that each of these 5 bad practices are prevalent in open source software. Further, we conduct several experiments to quantify the impact of each bad practice in multiple case studies, and find that bad practices often significantly impact the benchmark results. To validate our experimental results, we constructed seven patches that fix the identified bad practices for six of the studied open source projects, of which six were merged into the main branch of the project. In this paper, we show that developers struggle with accurate Java microbenchmarking, and provide several recommendations to developers of microbenchmarking frameworks on how to improve future versions of their framework.",
        "keywords": [
            "Benchmark testing",
            "Java",
            "Optimization",
            "Tools",
            "Writing",
            "Static analysis"
        ]
    },
    {
        "title": "Empirical Assessment of Multimorphic Testing.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2926971",
        "volume": "47",
        "abstract": "The performance of software systems such as speed, memory usage, correct identification rate, tends to be an evermore important concern, often nowadays on par with functional correctness for critical systems. Systematically testing these performance concerns is however extremely difficult, in particular because there exists no theory underpinning the evaluation of a performance test suite, i.e., to tell the software developer whether such a test suite is ”good enough” or even whether a test suite is better than another one. This paper proposes to apply Multimorphic testing and empirically assess the effectiveness of performance test suites of software systems coming from various domains. By analogy with mutation testing, our core idea is to leverage the typical configurability of these systems, and to check whether it makes any difference in the outcome of the tests: i.e., are some tests able to “kill” underperforming system configurations? More precisely, we propose a framework for defining and evaluating the coverage of a test suite with respect to a quantitative property of interest. Such properties can be the execution time, the memory usage or the success rate in tasks performed by a software system. This framework can be used to assess whether a new test case is worth adding to a test suite or to select an optimal test suite with respect to a property of interest. We evaluate several aspects of our proposal through 3 empirical studies carried out in different fields: object tracking in videos, object recognition in images, and code generators.",
        "keywords": [
            "Testing",
            "Software measurement",
            "Software systems",
            "Videos",
            "Task analysis",
            "Generators"
        ]
    },
    {
        "title": "Stability in Software Engineering: Survey of the State-of-the-Art and Research Directions.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2925616",
        "volume": "47",
        "abstract": "With the increasing dependence on software systems, their longevity is becoming a pressing need. Stability is envisioned as a primary property to achieve longevity. Stability has been defined and treated in many different ways in the literature. We conduct a systematic literature review to analyse the state-of-the-art related to stability as a software property. We formulate a taxonomy for characterising the notion, analyse the definitions found in the literature, and present research studies dealing with stability. Also, as architecture is one of the software artefacts with profound effects throughout the software lifecycle, we focus on software engineering practices for realising architectural stability. The analysis results show a wide variation in dimensions when dealing with stability. The state-of-the-art indicates the need for a shift towards a multi-dimensional concept that could cope with runtime dynamics and emerging software paradigms. More research efforts should be directed toward the identified gaps. The presented taxonomy and analysis of the literature aim to help the research community in consolidating the existing research efforts and deriving future developments.",
        "keywords": [
            "Stability criteria",
            "Software engineering",
            "Computer architecture",
            "Software systems",
            "Taxonomy"
        ]
    },
    {
        "title": "Methodological Principles for Reproducible Performance Evaluation in Cloud Computing.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2927908",
        "volume": "47",
        "abstract": "The rapid adoption and the diversification of cloud computing technology exacerbate the importance of a sound experimental methodology for this domain. This work investigates how to measure and report performance in the cloud, and how well the cloud research community is already doing it. We propose a set of eight important methodological principles that combine best-practices from nearby fields with concepts applicable only to clouds, and with new ideas about the time-accuracy trade-off. We show how these principles are applicable using a practical use-case experiment. To this end, we analyze the ability of the newly released SPEC Cloud IaaS benchmark to follow the principles, and showcase real-world experimental studies in common cloud environments that meet the principles. Last, we report on a systematic literature review including top conferences and journals in the field, from 2012 to 2017, analyzing if the practice of reporting cloud performance measurements follows the proposed eight principles. Worryingly, this systematic survey and the subsequent two-round human reviews, reveal that few of the published studies follow the eight experimental principles. We conclude that, although these important principles are simple and basic, the cloud community is yet to adopt them broadly to deliver sound measurement of cloud environments.",
        "keywords": [
            "Cloud computing",
            "Performance evaluation",
            "Benchmark testing",
            "Systematics",
            "Computer performance",
            "Software engineering"
        ]
    },
    {
        "title": "Evolving JavaScript Code to Reduce Load Time.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2928293",
        "volume": "47",
        "abstract": "JavaScript is one of the most used programming languages for front-end development of Web applications. The increase in complexity of front-end features brings concerns about performance, especially the load and execution time of JavaScript code. In this paper, we propose an evolutionary program improvement technique to reduce the size of JavaScript programs and, therefore, the time required to load and execute them in Web applications. To guide the development of this technique, we performed an experimental study to characterize the patches applied to JavaScript programs to reduce their size while keeping the functionality required to pass all test cases in their test suites. We applied this technique to 19 JavaScript programs varying from 92 to 15,602 LOC and observed reductions from 0.2 to 73.8 percent of the original code, as well as a relationship between the quality of a program's test suite and the ability to reduce the size of its source code.",
        "keywords": [
            "Software",
            "Syntactics",
            "Genetic programming",
            "Software algorithms",
            "Heuristic algorithms",
            "Libraries",
            "Runtime"
        ]
    },
    {
        "title": "The Impact of Mislabeled Changes by SZZ on Just-in-Time Defect Prediction.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2929761",
        "volume": "47",
        "abstract": "Just-in-Time (JIT) defect prediction-a technique which aims to predict bugs at change level-has been paid more attention. JIT defect prediction leverages the SZZ approach to identify bug-introducing changes. Recently, researchers found that the performance of SZZ (including its variants) is impacted by a large amount of noise. SZZ may considerably mislabel changes that are used to train a JIT defect prediction model, and thus impact the prediction accuracy. In this paper, we investigate the impact of the mislabeled changes by different SZZ variants on the performance and interpretation of JIT defect prediction models. We analyze four SZZ variants (i.e., B-SZZ, AG-SZZ, MA-SZZ, and RA-SZZ) that are proposed by prior studies. We build the prediction models using the labeled data by these four SZZ variants. Among the four SZZ variants, RA-SZZ is least likely to generate mislabeled changes, and we construct the testing set by using RA-SZZ. All of the four prediction models are then evaluated on the same testing set. We choose the prediction model built on the labeled data by RA-SZZ as the baseline model, and we compare the performance and metric importance of the models trained using the labeled data by the other three SZZ variants with the baseline model. Through a large-scale empirical study on a total of 126,526 changes from ten Apache open source projects, we find that in terms of various performance measures (AUC, F1-score, G-mean and Recall@20%), the mislabeled changes by B-SZZ and MA-SZZ are not likely to cause a considerable performance reduction, while the mislabeled changes by AG-SZZ cause a statistically significant performance reduction with an average difference of 1-5 percent. When considering developers' inspection effort (measured by LOC) in practice, the changes mislabeled B-SZZ and AG-SZZ lead to 9-10 and 1-15 percent more wasted inspection effort, respectively. And the mislabeled changes by B-SZZ lead to significantly more wasted effort. The mislabeled changes by MA-SZZ do not cause considerably more wasted effort. We also find that the top-most important metric for identifying bug-introducing changes (i.e., number of files modified in a change) is robust to the mislabeling noise generated by SZZ. But the second- and third-most important metrics are more likely to be impacted by the mislabeling noise, unless random forest is used as the underlying classifier.",
        "keywords": [
            "Predictive models",
            "Data models",
            "Computer bugs",
            "Measurement",
            "Inspection",
            "Analytical models",
            "Testing"
        ]
    },
    {
        "title": "Exploiting Natural Language Structures in Software Informal Documentation.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2930519",
        "volume": "47",
        "abstract": "Communication means, such as issue trackers, mailing lists, Q&A forums, and app reviews, are premier means of collaboration among developers, and between developers and end-users. Analyzing such sources of information is crucial to build recommenders for developers, for example suggesting experts, re-documenting source code, or transforming user feedback in maintenance and evolution strategies for developers. To ease this analysis, in previous work we proposed Development Emails Content Analyzer (DECA), a tool based on Natural Language Parsing that classifies with high precision development emails' fragments according to their purpose. However, DECA has to be trained through a manual tagging of relevant patterns, which is often effort-intensive, error-prone and requires specific expertise in natural language parsing. In this paper, we first show, with an empirical study, the extent to which producing rules for identifying such patterns requires effort, depending on the nature and complexity of patterns. Then, we propose an approach, named Nlp-based softwarE dOcumentation aNalyzer (NEON), that automatically mines such rules, minimizing the manual effort. We assess the performances of NEON in the analysis and classification of mobile app reviews, developers discussions, and issues. NEON simplifies the patterns identification and rules definition processes, allowing a savings of more than 70 percent of the time otherwise spent on performing such activities manually. Results also show that NEON-generated rules are close to the manually identified ones, achieving comparable recall.",
        "keywords": [
            "Neon",
            "Software",
            "Linguistics",
            "Pattern recognition",
            "Documentation",
            "Manuals"
        ]
    },
    {
        "title": "Empirical Evaluation of Fault Localisation Using Code and Change Metrics.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2930977",
        "volume": "47",
        "abstract": "Fault localisation aims to reduce the debugging efforts of human developers by highlighting the program elements that are suspected to be the root cause of the observed failure. Spectrum Based Fault Localisation (SBFL), a coverage based approach, has been widely studied in many researches as a promising localisation technique. Recently, however, it has been proven that SBFL techniques have reached the limit of further improvement. To overcome the limitation, we extend SBFL with code and change metrics that have been mainly studied in defect prediction, such as size, age, and churn. FLUCCS, our fault learn-to-rank localisation technique, employs both existing SBFL formulæ and these metrics as input. We investigate the effect of employing code and change metrics for fault localisation using four different learn-to-rank techniques: Genetic Programming, Gaussian Process Modelling, Support Vector Machine, and Random Forest. We evaluate the performance of FLUCCS with 386 real world faults collected from Defects4J repository. The results show that FLUCCS with code and change metrics places 144 faults at the top and 304 faults within the top ten. This is a significant improvement over the state-of-art SBFL formulæ, which can locate 65 and 212 faults at the top and within the top ten, respectively. We also investigate the feasibility of cross-project transfer learning of fault localisation. The results show that, while there exist project-specific properties that can be exploited for better localisation per project, ranking models learnt from one project can be applied to others without significant loss of effectiveness.",
        "keywords": [
            "Measurement",
            "Debugging",
            "Genetic programming",
            "Feature extraction",
            "Support vector machines",
            "Training"
        ]
    },
    {
        "title": "Finding Substitutable Binary Code By Synthesizing Adapters.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2931000",
        "volume": "47",
        "abstract": "Independently developed codebases typically contain many segments of code that perform same or closely related operations (semantic clones). Finding functionally equivalent segments enables applications like replacing a segment by a more efficient or more secure alternative. Such related segments often have different interfaces, so some glue code (an adapter) is needed to replace one with the other. In previous work, we presented an algorithm that searches for replaceable code segments by attempting to synthesize an adapter between them from some finite family of adapters; it terminates if it finds no possible adapter. In this work, we compare binary symbolic execution-based adapter search with concrete adapter enumeration based on Intel's Pin framework, and explore the relation between size of adapter search space and total search time. We present examples of applying adapter synthesis for improving security of binary functions and switching between binary implementations of RC4. We present two large-scale evaluations: (1) we run adapter synthesis on more than 13,000 function pairs from the Linux C library, and (2) we reverse engineer fragments of ARM binary code by running more than a million adapter synthesis tasks. Our results confirm that several instances of adaptably equivalent binary functions exist in real-world code, and suggest that adapter synthesis can be applied for automatically replacing binary code with its adaptably equivalent variants.",
        "keywords": [
            "Tools",
            "Binary codes",
            "Libraries",
            "Security",
            "Task analysis",
            "Reverse engineering",
            "Computer science"
        ]
    },
    {
        "title": "Version Control Systems: An Information Foraging Perspective.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2931296",
        "volume": "47",
        "abstract": "Version Control Systems (VCS) are an important source of information for developers. This calls for a principled understanding of developers' information seeking in VCS-both for improving existing tools and for understanding requirements for new tools. Our prior work investigated empirically how and why developers seek information in VCS: in this paper, we complement and enrich our prior findings by reanalyzing the data via a theory's lens. Using the lens of Information Foraging Theory (IFT), we present new insights not revealed by the prior empirical work. First, while looking for specific information, participants' foraging behaviors were consistent with other foraging situations in SE; therefore, prior research on IFT-based SE tool design can be leveraged for VCS. Second, in change awareness foraging, participants consumed similar diets, but in subtly different ways than in other situations; this calls for further investigations into change awareness foraging. Third, while committing changes, participants attempted to enable future foragers, but the competing needs of different foraging situations led to tensions that participants failed to balance: this opens up a new avenue for research at the intersection of IFT and SE, namely, creating forageable information. Finally, the results of using an IFT lens on these data provides some evidence as to IFT's scoping and utility for the version control domain.",
        "keywords": [
            "Tools",
            "Control systems",
            "Software",
            "Software engineering",
            "Computer bugs",
            "Animals",
            "Lenses"
        ]
    },
    {
        "title": "ModGuard : Identifying Integrity & Confidentiality Violations in Java Modules.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2931331",
        "volume": "47",
        "abstract": "With version 9, Java has been given the new module system Jigsaw. Major goals were to simplify maintainability of the JDK and improve its security by encapsulating modules' internal types. While the module system successfully limits the visibility of internal types, it does not prevent sensitive data from escaping. Since the module system reasons about types only, objects are allowed to escape even if that module declares the type as internal. Finding such unintended escapes is important, as they may violate a module's integrity and confidentiality, but is a complex task as it requires one to reason about pointers and type hierarchy. We thus present ModGuard, a novel static analysis based on Doop which complements the Java module system with an analysis to automatically identify instances that escape their declaring module. Along with ModGuard we contribute a complete formal definition of a module's entrypoints, i.e., the method implementations that a module actually allows other modules to directly invoke. We further make available a novel micro-benchmark suite MIC9Bench to show the effectiveness but also current shortcomings of ModGuard, and to enable comparative studies in the future. Finally, we describe a case study that we conducted using Apache Tomcat, which shows that a migration of applications towards Jigsaw modules does not prevent sensitive instances from escaping, yet also shows that ModGuard is an effective aid in identifying integrity and confidentiality violations of sensitive instances.",
        "keywords": [
            "Java",
            "Security",
            "Cognition",
            "Static analysis",
            "Encapsulation",
            "Manuals",
            "Benchmark testing"
        ]
    },
    {
        "title": "Fine-Grained Dynamic Resource Allocation for Big-Data Applications.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2931537",
        "volume": "47",
        "abstract": "Many big-data applications are batch applications that exploit dedicated frameworks to perform massively parallel computations across clusters of machines. The time needed to process the entirety of the inputs represents the application's response time, which can be subject to deadlines. Spark, probably the most famous incarnation of these frameworks today, allocates resources to applications statically at the beginning of the execution and deviations are not managed: to meet the applications' deadlines, resources must be allocated carefully. This paper proposes an extension to Spark, called dynaSpark, that is able to allocate and redistribute resources to applications dynamically to meet deadlines and cope with the execution of unanticipated applications. This work is based on two key enablers: containers, to isolate Spark's parallel executors and allow for the dynamic and fast allocation of resources, and control-theory to govern resource allocation at runtime and obtain required precision and speed. Our evaluation shows that dynaSpark can (i) allocate resources efficiently to execute single applications with respect to set deadlines and (ii) reduce deadline violations (w.r.t. Spark) when executing multiple concurrent applications.",
        "keywords": [
            "Sparks",
            "Resource management",
            "Dynamic scheduling",
            "Containers",
            "Task analysis",
            "Runtime",
            "Control theory"
        ]
    },
    {
        "title": "Software Deployment on Heterogeneous Platforms: A Systematic Mapping Study.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2932665",
        "volume": "47",
        "abstract": "Context: Multiple types of processing units (e.g., CPUs, GPUs and FPGAs) can be used jointly to achieve better performance in computational systems. However, these units are built with fundamentally different characteristics and demand attention especially towards software deployment. Objective: The goal of this work is to summarize the state-of-the-art of software deployment on heterogeneous platforms. We provide an overview of the research area by searching for and categorizing relevant studies, as well as discussing gaps and trends of the field. We are interested in the main concerns (RQ1) and the approaches used (RQ2) when deploying software on heterogeneous platforms. Method: In order to achieve our goal, we performed a systematic mapping study, which refers to a method for reviewing literature with basis on predefined search strategies and a multi-step selection process. Results: We selected and analyzed 146 primary studies from multiple sources and found that the area of research is dominated by solution proposals. The majority of the studies discuss concerns about scheduling, the quality of the software, and its architecture. A large number of studies focuses on the problem of scheduling tasks and processes. We found approaches that are applied at different binding times (i.e., design time, runtime, orthogonal). Conclusion: The evaluation of the proposed solutions in an industrial context is missing. Also, the proposed methods have not been evaluated in development processes. Most of the methods address a particular concern, or a few concerns, while there is a lack of a holistic approach.",
        "keywords": [
            "Task analysis",
            "Program processors",
            "Systematics",
            "Heterogeneous networks",
            "Central Processing Unit",
            "Field programmable gate arrays"
        ]
    },
    {
        "title": "An Empirical Validation of Oracle Improvement.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2934409",
        "volume": "47",
        "abstract": "We propose a human-in-the-loop approach for oracle improvement and analyse whether the proposed oracle improvement process is helping developers to create better oracles. For this, we conducted two human studies with 68 participants overall: an oracle assessment study and an oracle improvement study. Our results show that developers exhibit poor performance (29 percent accuracy) when manually assessing whether an assertion oracle contains a false positive, a false negative or none of the two. This shows that automated detection of these oracle deficiencies is beneficial for the users. Our tool OASIs (Oracle ASsessment and Improvement) helps developers produce assertions with higher quality. Participants who used OASIs in the improvement study were able to achieve 33 percent of full and 67 percent of partial correctness as opposed to participants without the tool who achieved only 21 percent of full and 43 percent of partial correctness.",
        "keywords": [
            "Tools",
            "Standards",
            "Generators",
            "Indexes",
            "Software testing",
            "Software"
        ]
    },
    {
        "title": "A Cost-Efficient Auto-Scaling Algorithm for Large-Scale Graph Processing in Cloud Environments with Heterogeneous Resources.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2934849",
        "volume": "47",
        "abstract": "Graph processing model is being adopted extensively in various domains such as online gaming, social media, scientific computing and Internet of Things (IoT). Since general purpose data processing tools such as MapReduce are shown to be inefficient for iterative graph processing, many frameworks have been developed in recent years to facilitate analytics and computing of large-scale graphs. However, regardless of distributed or single machine based architecture of such frameworks, dynamic scalability is always a major concern. It becomes even more important when there is a correlation between scalability and monetary cost - similar to what public clouds provide. The pay-as-you-go model that is used by public cloud providers enables users to pay only for the number of resources they utilize. Nevertheless, processing large-scale graphs in such environments has been less studied and most frameworks are implemented for commodity clusters where they will not be charged for the resources that they consume. In this paper, we have developed algorithms to take advantage of resource heterogeneity in cloud environments. Using these algorithms, the system can automatically adjust the number and types of virtual machines according to the computation requirements for convergent graph applications to improve the performance and reduce the monetary cost of the entire operation. Also, a smart profiling mechanism along with a novel dynamic repartitioning approach helps to distribute graph partitions expeditiously. It is shown that this method outperforms popular frameworks such as Giraph and decreases more than 50 percent of the dollar cost compared to Giraph.",
        "keywords": [
            "Cloud computing",
            "Scalability",
            "Computational modeling",
            "Internet of Things",
            "Heuristic algorithms",
            "Software algorithms",
            "Clustering algorithms"
        ]
    },
    {
        "title": "A Procedure and Guidelines for Analyzing Groups of Software Engineering Replications.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2935720",
        "volume": "47",
        "abstract": "Context: Researchers from different groups and institutions are collaborating on building groups of experiments by means of replication (i.e., conducting groups of replications). Disparate aggregation techniques are being applied to analyze groups of replications. The application of unsuitable techniques to aggregate replication results may undermine the potential of groups of replications to provide in-depth insights from experiment results. Objectives: Provide an analysis procedure with a set of embedded guidelines to aggregate software engineering (SE) replication results. Method: We compare the characteristics of groups of replications for SE and other mature experimental disciplines such as medicine and pharmacology. In view of their differences, the limitations with regard to the joint data analysis of groups of SE replications and the guidelines provided in mature experimental disciplines to analyze groups of replications, we build an analysis procedure with a set of embedded guidelines specifically tailored to the analysis of groups of SE replications. We apply the proposed analysis procedure to a representative group of SE replications to illustrate its use. Results: All the information contained within the raw data should be leveraged during the aggregation of replication results. The analysis procedure that we propose encourages the use of stratified individual participant data and aggregated data in tandem to analyze groups of SE replications. Conclusion: The aggregation techniques used to analyze groups of replications should be justified in research articles. This will increase the reliability and transparency of joint results. The proposed guidelines should ease this endeavor.",
        "keywords": [
            "Guidelines",
            "Reliability",
            "Aggregates",
            "Buildings",
            "Data analysis",
            "Biological system modeling",
            "Software engineering"
        ]
    },
    {
        "title": "METRIC$^{+}$+: A Metamorphic Relation Identification Technique Based on Input Plus Output Domains.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2934848",
        "volume": "47",
        "abstract": "Metamorphic testing is well known for its ability to alleviate the oracle problem in software testing. The main idea ofmetamorphic testing is to test a software system by checking whether each identified metamorphic relation (MR) holds among severalexecutions. In this regard, identifying MRs is an essential task in metamorphic testing. In view of the importance of this identificationtask, METRIC (METamorphic Relation Identification based on Category-choice framework) was developed to help software testersidentify MRs from a given set of complete test frames. However, during MR identification, METRIC primarily focuses on the inputdomain without sufficient attention given to the output domain, thereby hindering the effectiveness of METRIC. Inspired by this problem,we have extended METRIC into METRIC\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n by incorporating the information derived from the output domain for MR identification. A toolimplementing METRIC\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n has also been developed. Two rounds of experiments, involving four real-life specifications, have beenconducted to evaluate the effectiveness and efficiency of METRIC\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n. The results have confirmed that METRIC\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n is highly effective andefficient in MR identification. Additional experiments have been performed to compare the fault detection capability of the MRsgenerated by METRIC\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n and those bymMT (another MR identification technique). The comparison results have confirmed that the MRsgenerated by METRIC\n<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">+</sup>\n are highly effective in fault detection.",
        "keywords": [
            "Measurement",
            "Testing",
            "Software systems",
            "Fault detection",
            "Task analysis",
            "Tools"
        ]
    },
    {
        "title": "Bayesian Data Analysis in Empirical Software Engineering Research.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2935974",
        "volume": "47",
        "abstract": "Statistics comes in two main flavors: frequentist and Bayesian. For historical and technical reasons, frequentist statistics have traditionally dominated empirical data analysis, and certainly remain prevalent in empirical software engineering. This situation is unfortunate because frequentist statistics suffer from a number of shortcomings-such as lack of flexibility and results that are unintuitive and hard to interpret-that curtail their effectiveness when dealing with the heterogeneous data that is increasingly available for empirical analysis of software engineering practice. In this paper, we pinpoint these shortcomings, and present Bayesian data analysis techniques that provide tangible benefits-as they can provide clearer results that are simultaneously robust and nuanced. After a short, high-level introduction to the basic tools of Bayesian statistics, we present the reanalysis of two empirical studies on the effectiveness of automatically generated tests and the performance of programming languages. By contrasting the original frequentist analyses with our new Bayesian analyses, we demonstrate the concrete advantages of the latter. To conclude we advocate a more prominent role for Bayesian statistical techniques in empirical software engineering research and practice.",
        "keywords": [
            "Bayes methods",
            "Software engineering",
            "Testing",
            "Data analysis",
            "Machine learning",
            "Statistical analysis",
            "Software"
        ]
    },
    {
        "title": "Deep Learning Based Code Smell Detection.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2936376",
        "volume": "47",
        "abstract": "Code smells are structures in the source code that suggest the possibility of refactorings. Consequently, developers may identify refactoring opportunities by detecting code smells. However, manual identification of code smells is challenging and tedious. To this end, a number of approaches have been proposed to identify code smells automatically or semi-automatically. Most of such approaches rely on manually designed heuristics to map manually selected source code metrics into predictions. However, it is challenging to manually select the best features. It is also difficult to manually construct the optimal heuristics. To this end, in this paper we propose a deep learning based novel approach to detecting code smells. The key insight is that deep neural networks and advanced deep learning techniques could automatically select features of source code for code smell detection, and could automatically build the complex mapping between such features and predictions. A big challenge for deep learning based smell detection is that deep learning often requires a large number of labeled training data (to tune a large number of parameters within the employed deep neural network) whereas existing datasets for code smell detection are rather small. To this end, we propose an automatic approach to generating labeled training data for the neural network based classifier, which does not require any human intervention. As an initial try, we apply the proposed approach to four common and well-known code smells, i.e., feature envy, long method, large class, and misplaced class. Evaluation results on open-source applications suggest that the proposed approach significantly improves the state-of-the-art.",
        "keywords": [
            "Software",
            "Deep learning",
            "Feature extraction",
            "Training data",
            "Neural networks",
            "Measurement"
        ]
    },
    {
        "title": "Moving from Closed to Open Source: Observations from Six Transitioned Projects to GitHub.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2937025",
        "volume": "47",
        "abstract": "Open source software systems have gained a lot of attention in the past few years. With the emergence of open source platforms like GitHub, developers can contribute, store, and manage their projects with ease. Large organizations like Microsoft, Google, and Facebook are open sourcing their in-house technologies in an effort to more broadly involve the community in the development of software systems. Although closed source and open source systems have been studied extensively, there has been little research on the transition from closed source to open source systems. Through this study we aim to: a) provide guidance and insights for other teams planning to open source their projects and b) to help them avoid pitfalls during the transition process. We studied six different Microsoft systems, which were recently open-sourced i.e., CoreFX, CoreCLR, Roslyn, Entity Framework, MVC, and Orleans. This paper presents the transition from the viewpoints of both Microsoft and the open source community based on interviews with eleven Microsoft developer, five Microsoft senior managers involved in the decision to open source, and eleven open-source developers. From Microsoft's perspective we discuss the reasons for the transition, experiences of developers involved, and the transition's outcomes and challenges. Our results show that building a vibrant community, prompt answers, developing an open source culture, security regulations and business opportunities are the factors which persuade companies to open source their products. We also discuss the transition outcomes on processes such as code reviews, version control systems, continuous integration as well as developers' perception of these changes. From the open source community's perspective, we illustrate the response to the open-sourcing initiative through contributions and interactions with the internal developers and provide guidelines for other projects planning to go open source.",
        "keywords": [
            "Interviews",
            "Encoding",
            "Planning",
            "Software systems",
            "Open source software",
            "Companies"
        ]
    },
    {
        "title": "How does Machine Learning Change Software Development Practices?",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2937083",
        "volume": "47",
        "abstract": "Adding an ability for a system to learn inherently adds uncertainty into the system. Given the rising popularity of incorporating machine learning into systems, we wondered how the addition alters software development practices. We performed a mixture of qualitative and quantitative studies with 14 interviewees and 342 survey respondents from 26 countries across four continents to elicit significant differences between the development of machine learning systems and the development of non-machine-learning systems. Our study uncovers significant differences in various aspects of software engineering (e.g., requirements, design, testing, and process) and work characteristics (e.g., skill variety, problem solving and task identity). Based on our findings, we highlight future research directions and provide recommendations for practitioners.",
        "keywords": [
            "Software",
            "Interviews",
            "Data models",
            "Machine learning",
            "Testing",
            "Task analysis",
            "Software engineering"
        ]
    },
    {
        "title": "Enabling Good Work Habits in Software Developers through Reflective Goal-Setting.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2938525",
        "volume": "47",
        "abstract": "Software developers are generally interested in developing better habits to increase their workplace productivity and well-being, but have difficulties identifying concrete goals and actionable strategies to do so. In several areas of life, such as the physical activity and health domain, self-reflection has been shown to be successful at increasing people's awareness about a problematic behavior, motivating them to define a self-improvement goal, and fostering goal-achievement. We therefore designed a reflective goal-setting study to learn more about developers' goals and strategies to improve or maintain good habits at work. In our study, 52 professional software developers self-reflected about their work on a daily basis during two to three weeks, which resulted in a rich set of work habit goals and actionable strategies that developers pursue at work. We also found that purposeful, continuous self-reflection not only increases developers' awareness about productive and unproductive work habits (84.5 percent), but also leads to positive self-improvements that increase developer productivity and well-being (79.6 percent). We discuss how tools could support developers with a better trade-off between the cost and value of workplace self-reflection and increase long-term engagement.",
        "keywords": [
            "Productivity",
            "Software",
            "Employment",
            "Task analysis",
            "Tools",
            "Informatics",
            "Monitoring"
        ]
    },
    {
        "title": "Kernel Spectral Embedding Transfer Ensemble for Heterogeneous Defect Prediction.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2939303",
        "volume": "47",
        "abstract": "Cross-project defect prediction (CPDP) refers to predicting defects in the target project lacking of defect data by using prediction models trained on the historical defect data of other projects (i.e., source data). However, CPDP requires the source and target projects have common metric set (CPDP-CM). Recently, heterogeneous defect prediction (HDP) has drawn the increasing attention, which predicts defects across projects having heterogeneous metric sets. However, building high-performance HDP methods remains a challenge owing to several serious challenges including class imbalance problem, nonlinear, and the distribution differences between source and target datasets. In this paper, we propose a novel kernel spectral embedding transfer ensemble (KSETE) approach for HDP. KSETE first addresses the class-imbalance problem of the source data and then tries to find the latent common feature space for the source and target datasets by combining kernel spectral embedding, transfer learning, and ensemble learning. Experiments are performed on 22 public projects in both HDP and CPDP-CM scenarios in terms of multiple well-known performance measures such as, AUC, G-Measure, and MCC. The experimental results show that (1) KSETE improves the performance over previous HDP methods by at least 22.7, 138.9, and 494.4 percent in terms of AUC, G-Measure, and MCC, respectively. (2) KSETE improves the performance over previous CPDP-CM methods by at least 4.5, 30.2, and 17.9 percent in AUC, G-Measure, and MCC, respectively. It can be concluded that the proposed KSETE is very effective in both the HDP scenario and the CPDP-CM scenario.",
        "keywords": [
            "Kernel",
            "Predictive models",
            "Software metrics",
            "Correlation",
            "Buildings",
            "Data models"
        ]
    },
    {
        "title": "ProXray: Protocol Model Learning and Guided Firmware Analysis.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2939526",
        "volume": "47",
        "abstract": "The number of Internet of Things (IoT) has reached 7 billion globally in early 2018 and are nearly ubiquitous in daily life. Knowing whether or not these devices are safe and secure to use is becoming critical. IoT devices usually implement communication protocols such as USB and Bluetooth within firmware to allow a wide range of functionality. Thus analyzing firmware using domain knowledge from these protocols is vital to understand device behavior, detect implementation bugs, and identify malicious components. Unfortunately, due to the complexity of these protocols, there is usually no formal specification available that can help automate the firmware analysis; as a result significant manual effort is currently required to study these protocols and to reverse engineer the device firmware. In this paper, we propose a new firmware analysis methodology using symbolic execution called ProXray, which can learn a protocol model from known firmware, and apply the model to recognize the protocol relevant fields and detect functionality within unknown firmware automatically. After the training phase, ProXray can fully automate the firmware analysis process while supporting user's queries in the form of protocol relevant constraints. We have applied ProXray to the USB and the Bluetooth protocols by learning protocol constraint models from firmware that implement these protocols. We are then able to map protocol fields and identify USB functionality automatically within all 6 unknown USB firmware while achieving more than an order of magnitude speedup in reaching protocol relevant targets in unknown Bluetooth firmware. Our model achieved high coverage of the USB and Bluetooth specifications for several important protocol fields. ProXray provides a new method to apply domain knowledge to firmware analysis automatically.",
        "keywords": [
            "Protocols",
            "Universal Serial Bus",
            "Bluetooth",
            "Hidden Markov models",
            "Analytical models",
            "Microprogramming",
            "Feature extraction"
        ]
    },
    {
        "title": "POMP++: Facilitating Postmortem Program Diagnosis with Value-Set Analysis.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2939528",
        "volume": "47",
        "abstract": "With the emergence of hardware-assisted processor tracing, execution traces can be logged with lower runtime overhead and integrated into the core dump. In comparison with an ordinary core dump, such a new post-crash artifact provides software developers and security analysts with more clues to a program crash. However, existing works only rely on the resolved runtime information, which leads to the limitation in data flow recovery within long execution traces. In this work, we propose POMP++, an automated tool to facilitate the analysis of post-crash artifacts. More specifically, POMP++ introduces a reverse execution mechanism to construct the data flow that a program followed prior to its crash. Furthermore, POMP++ utilizes Value-set Analysis, which helps to verify memory alias relation, to improve the ability of data flow recovery. With the restored data flow, POMP++ then performs backward taint analysis and highlights program statements that actually contribute to the crash. We have implemented POMP++ for Linux system on x86-32 platform, and tested it against various crashes resulting from 31 distinct real-world security vulnerabilities. The evaluation shows that, our work can pinpoint the root causes in 29 cases, increase the number of recovered memory addresses by 12 percent and reduce the execution time by 60 percent compared with existing reverse execution. In short, POMP++ can accurately and efficiently pinpoint program statements that truly contribute to the crashes, making failure diagnosis significantly convenient.",
        "keywords": [
            "Computer crashes",
            "Software",
            "Security",
            "Core dumps",
            "Registers",
            "Runtime",
            "Tools"
        ]
    },
    {
        "title": "SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2940179",
        "volume": "47",
        "abstract": "This paper presents a novel end-to-end approach to program repair based on sequence-to-sequence learning. We devise, implement, and evaluate a technique, called SequenceR, for fixing bugs based on sequence-to-sequence learning on source code. This approach uses the copy mechanism to overcome the unlimited vocabulary problem that occurs with big code. Our system is data-driven; we train it on 35,578 samples, carefully curated from commits to open-source repositories. We evaluate SequenceR on 4,711 independent real bug fixes, as well on the Defects4J benchmark used in program repair research. SequenceR is able to perfectly predict the fixed line for 950/4,711 testing samples, and find correct patches for 14 bugs in Defects4J benchmark. SequenceR captures a wide range of repair operators without any domain-specific top-down design.",
        "keywords": [
            "Maintenance engineering",
            "Computer bugs",
            "Vocabulary",
            "Training",
            "Natural languages",
            "Benchmark testing"
        ]
    },
    {
        "title": "SEthesaurus: WordNet in Software Engineering.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2940439",
        "volume": "47",
        "abstract": "Informal discussions on social platforms (e.g., Stack Overflow, CodeProject) have accumulated a large body of programming knowledge in the form of natural language text. Natural language process (NLP) techniques can be utilized to harvest this knowledge base for software engineering tasks. However, consistent vocabulary for a concept is essential to make an effective use of these NLP techniques. Unfortunately, the same concepts are often intentionally or accidentally mentioned in many different morphological forms (such as abbreviations, synonyms and misspellings) in informal discussions. Existing techniques to deal with such morphological forms are either designed for general English or mainly resort to domain-specific lexical rules. A thesaurus, which contains software-specific terms and commonly-used morphological forms, is desirable to perform normalization for software engineering text. However, constructing this thesaurus in a manual way is a challenge task. In this paper, we propose an automatic unsupervised approach to build such a thesaurus. In particular, we first identify software-specific terms by utilizing a software-specific corpus (e.g., Stack Overflow) and a general corpus (e.g., Wikipedia). Then we infer morphological forms of software-specific terms by combining distributed word semantics, domain-specific lexical rules and transformations. Finally, we perform graph analysis on morphological relations. We evaluate the coverage and accuracy of our constructed thesaurus against community-cumulated lists of software-specific terms, abbreviations and synonyms. We also manually examine the correctness of the identified abbreviations and synonyms in our thesaurus. We demonstrate the usefulness of our constructed thesaurus by developing three applications and also verify the generality of our approach in constructing thesauruses from data sources in other domains.",
        "keywords": [
            "Thesauri",
            "Software engineering",
            "Encyclopedias",
            "Electronic publishing",
            "Internet",
            "Natural language processing"
        ]
    },
    {
        "title": "Smart Greybox Fuzzing.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2941681",
        "volume": "47",
        "abstract": "Coverage-based greybox fuzzing (CGF) is one of the most successful approaches for automated vulnerability detection. Given a seed file (as a sequence of bits), a CGF randomly flips, deletes or copies some bits to generate new files. CGF iteratively constructs (and fuzzes) a seed corpus by retaining those generated files which enhance coverage. However, random bitflips are unlikely to produce valid files (or valid chunks in files), for applications processing complex file formats. In this work, we introduce smart greybox fuzzing (SGF) which leverages a high-level structural representation of the seed file to generate new files. We define innovative mutation operators that work on the virtual file structure rather than on the bit level which allows SGF to explore completely new input domains while maintaining file validity. We introduce a novel validity-based power schedule that enables SGF to spend more time generating files that are more likely to pass the parsing stage of the program, which can expose vulnerabilities much deeper in the processing logic. Our evaluation demonstrates the effectiveness of SGF. On several libraries that parse complex chunk-based files, our tool AFLsmart achieves substantially more branch coverage (up to 87 percent improvement) and exposes more vulnerabilities than baseline AFL. Our tool AFLsmart discovered 42 zero-day vulnerabilities in widely-used, well-tested tools and libraries; 22 CVEs were assigned.",
        "keywords": [
            "Fuzzing",
            "Computer bugs",
            "Libraries",
            "Tools",
            "Dictionaries",
            "Open area test sites",
            "Schedules"
        ]
    },
    {
        "title": "Studying the Impact of Noises in Build Breakage Data.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2941880",
        "volume": "47",
        "abstract": "Much research has investigated the common reasons for build breakages. However, prior research has paid little attention to builds that may break due to reasons that are unlikely to be related to development activities. For example, Continuous Integration (CI) builds may break due to timeout or connection errors while generating the build. Such kinds of build breakages potentially introduce noises to build breakage data. Not considering such noises may lead to misleading results when studying CI builds. In this paper, we propose three criteria to identify build breakages that can potentially introduce noises to build breakage data. We apply these criteria to a dataset of 350,246 builds from 153 GitHub projects that are linked with Travis CI. Our results reveal that 33 percent of the build breakages are due to environmental factors (e.g., errors in CI servers), 29 percent are due to (unfixed) errors in previous builds, and 9 percent are due to build jobs that were later deemed by developers as noisy (there is an overlap of 17 percent between these three types of breakages). We measure the impact of noises in build breakage data on modeling build breakages. We observe that models that use uncleaned build breakage data can lead to misleading associations between build breakages and development activities (e.g., the role of developer). However, such associations could not be observed after eliminating noisy build breakages. Moreover, we replicate a prior study that investigates the association between build breakages and development activities using data from 14 GitHub projects. We observe that some observations reported by the prior study (e.g., pull requests cause more breakages) do not hold after eliminating the noises from build breakage data.",
        "keywords": [
            "Noise measurement",
            "Data models",
            "Software",
            "Environmental factors",
            "Servers",
            "Indexes"
        ]
    },
    {
        "title": "Which Variables Should I Log?",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2941943",
        "volume": "47",
        "abstract": "Developers usually depend on inserting logging statements into the source code to collect system runtime information. Such logged information is valuable for software maintenance. A logging statement usually prints one or more variables to record vital system status. However, due to the lack of rigorous logging guidance and the requirement of domain-specific knowledge, it is not easy for developers to make proper decisions about which variables to log. To address this need, in this work, we propose an approach to recommend logging variables for developers during development by learning from existing logging statements. Different from other prediction tasks in software engineering, this task has two challenges: 1) Dynamic labels - different logging statements have different sets of accessible variables, which means in this task, the set of possible labels of each sample is not the same. 2) Out-of-vocabulary words - identifiers' names are not limited to natural language words and the test set usually contains a number of program tokens which are out of the vocabulary built from the training set and cannot be appropriately mapped to word embeddings. To deal with the first challenge, we convert this task into a representation learning problem instead of a multi-label classification problem. Given a code snippet which lacks a logging statement, our approach first leverages a neural network with an RNN (recurrent neural network) layer and a self-attention layer to learn the proper representation of each program token, and then predicts whether each token should be logged through a unified binary classifier based on the learned representation. To handle the second challenge, we propose a novel method to map program tokens into word embeddings by making use of the pre-trained word embeddings of natural language tokens. We evaluate our approach on 9 large and high-quality Java projects. Our evaluation results show that the average MAP of our approach is over 0.84, outperforming random guess and an information-retrieval-based method by large margins.",
        "keywords": [
            "Task analysis",
            "Recurrent neural networks",
            "Tools",
            "Compounds",
            "Vocabulary",
            "Software maintenance"
        ]
    },
    {
        "title": "Enhancing Trustability of Android Applications via User-Centric Flexible Permissions.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2941936",
        "volume": "47",
        "abstract": "The Android OS market is experiencing a growing share globally. It is becoming the mobile platform of choice for an increasing number of users. People rely on Android mobile devices for surfing the web, purchasing products, or to be part of a social network. The large amount of personal information that is exchanged makes privacy an important concern. As a result, the trustability of mobile apps is a fundamental aspect to be considered, particularly with regard to meeting the expectations of end users. The rigidities of the Android permission model confine end users into a secondary role, offering the only option of choosing between either privacy or functionalities. In this paper, we aim at improving the trustability of Android apps by proposing a user-centric approach to the flexible management of Android permissions. The proposed approach empowers end users to selectively grant permission by specifying (i) the desired level of permissions granularity and (ii) the specific features of the app in which the chosen permission levels are granted. Four experiments have been designed, conducted, and reported for evaluating it. The experiments consider performance, usability, and acceptance from both the end user's and developer's perspective. Results confirm confidence on the approach.",
        "keywords": [
            "Privacy",
            "Runtime",
            "Usability",
            "Social networking (online)",
            "Libraries",
            "Fatigue",
            "Smart phones"
        ]
    },
    {
        "title": "A Survey on Adaptive Random Testing.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2942921",
        "volume": "47",
        "abstract": "Random testing (RT) is a well-studied testing method that has been widely applied to the testing of many applications, including embedded software systems, SQL database systems, and Android applications. Adaptive random testing (ART) aims to enhance RT's failure-detection ability by more evenly spreading the test cases over the input domain. Since its introduction in 2001, there have been many contributions to the development of ART, including various approaches, implementations, assessment and evaluation methods, and applications. This paper provides a comprehensive survey on ART, classifying techniques, summarizing application areas, and analyzing experimental evaluations. This paper also addresses some misconceptions about ART, and identifies open research challenges to be further investigated in the future work.",
        "keywords": [
            "Subspace constraints",
            "Testing",
            "Libraries",
            "Software",
            "Power capacitors",
            "Strips",
            "Art"
        ]
    },
    {
        "title": "Smart Contract Development: Challenges and Opportunities.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2942301",
        "volume": "47",
        "abstract": "Smart contract, a term which was originally coined to refer to the automation of legal contracts in general, has recently seen much interest due to the advent of blockchain technology. Recently, the term is popularly used to refer to low-level code scripts running on a blockchain platform. Our study focuses exclusively on this subset of smart contracts. Such smart contracts have increasingly been gaining ground, finding numerous important applications (e.g., crowdfunding) in the real world. Despite the increasing popularity, smart contract development still remains somewhat a mystery to many developers largely due to its special design and applications. Are there any differences between smart contract development and traditional software development? What kind of challenges are faced by developers during smart contract development? Questions like these are important but have not been explored by researchers yet. In this paper, we performed an exploratory study to understand the current state and potential challenges developers are facing in developing smart contracts on blockchains, with a focus on Ethereum (the most popular public blockchain platform for smart contracts). Toward this end, we conducted this study in two phases. In the first phase, we conducted semi-structured interviews with 20 developers from GitHub and industry professionals who are working on smart contracts. In the second phase, we performed a survey on 232 practitioners to validate the findings from the interviews. Our interview and survey results revealed several major challenges developers are facing during smart contract development: (1) there is no effective way to guarantee the security of smart contract code; (2) existing tools for development are still very basic; (3) the programming languages and the virtual machines still have a number of limitations; (4) performance problems are hard to handle under resource constrained running environment; and (5) online resources (including advanced/updated documents and community support) are still limited. Our study suggests several directions that researchers and practitioners can work on to help improve developers’ experience on developing high-quality smart contracts.",
        "keywords": [
            "Smart contracts",
            "Blockchain",
            "Law",
            "Interviews",
            "Software"
        ]
    },
    {
        "title": "FutureWare: Designing a Middleware for Anticipatory Mobile Computing.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2943554",
        "volume": "47",
        "abstract": "Ubiquitous computing is moving from context-awareness to context-prediction. In order to build truly anticipatory systems developers have to deal with many challenges, from multimodal sensing to modeling context from sensed data, and, when necessary, coordinating multiple predictive models across devices. Novel expressive programming interfaces and paradigms are needed for this new class of mobile and ubiquitous applications. In this paper we present FutureWare, a middleware for seamless development of mobile applications that rely on context prediction. FutureWare exposes an expressive API to lift the burden of mobile sensing, individual and group behavior modeling, and future context querying, from an application developer. We implement FutureWare as an Android library, and through a scenario-based testing and a demo app we show that it represents an efficient way of supporting anticipatory applications, reducing the necessary coding effort by two orders of magnitude.",
        "keywords": [
            "Middleware",
            "Sensors",
            "Predictive models",
            "Context modeling",
            "Machine learning",
            "Servers",
            "Mobile applications"
        ]
    },
    {
        "title": "Towards a Theory of Software Developer Job Satisfaction and Perceived Productivity.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2944354",
        "volume": "47",
        "abstract": "Developer satisfaction and work productivity are important considerations for software companies. Enhanced developer satisfaction may improve the attraction, retention and health of employees, while higher productivity should reduce costs and increase customer satisfaction through faster software improvements. Many researchers and companies assume that perceived productivity and job satisfaction are related and may be used as proxies for one another, but these claims are a current topic of debate. There are also many social and technical factors that may impact satisfaction and productivity, but which factors have the most impact is not clear, especially for specific development contexts. Through our research, we developed a theory articulating a bi-directional relationship between software developer job satisfaction and perceived productivity, and identified what additional social and technical factors, challenges and work context variables influence this relationship. The constructs and relationships in our theory were derived in part from related literature in software engineering and knowledge work, and we validated and extended these concepts through a rigorously designed survey instrument. We instantiate our theory with a large software company, which suggests a number of propositions about the relative impact of various factors and challenges on developer satisfaction and perceived productivity. Our survey instrument and analysis approach can be applied to other development settings, while our findings lead to concrete recommendations for practitioners and researchers.",
        "keywords": [
            "Productivity",
            "Software",
            "Companies",
            "Software engineering",
            "Complexity theory",
            "Psychology",
            "Measurement"
        ]
    },
    {
        "title": "The Assessor's Dilemma: Improving Bug Repair via Empirical Game Theory.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2944608",
        "volume": "47",
        "abstract": "Priority inflation occurs when a Quality-Assurance (QA) engineer or a project manager requesting a feature inflates the priority of their task so that developers deliver the fix or the new functionality more quickly. We survey developers and show that priority inflation occurs and misallocates developer time. We are the first to apply empirical game-theoretic analysis (EGTA) to a software engineering problem, specifically priority inflation. First, we extract prioritisation strategies from 42,620 issues from Apache's JIRA, then use \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TaskAssessor</small>\n, our EGTA-based modelling approach, to confirm conventional wisdom and show that the common process of a QA engineer assigning priority labels is susceptible to priority inflation. We then show that the common mitigation strategy of having a bug triage team assigning priorities does not resolve priority inflation and slows development. We then use mechanism design to devise \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">assessor-throttling</i>\n, a new, lightweight prioritization process, immune to priority inflation. We show that assessor-throttling resolves 97 percent of high priority tasks, 69 percent better than simply relying on those filing tasks to assign priorities. Finally, we present The Fed, a browser extension for Chrome that supports assessor-throttling.",
        "keywords": [
            "Task analysis",
            "Computer bugs",
            "Logic gates",
            "Games",
            "Nash equilibrium",
            "Software"
        ]
    },
    {
        "title": "SOSRepair: Expressive Semantic Search for Real-World Program Repair.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2944914",
        "volume": "47",
        "abstract": "Automated program repair holds the potential to significantly reduce software maintenance effort and cost. However, recent studies have shown that it often produces low-quality patches that repair some but break other functionality. We hypothesize that producing patches by replacing likely faulty regions of code with semantically-similar code fragments, and doing so at a higher level of granularity than prior approaches can better capture abstraction and the intended specification, and can improve repair quality. We create SOSRepair, an automated program repair technique that uses semantic code search to replace candidate buggy code regions with behaviorally-similar (but not identical) code written by humans. SOSRepair is the first such technique to scale to real-world defects in real-world systems. On a subset of the ManyBugs benchmark of such defects, SOSRepair produces patches for 22 (34%) of the 65 defects, including 3, 5, and 6 defects for which previous state-of-the-art techniques Angelix, Prophet, and GenProg do not, respectively. On these 22 defects, SOSRepair produces more patches (9, 41%) that pass all independent tests than the prior techniques. We demonstrate a relationship between patch granularity and the ability to produce patches that pass all independent tests. We then show that fault localization precision is a key factor in SOSRepair's success. Manually improving fault localization allows SOSRepair to patch 23 (35%) defects, of which 16 (70%) pass all independent tests. We conclude that (1) higher-granularity, semantic-based patches can improve patch quality, (2) semantic search is promising for producing high-quality real-world defect repairs, (3) research in fault localization can significantly improve the quality of program repair techniques, and (4) semi-automated approaches in which developers suggest fix locations may produce high-quality patches.",
        "keywords": [
            "Maintenance engineering",
            "Semantic search",
            "Encoding",
            "Benchmark testing",
            "Computer bugs",
            "Software"
        ]
    },
    {
        "title": "How to \"DODGE\" Complex Software Analytics.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2945020",
        "volume": "47",
        "abstract": "Machine learning techniques applied to software engineering tasks can be improved by hyperparameter optimization, i.e., automatic tools that find good settings for a learner's control parameters. We show that such hyperparameter optimization can be unnecessarily slow, particularly when the optimizers waste time exploring “redundant tunings”, i.e., pairs of tunings which lead to indistinguishable results. By ignoring redundant tunings, \n<bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">DODGE(<inline-formula><tex-math notation=\"LaTeX\">$\\mathcal {E})$</tex-math><alternatives><mml:math><mml:mrow><mml:mi mathvariant=\"script\">E</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href=\"agrawal-ieq1-2945020.gif\"/></alternatives></inline-formula></b>\n, a tuning tool, runs orders of magnitude faster, while also generating learners with more accurate predictions than seen in prior state-of-the-art approaches.",
        "keywords": [
            "Tuning",
            "Text mining",
            "Software",
            "Task analysis",
            "Optimization",
            "Software engineering",
            "Tools"
        ]
    },
    {
        "title": "Metric-Based Fault Prediction for Spreadsheets.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2944604",
        "volume": "47",
        "abstract": "Electronic spreadsheets are widely used in organizations for various data analytics and decision-making tasks. Even though faults within such spreadsheets are common and can have significant negative consequences, today's tools for creating and handling spreadsheets provide limited support for fault detection, localization, and repair. Being able to predict whether a certain part of a spreadsheet is faulty or not is often central for the implementation of such supporting functionality. In this work, we propose a novel approach to fault prediction in spreadsheet formulas, which combines an extensive catalog of spreadsheet metrics with modern machine learning algorithms. An analysis of the individual metrics from our catalog reveals that they are generally suited to discover a wide range of faults. Their predictive power is, however, limited when considered in isolation. Therefore, in our approach we apply supervised learning algorithms to obtain fault predictors that utilize all data provided by multiple spreadsheet metrics from our catalog. Experiments on different datasets containing faulty spreadsheets show that particularly Random Forests classifiers are often effective. As a result, the proposed method is in many cases able to make highly accurate predictions whether a given formula of a spreadsheet is faulty.\n<xref ref-type=\"fn\" rid=\"fn1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><sup>1</sup></xref>\n<fn id=\"fn1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><label>1.</label><p>Results of a preliminary study were published in <xref ref-type=\"bibr\" rid=\"ref1\">[1]</xref> .</p></fn>",
        "keywords": [
            "Measurement",
            "Software",
            "Prediction algorithms",
            "Predictive models",
            "Tools",
            "Radio frequency",
            "Task analysis"
        ]
    },
    {
        "title": "Specification Patterns for Robotic Missions.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2945329",
        "volume": "47",
        "abstract": "Mobile and general-purpose robots increasingly support everyday life, requiring dependable robotics control software. Creating such software mainly amounts to implementing complex behaviors known as missions. Recognizing this need, a large number of domain-specific specification languages has been proposed. These, in addition to traditional logical languages, allow the use of formally specified missions for synthesis, verification, simulation or guiding implementation. For instance, the logical language LTL is commonly used by experts to specify missions as an input for planners, which synthesize a robot's required behavior. Unfortunately, domain-specific languages are usually tied to specific robot models, while logical languages such as LTL are difficult to use by non-experts. We present a catalog of 22 mission specification patterns for mobile robots, together with tooling for instantiating, composing, and compiling the patterns to create mission specifications. The patterns provide solutions for recurrent specification problems; each pattern details the usage intent, known uses, relationships to other patterns, and—most importantly—a template mission specification in temporal logic. Our tooling produces specifications expressed in the temporal logics LTL and CTL to be used by planners, simulators or model checkers. The patterns originate from 245 mission requirements extracted from the robotics literature, and they are evaluated upon a total of 441 real-world mission requirements and 1251 mission specifications. Five of these reflect scenarios defined with two well-known industrial partners developing human-size robots. We further validate our patterns’ correctness with simulators and two different types of real robots.",
        "keywords": [
            "Software",
            "Service robots",
            "Natural languages",
            "Software engineering",
            "Tools",
            "Task analysis"
        ]
    },
    {
        "title": "IntRepair: Informed Repairing of Integer Overflows.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2946148",
        "volume": "47",
        "abstract": "Integer overflows have threatened software applications for decades. Thus, in this paper, we propose a novel technique to provide automatic repairs of integer overflows in \n<monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">C</monospace>\n source code. Our technique, based on static symbolic execution, fuses \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">detection</i>\n, \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">repair generation</i>\n and \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">validation</i>\n. This technique is implemented in a prototype named \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">IntRepair</small>\n. We applied \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">IntRepair</small>\n to 2,052 \n<monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">C</monospace>\n programs (approx. 1 million lines of code) contained in SAMATE's Juliet test suite and 50 synthesized programs that range up to 20 KLOC. Our experimental results show that \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">IntRepair</small>\n is able to effectively detect integer overflows and successfully repair them, while only increasing the source code (LOC) and binary (Kb) size by around 1 percent, respectively. Further, we present the results of a user study with 30 participants which shows that \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">IntRepair</small>\n repairs are more than 10x efficient as compared to manually generated code repairs.",
        "keywords": [
            "Maintenance engineering",
            "Software",
            "Tools",
            "Fault detection",
            "Runtime",
            "Engines",
            "Fuses"
        ]
    },
    {
        "title": "Companies' Participation in OSS Development-An Empirical Study of OpenStack.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2946156",
        "volume": "47",
        "abstract": "Commercial participation continues to grow in open source software (OSS) projects and novel arrangements appear to emerge in company-dominated projects and ecosystems. What is the nature of these novel arrangements? Does volunteers’ participation remain critical for these ecosystems? Despite extensive research on commercial participation in OSS, the exact nature and extent of company contributions to OSS development, and the impact of this engagement may have on the volunteer community have not been clarified. To bridge the gap, we perform an exploratory study of OpenStack: a large OSS ecosystem with intense commercial participation. We quantify companies’ contributions via the developers that they provide and the commits made by those developers. We find that companies made far more contributions than volunteers and the distribution of the contributions made by different companies is also highly unbalanced. We observe eight unique contribution models based on companies’ commercial objectives and characterize each model according to three dimensions: contribution intensity, extent, and focus. Companies providing full cloud solutions tend to make both intensive (more than other companies) and extensive (involving a wider variety of projects) contributions. Usage-oriented companies make extensive but less intense contributions. Companies driven by particular business needs focus their contributions on the specific projects addressing these needs. Minor contributors include community players (e.g., the Linux Foundation) and research groups. A model relating the number of volunteers to the diversity of contribution shows a strong positive association between them.",
        "keywords": [
            "Companies",
            "Ecosystems",
            "Biological system modeling",
            "Software",
            "Cloud computing",
            "Linux"
        ]
    },
    {
        "title": "On the Energy Footprint of Mobile Testing Frameworks.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2946163",
        "volume": "47",
        "abstract": "High energy consumption is a challenging issue that an ever increasing number of mobile applications face today. However, energy consumption is being tested in an <i>ad hoc</i> way, despite being an important non-functional requirement of an application. Such limitation becomes particularly disconcerting during software testing: on the one hand, developers do not really know how to measure energy; on the other hand, there is no knowledge as to what is the energy overhead imposed by the testing framework. In this paper, as we evaluate eight popular mobile UI automation frameworks, we have discovered that there are automation frameworks that increase energy consumption up to roughly 2200 percent. While limited in the interactions one can do, <i>Espresso</i> is the most energy efficient framework. However, depending on the needs of the tester, <i>Appium</i>, <i>Monkeyrunner</i>, or <i>UIAutomator</i> are good alternatives. In practice, results show that deciding which is the most suitable framework is vital. We provide a decision tree to help developers make an educated decision on which framework suits best their testing needs.",
        "keywords": [
            "Automation",
            "Energy consumption",
            "Testing",
            "Tools",
            "Energy measurement",
            "Monitoring",
            "Robots"
        ]
    },
    {
        "title": "ElementRank: Ranking Java Software Classes and Packages using a Multilayer Complex Network-Based Approach.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2946357",
        "volume": "47",
        "abstract": "Software comprehension is an important part of software maintenance. To understand a piece of large and complex software, the first problem to be solved is where to start the understanding process. Choosing to start the comprehension process from the important software elements has proven to be a practical way. Research on complex networks opens new opportunities for identifying important elements, and many approaches have been proposed. However, the software networks that existing approaches use neglect the multilayer nature of software systems. That is, nodes in the network can have different types of relationships at the same time, and each type of relationship forms a specific layer. Worse still, they mainly focus on identifying important classes, and little work has been done on quantifying package importance. In this paper, we propose an ElementRank approach to provide a ranked list of classes (or packages) for maintainers to start the comprehension process. The top-ranked classes (or packages) can be seen as the starting points for the software comprehension process at the class (or package) level. First, we introduce two kinds of multilayer software networks to describe the topological structure of software at the class level and package level, respectively. Second, we propose a weighted PageRank algorithm to calculate the weighted PageRank value of classes (or packages) in each layer of the corresponding multilayer software network. Then, we use AHP (Analytic Hierarchy Process) to weigh each layer in the corresponding multilayer software network, and further aggregate the weighted PageRank value to obtain the global weighted PageRank value for each class (or package). Finally, all the classes (or packages) are ranked according to their global weighted PageRank values in a descending order, and the top-ranked classes (or packages) can serve as the starting points for the software comprehension process at the class (or package) level. ElementRank is validated theoretically using the widely accepted Weyuker’s criteria. Theoretical results show that the global weighted PageRank value for classes (or packages) satisfies most of Weyuker’s properties. Furthermore, ElementRank is evaluated empirically using a set of twelve open source software systems. Through a set of experiments, we show the rank correlation between the results of ElementRank and that of the approaches in the related work, and the benefits of ElementRank are also illustrated in comparison with other approaches in the related work. Empirical results also show that ElementRank can be applied to large software systems.",
        "keywords": [
            "Software systems",
            "Nonhomogeneous media",
            "Complex networks",
            "Maintenance engineering",
            "Measurement",
            "Computer science"
        ]
    },
    {
        "title": "Easy-to-Deploy API Extraction by Multi-Level Feature Embedding and Transfer Learning.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2946830",
        "volume": "47",
        "abstract": "Application Programming Interfaces (APIs) have been widely discussed on social-technical platforms (e.g., Stack Overflow). Extracting API mentions from such informal software texts is the prerequisite for API-centric search and summarization of programming knowledge. Machine learning based API extraction has demonstrated superior performance than rule-based methods in informal software texts that lack consistent writing forms and annotations. However, machine learning based methods have a significant overhead in preparing training data and effective features. In this paper, we propose a multi-layer neural network based architecture for API extraction. Our architecture automatically learns character-, word- and sentence-level features from the input texts, thus removing the need for manual feature engineering and the dependence on advanced features (e.g., API gazetteers) beyond the input texts. We also propose to adopt transfer learning to adapt a source-library-trained model to a target-library, thus reducing the overhead of manual training-data labeling when the software text of multiple programming languages and libraries need to be processed. We conduct extensive experiments with six libraries of four programming languages which support diverse functionalities and have different API-naming and API-mention characteristics. Our experiments investigate the performance of our neural architecture for API extraction in informal software texts, the importance of different features, the effectiveness of transfer learning. Our results confirm not only the superior performance of our neural architecture than existing machine learning based methods for API extraction in informal software texts, but also the easy-to-deploy characteristic of our neural architecture.",
        "keywords": [
            "Libraries",
            "Feature extraction",
            "Machine learning",
            "Software",
            "Computer architecture",
            "Training data",
            "Manuals"
        ]
    },
    {
        "title": "The Art, Science, and Engineering of Fuzzing: A Survey.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2946563",
        "volume": "47",
        "abstract": "Among the many software testing techniques available today, \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">fuzzing</i>\n has remained highly popular due to its conceptual simplicity, its low barrier to deployment, and its vast amount of empirical evidence in discovering real-world software vulnerabilities. At a high level, fuzzing refers to a process of repeatedly running a program with generated inputs that may be syntactically or semantically malformed. While researchers and practitioners alike have invested a large and diverse effort towards improving fuzzing in recent years, this surge of work has also made it difficult to gain a comprehensive and coherent view of fuzzing. To help preserve and bring coherence to the vast literature of fuzzing, this paper presents a unified, general-purpose model of fuzzing together with a taxonomy of the current fuzzing literature. We methodically explore the design decisions at every stage of our model fuzzer by surveying the related literature and innovations in the art, science, and engineering that make modern-day fuzzers effective.",
        "keywords": [
            "Fuzzing",
            "Security",
            "Computer bugs",
            "Terminology"
        ]
    },
    {
        "title": "Testing with Fewer Resources: An Adaptive Approach to Performance-Aware Test Case Generation.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2946773",
        "volume": "47",
        "abstract": "Automated test case generation is an effective technique to yield high-coverage test suites. While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects. In this regard, runtime and memory usage are two essential dimensions: less expensive tests reduce the resource demands for the generation process and later regression testing phases. This study shows that \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">performance-aware</i>\n test case generation requires solving two main challenges: providing a good approximation of resource usage with minimal overhead and avoiding detrimental effects on both final coverage and fault detection effectiveness. To tackle these challenges, we conceived a set of performance proxies—inspired by previous work on performance testing— that provide a reasonable estimation of the test execution costs (\n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i.e.</i>\n, runtime and memory usage). Thus, we propose an adaptive strategy, called aDynaMOSA, which leverages these proxies by extending DynaMOSA, a state-of-the-art evolutionary algorithm in unit testing. Our empirical study —involving 110 non-trivial Java classes—reveals that our adaptive approach generates test suite with statistically significant improvements in runtime (−25 percent) and heap memory consumption (−15 percent) compared to DynaMOSA. Additionally, aDynaMOSA has comparable results to DynaMOSA over seven different coverage criteria and similar fault detection effectiveness. Our empirical investigation also highlights that the usage of performance proxies (i.e., without the adaptiveness) is not sufficient to generate more performant test cases without compromising the overall coverage.",
        "keywords": [
            "Testing",
            "Runtime",
            "Genetic algorithms",
            "Memory management",
            "Fault detection",
            "Sociology",
            "Statistics"
        ]
    },
    {
        "title": "Historical Spectrum Based Fault Localization.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2948158",
        "volume": "47",
        "abstract": "Spectrum-based fault localization (SBFL) techniques are widely studied and have been evaluated to be effective in locating faults. Recent studies also showed that developers from industry value automated SBFL techniques. However, their effectiveness is still limited by two main reasons. First, the test coverage information leveraged to construct the spectrum does not reflect the root cause directly. Second, SBFL suffers from the tie issue so that the buggy code entities can not be well differentiated from non-buggy ones. To address these challenges, we propose to leverage the information of version histories in fault localization based on the following two intuitions. First, version histories record how bugs are introduced to software projects and this information reflects the root cause of bugs directly. Second, the evolution histories of code can help differentiate those suspicious code entities ranked in tie by SBFL. Our intuitions are also inspired by the observations on debugging practices from large open source projects and industry. Based on the intuitions, we propose a novel technique HSFL (historical spectrum based fault localization). Specifically, HSFL identifies bug-inducing commits from the version history in the first step. It then constructs historical spectrum (denoted as Histrum) based on bug-inducing commits, which is another dimension of spectrum orthogonal to the coverage based spectrum used in SBFL. HSFL finally ranks the suspicious code elements based on our proposed Histrum and the conventional spectrum. HSFL outperforms the state-of-the-art SBFL techniques significantly on the Defects4J benchmark. Specifically, it locates and ranks the buggy statement at Top-1 for 77.8 percent more bugs as compared with SBFL, and 33.9 percent more bugs at Top-5. Besides, for the metrics MAP and MRR, HSFL achieves an average improvement of 28.3 and 40.8 percent over all bugs, respectively. Moreover, HSFL can also outperform other six families of fault localization techniques, and our proposed Histrum model can be integrated with different families of techniques and boost their performance.",
        "keywords": [
            "Computer bugs",
            "History",
            "Debugging",
            "Industries",
            "Software",
            "Benchmark testing",
            "Maintenance engineering"
        ]
    },
    {
        "title": "Automatic Repair of Timestamp Comparisons.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2948351",
        "volume": "47",
        "abstract": "Automated program repair has the potential to reduce the developers’ effort to fix errors in their code. In particular, modern programming languages, such as Java, C, and C#, represent time as integer variables that suffer from integer overflow, introducing subtle errors that are hard to discover and repair. Recent researches on automated program repair rely on test cases to discover failures to correct, making them suitable only for regression errors. We propose a new strategy to automatically repair programs that suffer from timestamp overflows that are manifested in comparison expressions. It unifies the benefits of static analysis and automatic program repair avoiding dependency on testing to identify and correct defected code. Our approach performs an abstract analysis over the time domain of a program using a Time Type System to identify the problematic comparison expressions. The repairing strategy rewrites the timestamp comparisons exploiting the binary representation of machine numbers to correct the code. We have validated the applicability of our approach with 20 open source Java projects. The results show that it is able to correctly repair all 246 identified errors. To further validate the reliability of our approach, we have proved the soundness of both, type system and repairing strategy. Furthermore, several patches for three open source projects have been acknowledged and accepted by their developers.",
        "keywords": [
            "Maintenance engineering",
            "Java",
            "Semantics",
            "Static analysis",
            "Software",
            "Testing"
        ]
    },
    {
        "title": "CrySL: An Extensible Approach to Validating the Correct Usage of Cryptographic APIs.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2948910",
        "volume": "47",
        "abstract": "Various studies have empirically shown that the majority of Java and Android applications misuse cryptographic libraries, causing devastating breaches of data security. It is crucial to detect such misuses early in the development process. To detect cryptography misuses, one must \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">define</i>\n secure uses first, a process mastered primarily by cryptography experts but not by developers. In this paper, we present \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">CrySL</small>\n, a specification language for bridging the cognitive gap between cryptography experts and developers. \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">CrySL</small>\n enables cryptography experts to specify the secure usage of the cryptographic libraries they provide. We have implemented a compiler that translates such \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">CrySL</small>\n specification into a context-sensitive and flow-sensitive demand-driven static analysis. The analysis then helps developers by automatically checking a given Java or Android app for compliance with the \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">CrySL</small>\n-encoded rules. We have designed an extensive \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">CrySL</small>\n rule set for the Java Cryptography Architecture (JCA), and empirically evaluated it by analyzing 10,000 current Android apps and all 204,788 current Java software artefacts on Maven Central. Our results show that misuse of cryptographic APIs is still widespread, with 95 percent of apps and 63 percent of Maven artefacts containing at least one misuse. Our easily extensible \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">CrySL</small>\n rule set covers more violations than previous special-purpose tools that contain hard-coded rules, while still offering a more precise analysis.",
        "keywords": [
            "Java",
            "Encryption",
            "Static analysis",
            "Tools",
            "Ciphers",
            "Semantics"
        ]
    },
    {
        "title": "Improving Vulnerability Inspection Efficiency Using Active Learning.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2949275",
        "volume": "47",
        "abstract": "Software engineers can find vulnerabilities with less effort if they are directed towards code that might contain more vulnerabilities. HARMLESS is an incremental support vector machine tool that builds a vulnerability prediction model from the source code inspected to date, then suggests what source code files should be inspected next. In this way, HARMLESS can reduce the time and effort required to achieve some desired level of recall for finding vulnerabilities. The tool also provides feedback on when to stop (at that desired level of recall) while at the same time, correcting human errors by double-checking suspicious files. This paper evaluates HARMLESS on Mozilla Firefox vulnerability data. HARMLESS found 80, 90, 95, 99 percent of the vulnerabilities by inspecting 10, 16, 20, 34 percent of the source code files. When targeting 90, 95, 99 percent recall, HARMLESS could stop after inspecting 23, 30, 47 percent of the source code files. Even when human reviewers fail to identify half of the vulnerabilities (50 percent false negative rate), HARMLESS could detect 96 percent of the missing vulnerabilities by double-checking half of the inspected files. Our results serve to highlight the very steep cost of protecting software from vulnerabilities (in our case study that cost is, for example, the human effort of inspecting 28,750 × 20% = 5,750 source code files to identify 95 percent of the vulnerabilities). While this result could benefit the mission-critical projects where human resources are available for inspecting thousands of source code files, the research challenge for future work is how to further reduce that cost. The conclusion of this paper discusses various ways that goal might be achieved.",
        "keywords": [
            "Inspection",
            "Software",
            "Tools",
            "Security",
            "Predictive models",
            "Error correction",
            "NIST"
        ]
    },
    {
        "title": "Explaining Regressions via Alignment Slicing and Mending.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2949568",
        "volume": "47",
        "abstract": "Regression faults, which make working code stop functioning, are often introduced when developers make changes to the software. Many regression fault localization techniques have been proposed. However, issues like inaccuracy and lack of explanation are still obstacles for their practical application. In this work, we propose a trace-based approach to identifying not only where the root cause of a regression bug lies, but also how the defect is propagated to its manifestation as the explanation. In our approach, we keep the trace of original correct version as reference and infer the faulty steps on the trace of regression version so that we can build a causality graph of how the defect is propagated. To this end, we overcomes two technical challenges. First, we align two traces derived from two program versions by extending state-of-the-art trace alignment technique for regression fault with novel relaxation technique. Second, we construct causality graph (i.e., explanation) by adopting a technique called \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">alignment slicing and mending</i>\n to isolate the failure-inducing changes and explain the failure. Our comparative experiment with the state-of-the-art techniques including dynamic slicing, delta-debugging, and symbolic execution on 24 real-world regressions shows that (1) our approach is more accurate on isolating the failure-inducing changes, (2) the generated explanation requires acceptable manual effort to inspect, and (3) our approach requires lower runtime overhead. In addition, we also conduct an applicability experiment based on Defects4J bug repository, showing the potential limitations of our trace-based approach and providing guidance for its practical use.",
        "keywords": [
            "Computer bugs",
            "Semantics",
            "Debugging",
            "Java",
            "Software",
            "Runtime",
            "Task analysis"
        ]
    },
    {
        "title": "Investigating the Impact of Development Task on External Quality in Test-Driven Development: An Industry Experiment.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2949811",
        "volume": "47",
        "abstract": "Reviews on test-driven development (TDD) studies suggest that the conflicting results reported in the literature are due to unobserved factors, such as the tasks used in the experiments, and highlight that there are very few industry experiments conducted with professionals. The goal of this study is to investigate the impact of a new factor, the chosen \n<i>task</i>\n, and the \n<i>development approach</i>\n on external quality in an industrial experimental setting with 17 professionals. The participants are junior to senior developers in programming with Java, beginner to novice in unit testing, JUnit, and they have no prior experience in TDD. The experimental design is a \n<inline-formula><tex-math notation=\"LaTeX\">$2\\times 2$</tex-math></inline-formula>\n cross-over, i.e., we use two tasks for each of the two approaches, namely TDD and incremental test-last development (ITLD). Our results reveal that both \n<i>development approach</i>\n and \n<i>task</i>\n are significant factors with regards to the external quality achieved by the participants. More specifically, the participants produce higher quality code during ITLD in which splitting user stories into subtasks, coding, and testing activities are followed, compared to TDD. The results also indicate that the participants produce higher quality code during the implementation of Bowling Score Keeper, compared to that of Mars Rover API, although they perceived both tasks as of similar complexity. An interaction between the \n<i>development approach</i>\n and \n<i>task</i>\n could not be observed in this experiment. We conclude that variables that have not been explored so often, such as the extent to which the task is specified in terms of smaller subtasks, and developers’ unit testing experience might be critical factors in TDD experiments. The real-world appliance of TDD and its implications on external quality still remain to be challenging unless these uncontrolled and unconsidered factors are further investigated by researchers in both academic and industrial settings.",
        "keywords": [
            "Task analysis",
            "Industries",
            "Bibliographies",
            "Productivity",
            "Programming profession",
            "Organizations"
        ]
    },
    {
        "title": "An Empirical Study of Dependency Downgrades in the npm Ecosystem.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2952130",
        "volume": "47",
        "abstract": "In a software ecosystem, a dependency relationship enables a \n<i>client</i>\n package to reuse a certain version of a \n<i>provider</i>\n package. Packages in a software ecosystem often release versions containing bug fixes, new functionalities, and security enhancements. Hence, updating the provider version is an important maintenance task for client packages. Despite the number of investigations about dependency updates, there is a lack of studies about dependency downgrades in software ecosystems. A downgrade indicates that the adopted version of a provider package is not suitable to the client package at a certain moment. In this paper, we investigate downgrades in the \n<inline-formula><tex-math notation=\"LaTeX\">${\\sf npm}$</tex-math></inline-formula>\n ecosystem. We address three research questions. In our first RQ, we provide a list of the reasons behind the occurrence of downgrades. Our manual analysis of the artifacts (e.g., release notes and commit messages) of a package code repository identified two categories of downgrades according to their rationale: reactive and preventive. The reasons behind reactive downgrades are defects in a specific version of a provider, unexpected feature changes in a provider, and incompatibilities. In turn, preventive downgrades are an attempt to avoid issues in future releases. In our second RQ, we investigate how the versioning of dependencies is modified when a downgrade occurs. We observe that 49 percent of the downgrades are performed by replacing a range of acceptable versions of a provider by a specific old version. This observation suggests that client packages have the tendency to become more conservative regarding the update of their providers after a downgrade. Also, 48 percent of the downgrades reduce the provider version by a minor level (e.g., from 2.1.0 to 2.0.0). This observation indicates that client packages in \n<inline-formula><tex-math notation=\"LaTeX\">${\\sf npm}$</tex-math></inline-formula>\n should be cautious when updating minor releases of the provider (e.g., by prioritizing tests). Finally, in our third RQ we observe that 50 percent of the downgrades are performed at a rate that is 2.6 times as slow as the median time-between-releases of their associated client packages. We also observe that downgrades that follow an explicit update of a provider package occur faster than downgrades that follow an implicit update. Explicit updates occur when the provider is updated by means of an explicit change to the versioning specification (i.e., the string used by client packages to define the provider version that they are willing to adopt). We conjecture that, due to the controlled nature of explicit updates, it is easier for client packages to identify the provider that is associated with the problem that motivated the downgrade.",
        "keywords": [
            "Ecosystems",
            "Software",
            "Computer bugs",
            "Tools",
            "Security",
            "Task analysis"
        ]
    },
    {
        "title": "PatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2952614",
        "volume": "47",
        "abstract": "Linux kernel stable versions serve the needs of users who value stability of the kernel over new features. The quality of such stable versions depends on the initiative of kernel developers and maintainers to propagate bug fixing patches to the stable versions. Thus, it is desirable to consider to what extent this process can be automated. A previous approach relies on words from commit messages and a small set of manually constructed code features. This approach, however, shows only moderate accuracy. In this paper, we investigate whether deep learning can provide a more accurate solution. We propose PatchNet, a hierarchical deep learning-based approach capable of automatically extracting features from commit messages and commit code and using them to identify stable patches. PatchNet contains a deep hierarchical structure that mirrors the hierarchical and sequential structure of commit code, making it distinctive from the existing deep learning models on source code. Experiments on 82,403 recent Linux patches confirm the superiority of PatchNet against various state-of-the-art baselines, including the one recently-adopted by Linux kernel maintainers.",
        "keywords": [
            "Kernel",
            "Linux",
            "Computer bugs",
            "Feature extraction",
            "Deep learning",
            "Indexes",
            "Manuals"
        ]
    },
    {
        "title": "Grammar Based Directed Testing of Machine Learning Systems.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2953066",
        "volume": "47",
        "abstract": "The massive progress of machine learning has seen its application over a variety of domains in the past decade. But how do we develop a systematic, scalable and modular strategy to validate machine-learning systems? We present, to the best of our knowledge, the first approach, which provides a systematic test framework for machine-learning systems that accepts grammar-based inputs. Our \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ogma</small>\n approach automatically discovers erroneous behaviours in classifiers and leverages these erroneous behaviours to improve the respective models. \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ogma</small>\n leverages inherent robustness properties present in any well trained machine-learning model to direct test generation and thus, implementing a scalable test generation methodology. To evaluate our \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ogma</small>\n approach, we have tested it on three real world natural language processing (NLP) classifiers. We have found thousands of erroneous behaviours in these systems. We also compare \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ogma</small>\n with a random test generation approach and observe that \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Ogma</small>\n is more effective than such random test generation by up to 489 percent.",
        "keywords": [
            "Machine learning",
            "Grammar",
            "Robustness",
            "Systematics",
            "Test pattern generators",
            "Natural language processing"
        ]
    },
    {
        "title": "oo7: Low-Overhead Defense Against Spectre Attacks via Program Analysis.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2953709",
        "volume": "47",
        "abstract": "The Spectre vulnerability in modern processors has been widely reported. The key insight in this vulnerability is that speculative execution in processors can be misused to access the secrets. Subsequently, even though the speculatively executed instructions are squashed, the secret may linger in micro-architectural states such as cache, and can potentially be accessed by an attacker via side channels. In this paper, we propose \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">oo7</i>\n, a static analysis approach that can mitigate Spectre attacks by detecting potentially vulnerable code snippets in program binaries and protecting them against the attack by patching them. Our key contribution is to balance the concerns of effectiveness, analysis time and run-time overheads. We employ control flow extraction, taint analysis, and address analysis to detect tainted conditional branches and speculative memory accesses. \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">oo7</i>\n can detect all fifteen purpose-built Spectre-vulnerable code patterns \n<xref ref-type=\"bibr\" rid=\"ref1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[1]</xref>\n , whereas Microsoft compiler with Spectre mitigation option can only detect two of them. We also report the results of a large-scale study on applying \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">oo7</i>\n to over 500 program binaries (average binary size 261 KB) from different real-world projects. We protect programs against Spectre attack by selectively inserting fences only at vulnerable conditional branches to prevent speculative execution. Our approach is experimentally observed to incur around 5.9 percent performance overheads on SPECint benchmarks.",
        "keywords": [
            "Program processors",
            "Malware",
            "Arrays",
            "Transient analysis",
            "Benchmark testing",
            "Analytical models",
            "Maintenance engineering"
        ]
    },
    {
        "title": "Reading Answers on Stack Overflow: Not Enough!",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2954319",
        "volume": "47",
        "abstract": "Stack Overflow is one of the most active communities for developers to share their programming knowledge. Answers posted on Stack Overflow help developers solve issues during software development. In addition to posting answers, users can also post comments to further discuss their associated answers. As of Aug 2017, there are 32.3 million comments that are associated with answers, forming a large collection of crowdsourced repository of knowledge on top of the commonly-studied Stack Overflow answers. In this study, we wish to understand how the commenting activities contribute to the crowdsourced knowledge. We investigate what users discuss in comments, and analyze the characteristics of the commenting dynamics, (i.e., the timing of commenting activities and the roles of commenters). We find that: 1) the majority of comments are informative and thus can enhance their associated answers from a diverse range of perspectives. However, some comments contain content that is discouraged by Stack Overflow. 2) The majority of commenting activities occur after the acceptance of an answer. More than half of the comments are fast responses occurring within one day of the creation of an answer, while later comments tend to be more informative. Most comments are rarely integrated back into their associated answers, even though such comments are informative. 3) Insiders (i.e., users who posted questions/answers before posting a comment in a question thread) post the majority of comments within one month, and outsiders (i.e., users who never posted any question/answer before posting a comment) post the majority of comments after one month. Inexperienced users tend to raise limitations and concerns while experienced users tend to enhance the answer through commenting. Our study provides insights into the commenting activities in terms of their content, timing, and the individuals who perform the commenting. For the purpose of long-term knowledge maintenance and effective information retrieval for developers, we also provide actionable suggestions to encourage Stack Overflow users/engineers/moderators to leverage our insights for enhancing the current Stack Overflow commenting system for improving the maintenance and organization of the crowdsourced knowledge.",
        "keywords": [
            "Programming",
            "Software",
            "Guidelines",
            "Maintenance engineering",
            "Knowledge discovery",
            "Timing"
        ]
    },
    {
        "title": "A Chaos Engineering System for Live Analysis and Falsification of Exception-Handling in the JVM.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2954871",
        "volume": "47",
        "abstract": "Software systems contain resilience code to handle those failures and unexpected events happening in production. It is essential for developers to understand and assess the resilience of their systems. Chaos engineering is a technology that aims at assessing resilience and uncovering weaknesses by actively injecting perturbations in production. In this paper, we propose a novel design and implementation of a chaos engineering system in Java called \n<small>ChaosMachine</small>\n. It provides a unique and actionable analysis on exception-handling capabilities in production, at the level of try-catch blocks. To evaluate our approach, we have deployed \n<small>ChaosMachine</small>\n on top of 3 large-scale and well-known Java applications totaling \n<inline-formula><tex-math notation=\"LaTeX\">$630k$</tex-math></inline-formula>\n lines of code. Our results show that \n<small>ChaosMachine</small>\n reveals both strengths and weaknesses of the resilience code of a software system at the level of exception handling.",
        "keywords": [
            "Chaos",
            "Production",
            "Perturbation methods",
            "Resilience",
            "Measurement",
            "Monitoring",
            "Java"
        ]
    },
    {
        "title": "Comparative Analysis of Constraint Handling Techniques for Constrained Combinatorial Testing.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2955687",
        "volume": "47",
        "abstract": "Constraints depict the dependency relationships between parameters in a software system under test. Because almost all systems are constrained in some way, techniques that adequately cater for constraints have become a crucial factor for adoption, deployment and exploitation of Combinatorial Testing (CT). Currently, despite a variety of different constraint handling techniques available, the relationship between these techniques and the generation algorithms that use them remains unknown, yielding an important gap and pressing concern in the literature of constrained combination testing. In this article, we present a comparative empirical study to investigate the impact of four common constraint handling techniques on the efficiency of six representative (greedy and search-based) test suite generation algorithms. The results reveal that the \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Verify</i>\n technique implemented with the Minimal Forbidden Tuple (MFT) approach is the fastest, while the \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Replace</i>\n technique is promising for producing the smallest constrained covering arrays, especially for algorithms that construct test cases one-at-a-time. The results also show that there is an interplay between efficiency of the constraint handler and the test suite generation algorithm into which it is developed.",
        "keywords": [
            "Combinatorial testing",
            "Software systems",
            "Computational efficiency"
        ]
    },
    {
        "title": "Using Docker to Assist Q&A Forum Users.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2956919",
        "volume": "47",
        "abstract": "Q&A forums are today a valuable tool to assist developers in programming tasks. Unfortunately, contributions to these forums are often unclear and incomplete. Docker is a container solution that enables software developers to encapsulate an operating environment and could help address reproducibility issues. This artile reports on a feasibility study to evaluate if Docker can help improve reproducibility in Stack Overflow. We started surveying Stack Overflow users to understand their perceptions on the proposal of using Docker to reproduce Stack Overflow posts. Participants were critical and mentioned two important aspects: cost and need. To validate their criticism, we conducted an exploratory study focused on understanding how costly the task of creating containers for posts is for developers. Overall, results indicate that the cost of creating containers is not high, especially due to the fact that dockerfiles are highly similar and small. Based on these findings we developed a tool, dubbed \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Frisk</small>\n, to assist developers in creating containers for those posts. We then conducted a user study to evaluate interest of Stack Overflow developers on the tool. We found that, on average, users spent nearly ten minutes interacting with \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Frisk</small>\n and that 45.3% of the 563 \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Frisk</small>\n sessions we created for existing posts resulted in a successful access to the corresponding web service by the owners of the post. Overall, this artile provides early evidence that the use of Docker in Q&A forums should be encouraged for configuration-related posts.",
        "keywords": [
            "Containers",
            "Servers",
            "Tools",
            "Web services",
            "Proposals",
            "Electronic mail"
        ]
    },
    {
        "title": "Semantic Learning and Emulation Based Cross-Platform Binary Vulnerability Seeker.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2956932",
        "volume": "47",
        "abstract": "Clone detection is widely exploited for software vulnerability search. The approaches based on source code analysis cannot be applied to binary clone detection because the same source code can produce significantly different binaries due to different operating systems, microprocessor architectures and compilers. In this paper, we present <i>BinSeeker</i>, a cross-platform binary seeker that integrates semantic learning and emulation. With the help of the labeled semantic flow graph, <i>BinSeeker</i> can quickly identify <inline-formula><tex-math notation=\"LaTeX\">$M$</tex-math><alternatives><mml:math><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href=\"gao-ieq1-2956932.gif\"/></alternatives></inline-formula> candidate functions that are most similar to the vulnerability from the target binary. The value of <inline-formula><tex-math notation=\"LaTeX\">$M$</tex-math><alternatives><mml:math><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href=\"gao-ieq2-2956932.gif\"/></alternatives></inline-formula> is relatively large so this semantic learning procedure essentially eliminates those functions that are very unlikely to have the vulnerability. Then, semantic emulation is conducted on these <inline-formula><tex-math notation=\"LaTeX\">$M$</tex-math><alternatives><mml:math><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href=\"gao-ieq3-2956932.gif\"/></alternatives></inline-formula> candidates to obtain their dynamic signature sequences. By comparing signature sequences, <i>BinSeeker</i> produces top-<inline-formula><tex-math notation=\"LaTeX\">$N$</tex-math><alternatives><mml:math><mml:mi>N</mml:mi></mml:math><inline-graphic xlink:href=\"gao-ieq4-2956932.gif\"/></alternatives></inline-formula> functions that exhibit most similar behavior to that of the vulnerability. With fast filtering of semantic learning and accurate comparison of semantic emulation, <i>BinSeeker</i> seeks vulnerability precisely with little overhead. The experiments on six widely used programs with fifteen known CVE vulnerabilities demonstrate that <i>BinSeeker</i> outperforms three state-of-the-art tools <i>Genius</i>, <i>Gemini</i> and <i>CACompare</i>. Regarding search accuracy, <i>BinSeeker</i> achieves an MRR value of 0.65 in the target programs, whereas the MRR values by <i>Genius</i>, <i>Gemini</i> and <i>CACompare</i> are 0.17, 0.07 and 0.42, respectively. If we consider ranking a function with the targeted vulnerability in the top-5 as accurate, <i>BinSeeker</i> achieves the accuracy of 93.33 percent, while the accuracy of the other three tools is merely 33.33, 13.33 and 53.33 percent, respectively. Such accuracy is achieved with 0.27s on average to determine whether the target binary function contains a known vulnerability, and the time for the other three tools are 1.57s, 0.15s and 0.98s, respectively. Compared to the time used to manually identify the true positive vulnerability from the false positive candidates reported by Gemini, the time overhead of <i>BinSeeker</i> is negligible. Evidently, the proposed <i>BinSeeker</i> achieves a better balance between accuracy and efficiency.",
        "keywords": [
            "Drilling machines",
            "Process control",
            "Automation",
            "Rocks",
            "Tools"
        ]
    },
    {
        "title": "Where2Change: Change Request Localization for App Reviews.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2956941",
        "volume": "47",
        "abstract": "Million of mobile apps have been released to the market. Developers need to maintain these apps so that they can continue to benefit end users. Developers usually extract useful information from user reviews to maintain and evolve mobile apps. One of the important activities that developers need to do while reading user reviews is to locate the source code related to requested changes. Unfortunately, this manual work is costly and time consuming since: (1) an app can receive thousands of reviews, and (2) a mobile app can consist of hundreds of source code files. To address this challenge, Palomba \n<i>et al.</i>\n recently proposed \n<monospace>CHANGEADVISOR</monospace>\n that utilizes user reviews to locate source code to be changed. However, we find that it cannot identify real source code to be changed for part of reviews. In this work, we aim to advance Palomba \n<i>et al.</i>\n's work by proposing a novel approach that can achieve higher accuracy in change localization. Our approach first extracts the informative sentences (i.e., user feedback) from user reviews and identifies user feedback related to various problems and feature requests, and then cluster the corresponding user feedback into groups. Each group reports the similar users’ needs. Next, these groups are mapped to issue reports by using \n<inline-formula><tex-math notation=\"LaTeX\">$Word2Vec$</tex-math></inline-formula>\n. The resultant enriched text consisting of user feedback and their corresponding issue reports is used to identify source code classes that should be changed by using our novel \n<i>weight selection</i>\n-based cosine similarity metric. We have evaluated the new proposed change request localization approach (\n<monospace>Where2Change</monospace>\n) on 31,597 user reviews and 3,272 issue reports of 10 open source mobile apps. The experiments demonstrate that \n<monospace>Where2Change</monospace>\n can successfully locate more source code classes related to the change requests for more user feedback clusters than \n<monospace>CHANGEADVISOR</monospace>\n as demonstrated by higher Top-N and Recall values. The differences reach up to 17 for Top-1, 18.1 for Top-3, 17.9 for Top-5, and 50.08 percent for Recall. In addition, we also compare the performance of \n<monospace>Where2Change</monospace>\n and two previous Information Retrieval (IR)-based fault localization technologies:\n<monospace>BLUiR</monospace>\n and \n<monospace>BLIA</monospace>\n. The results showed that our approach performs better than them. As an important part of our work, we conduct an empirical study to investigate the value of using both user reviews and historical issue reports for change request localization; the results shown that historical issue reports can help to improve the performance of change localization.",
        "keywords": [
            "Information retrieval",
            "Measurement",
            "Task analysis",
            "Tools",
            "Feature extraction",
            "Software maintenance"
        ]
    },
    {
        "title": "On the Costs and Profit of Software Defect Prediction.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2957794",
        "volume": "47",
        "abstract": "Defect prediction can be a powerful tool to guide the use of quality assurance resources. However, while lots of research covered methods for defect prediction as well as methodological aspects of defect prediction research, the actual cost saving potential of defect prediction is still unclear. Within this article, we close this research gap and formulate a cost model for software defect prediction. We derive mathematically provable boundary conditions that must be fulfilled by defect prediction models such that there is a positive profit when the defect prediction model is used. Our cost model includes aspects like the costs for quality assurance, the costs of post-release defects, the possibility that quality assurance fails to reveal predicted defects, and the relationship between software artifacts and defects. We initialize the cost model using different assumptions, perform experiments to show trends of the behavior of costs on real projects. Our results show that the unrealistic assumption that defects only affect a single software artifact, which is a standard practice in the defect prediction literature, leads to inaccurate cost estimations. Moreover, the results indicate that thresholds for machine learning metrics are also not suited to define success criteria for software defect prediction.",
        "keywords": [
            "Predictive models",
            "Software",
            "Quality assurance",
            "Measurement",
            "Mathematical model",
            "Machine learning",
            "Computational modeling"
        ]
    },
    {
        "title": "Effects of Personality Traits on Pull Request Acceptance.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2960357",
        "volume": "47",
        "abstract": "In this paper, we examine the influence of personality traits of developers on the pull request evaluation process in GitHub. We first replicate Tsay \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">et al.</i>\n’s work that examined the influence of social factors (e.g., ‘social distance’) and technical factors (e.g., test file inclusion) for evaluating contributions, and then extend it with personality based factors. In particular, we extract the Big Five personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) of developers from their online digital footprints, such as pull request comments. We analyze the personality traits of 16,935 active developers from 1,860 projects and compare their relative importance to other non-personality factors from past research, in the pull request evaluation process. We find that pull requests from authors (requesters) who are more open and conscientious, but less extroverted, have a higher chance of approval. Furthermore, pull requests that are closed by developers (closers) who are more conscientious, extroverted, and neurotic, have a higher likelihood of acceptance. The larger the difference in personality traits between the requester and the closer, the more positive effect it has on pull request acceptance. Finally, although the effect of personality traits is significant and comparable to technical factors, we find that social factors are still more influential on the likelihood of pull request acceptance.",
        "keywords": [
            "Psychology",
            "Social factors",
            "Software engineering",
            "Task analysis",
            "Dictionaries",
            "Robots",
            "Software"
        ]
    },
    {
        "title": "A Study of Call Graph Construction for JVM-Hosted Languages.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2956925",
        "volume": "47",
        "abstract": "Call graphs have many applications in software engineering, including bug-finding, security analysis, and code navigation in IDEs. However, the construction of call graphs requires significant investment in program analysis infrastructure. An increasing number of programming languages compile to the Java Virtual Machine (JVM), and program analysis frameworks such as WALA and SOOT support a broad range of program analysis algorithms by analyzing JVM bytecode. This approach has been shown to work well when applied to bytecode produced from Java code. In this paper, we show that it also works well for diverse other JVM-hosted languages: dynamically-typed functional Scheme, statically-typed object-oriented Scala, and polymorphic functional OCaml. Effectively, we get call graph construction for these languages for free, using existing analysis infrastructure for Java, with only minor challenges to soundness. This, in turn, suggests that bytecode-based analysis could serve as an implementation vehicle for bug-finding, security analysis, and IDE features for these languages. We present qualitative and quantitative analyses of the soundness and precision of call graphs constructed from JVM bytecodes for these languages, and also for Groovy, Clojure, Python, and Ruby. However, we also show that implementation details matter greatly. In particular, the JVM-hosted implementations of Groovy, Clojure, Python, and Ruby produce very unsound call graphs, due to the pervasive use of reflection, \n<monospace xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">invokedynamic</monospace>\n instructions, and run-time code generation. Interestingly, the dynamic translation schemes employed by these languages, which result in unsound static call graphs, tend to be correlated with poor performance at run time.",
        "keywords": [
            "Java",
            "Static analysis",
            "Python",
            "Computer security",
            "Software engineering",
            "Graphs"
        ]
    },
    {
        "title": "Scrutinizing Implementations of Smart Home Integrations.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2960690",
        "volume": "47",
        "abstract": "A key feature of the booming smart home is the integration of a wide assortment of technologies, including various standards, proprietary communication protocols and heterogeneous platforms. Due to customization, unsatisfied assumptions and incompatibility in the integration, critical security vulnerabilities are likely to be introduced by the integration. Hence, this work addresses the security problems in smart home systems from an \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">integration</i>\n perspective, as a complement to numerous studies that focus on the analysis of individual techniques. We propose H\n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ome</small>\nS\n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">can</small>\n, an approach that examines the security of the implementations of smart home systems. It extracts the abstract specification of application-layer protocols and internal behaviors of entities, so that it is able to conduct an end-to-end security analysis against various attack models. Applying H\n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ome</small>\nS\n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">can</small>\n on three extensively-used smart home systems, we have found twelve non-trivial security issues, which may lead to unauthorized remote control and credential leakage.",
        "keywords": [
            "Network security",
            "Smart homes",
            "Zigbee",
            "Protocols",
            "Authentication",
            "Java",
            "Wireless fidelity",
            "Internet of Things"
        ]
    },
    {
        "title": "A Study of Bug Resolution Characteristics in Popular Programming Languages.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2019.2961897",
        "volume": "47",
        "abstract": "This paper presents a large-scale study that investigates the bug resolution characteristics among popular Github projects written in different programming languages. We explore correlations but, of course, we cannot infer causation. Specifically, we analyse bug resolution data from approximately 70 million Source Line of Code, drawn from 3 million commits to 600 GitHub projects, primarily written in 10 programming languages. We find notable variations in apparent bug resolution time and patch (fix) size. While interpretation of results from such large-scale empirical studies is inherently difficult, we believe that the differences in medians are sufficiently large to warrant further investigation, replication, re-analysis and follow up research. For example, in our corpus, the median apparent bug resolution time (elapsed time from raise to resolve) for Ruby was 4X that for Go and 2.5X for Java. We also found that patches tend to touch more files for the corpus of strongly typed and for statically typed programs. However, we also found evidence for a \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">lower</i>\n elapsed resolution time for bug resolution committed to projects constructed from statically typed languages. These findings, if replicated in subsequent follow on studies, may shed further empirical light on the debate about the importance of static typing.",
        "keywords": [
            "Computer bugs",
            "Software engineering",
            "Java",
            "Correlation",
            "Programming languages",
            "Data mining"
        ]
    },
    {
        "title": "Review Dynamics and Their Impact on Software Quality.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2964660",
        "volume": "47",
        "abstract": "Code review is a crucial activity for ensuring the quality of software products. Unlike the traditional code review process of the past where reviewers independently examine software artifacts, contemporary code review processes allow teams to collaboratively examine and discuss proposed patches. While the visibility of reviewing activities including review discussions in a contemporary code review tends to increase developer collaboration and openness, little is known whether such visible information influences the evaluation decision of a reviewer or not (i.e., knowing others’ feedback about the patch before providing ones own feedback). Therefore, in this work, we set out to investigate the review dynamics, i.e., a practice of providing a vote to accept a proposed patch, in a code review process. To do so, we first characterize the review dynamics by examining the relationship between the evaluation decision of a reviewer and the visible information about a patch under review (e.g., comments and votes that are provided by prior co-reviewers). We then investigate the association between the characterized review dynamics and the defect-proneness of a patch. Through a case study of 83,750 patches of the OpenStack and Qt projects, we observe that the amount of feedback (either votes and comments of prior reviewers) and the co-working frequency of a reviewer with the patch author are highly associated with the likelihood that the reviewer will provide a positive vote to accept a proposed patch. Furthermore, we find that the proportion of reviewers who provided a vote consistent with prior reviewers is significantly associated with the defect-proneness of a patch. However, the associations of these review dynamics are not as strong as the confounding factors (i.e., patch characteristics and overall reviewing activities). Our observations shed light on the implicit influence of the visible information about a patch under review on the evaluation decision of a reviewer. Our findings suggest that the code reviewing policies that are mindful of these practices may help teams improve code review effectiveness. Nonetheless, such review dynamics should not be too concerning in terms of software quality.",
        "keywords": [
            "Software quality",
            "Human factors",
            "Collaboration",
            "Measurement",
            "Manuals",
            "Proposals",
            "Codes",
            "Performance evaluation"
        ]
    },
    {
        "title": "checsdm: A Method for Ensuring Consistency in Heterogeneous Safety-Critical System Design.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2966994",
        "volume": "47",
        "abstract": "Safety-critical systems are highly heterogeneous, combining different characteristics. Effectively designing such systems requires a complex modelling approach that deals with diverse components (e.g., mechanical, electronic, software)—each having its own underlying domain theories and vocabularies—as well as with various aspects of the same component (e.g., function, structure, behaviour). Furthermore, the regulated nature of such systems prescribes the objectives for their design verification and validation. This paper proposes \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">checsdm</i>\n, a systematic approach, based on Model-Driven Engineering (MDE), for assisting engineering teams in ensuring consistency of heterogeneous design of safety-critical systems. The approach is developed as a generic \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">methodology</i>\n and a \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">tool framework</i>\n, that can be applied to various design scenarios involving different modelling languages and different design guidelines. The methodology comprises an iterative three-phased process. The first phase, \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">elicitation</i>\n, aims at specifying requirements of the heterogeneous design scenario. Using the proposed tool framework, the second phase, \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">codification</i>\n, consists in building a particular tool set that supports the heterogeneous design scenario and helps engineers in flagging consistency errors for review and eventual correction. The third phase, \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">operation</i>\n, applies the tool set to actual system designs. Empirical evaluation of the work is presented through two executions of the \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">checsdm</i>\n approach for the specific cases of a design scenario involving a mix of UML, Simulink and Stateflow, and a design scenario involving a mix of AADL, Simulink and Stateflow. The \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">operation</i>\n phase of the first case was performed over three avionics systems and the identified inconsistencies in the design models of these systems were compared to the results of a fully manual verification carried out by professional engineers. The evaluation also includes an assessment workshop with industrial practitioners to examine their perceptions about the approach. The empirical validation indicates the feasibility and “cost-effectiveness” of the approach. Inconsistencies were identified in the three avionics systems with a greater recall rate over the manual verification. The assessment workshop shows the practitioners found the approach easy to understand and gave an overall likelihood of adoption within the context of their work.",
        "keywords": [
            "Unified modeling language",
            "Software packages",
            "Tools",
            "Object oriented modeling",
            "Safety",
            "Guidelines",
            "Design methodology"
        ]
    },
    {
        "title": "A Machine Learning Approach to Improve the Detection of CI Skip Commits.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2967380",
        "volume": "47",
        "abstract": "Continuous integration (CI) frameworks, such as Travis CI, are growing in popularity, encouraged by market trends towards speeding up the release cycle and building higher-quality software. A key facilitator of CI is to automatically build and run tests whenever a new commit is submitted/pushed. Despite the many advantages of using CI, it is known that the CI process can take a very long time to complete. One of the core causes for such delays is the fact that some commits (e.g., cosmetic changes) unnecessarily kick off the CI process. Therefore, the main \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">goal</i>\n of this paper is to automate the process of determining which commits can be CI skipped through the use of machine learning techniques. We first extracted 23 features from historical data of ten software repositories. Second, we conduct a study on the detection of CI skip commits using machine learning where we built a decision tree classifier. We then examine the accuracy of using the decision tree in detecting CI skip commits. Our results show that the decision tree can identify CI skip commits with an average AUC equal to 0.89. Furthermore, the top node analysis shows that the number of developers who changed the modified files, the CI-Skip rules, and commit message are the most important features to detect CI skip commits. Finally, we investigate the generalizability of identifying CI skip commits through applying cross-project validation, and our results show that the general classifier achieves an average 0.74 of AUC values.",
        "keywords": [
            "Machine learning",
            "Decision trees",
            "Feature extraction",
            "Message systems",
            "Documentation",
            "Buildings"
        ]
    },
    {
        "title": "User Review-Based Change File Localization for Mobile Applications.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2967383",
        "volume": "47",
        "abstract": "In the current mobile app development, novel and emerging DevOps practices (e.g., Continuous Delivery, Integration, and user feedback analysis) and tools are becoming more widespread. For instance, the integration of user feedback (provided in the form of user reviews) in the software release cycle represents a valuable asset for the maintenance and evolution of mobile apps. To fully make use of these assets, it is highly desirable for developers to establish semantic links between the user reviews and the software artefacts to be changed (e.g., source code and documentation), and thus to localize the potential files to change for addressing the user feedback. In this paper, we propose \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">RISING</small>\n (\n<bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">R</b>\neview \n<bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">I</b>\nntegration via cla\n<bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S</b>\nsification, cluster\n<bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">I</b>\nng, and linki\n<bold xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">NG</b>\n), an automated approach to support the continuous integration of user feedback via classification, clustering, and linking of user reviews. \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">RISING</small>\n leverages domain-specific constraint information and semi-supervised learning to group user reviews into multiple fine-grained clusters concerning similar users’ requests. Then, by combining the textual information from both commit messages and source code, it automatically localizes potential change files to accommodate the users’ requests. Our empirical studies demonstrate that the proposed approach outperforms the state-of-the-art baseline work in terms of clustering and localization accuracy, and thus produces more reliable results.",
        "keywords": [
            "Software testing",
            "Mobile applications",
            "User experiences",
            "Information retrieval",
            "Maintenance engineering",
            "Reliability",
            "Software engineering"
        ]
    },
    {
        "title": "MoMIT: Porting a JavaScript Interpreter on a Quarter Coin.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2968061",
        "volume": "47",
        "abstract": "The Internet of Things (IoT) is a network of physical, connected devices providing services through private networks and the Internet. The devices connect through the Internet to Web servers and other devices. One of the popular programming languages for communicating Web pages and Web apps is JavaScript (JS). Hence, the devices would benefit from JS apps. However, porting JS apps to the many IoT devices, e.g., System-on-a-Chip (SoCs) devices (e.g., Arduino Uno), is challenging because of their limited memory, storage, and CPU capabilities. Also, some devices may lack hardware/software capabilities for running JS apps “as is”. Thus, we propose \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">MoMIT</i>\n, a multiobjective optimization approach to miniaturize JS apps to run on IoT devices. We implement \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">MoMIT</i>\n using three different search algorithms. We miniaturize a JS interpreter and measure the characteristics of 23 apps before/after applying \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">MoMIT</i>\n. We find reductions of code size, memory usage, and CPU time of 31, 56, and 36 percent, respectively (medians). We show that \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">MoMIT</i>\n allows apps to run on up to two additional devices in comparison to the original JS interpreter.",
        "keywords": [
            "Optimization",
            "Java",
            "Internet of Things",
            "Computer languages",
            "Embedded devices",
            "Evolutionary algorithms"
        ]
    },
    {
        "title": "RefDiff 2.0: A Multi-Language Refactoring Detection Tool.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2968072",
        "volume": "47",
        "abstract": "Identifying refactoring operations in source code changes is valuable to understand software evolution. Therefore, several tools have been proposed to automatically detect refactorings applied in a system by comparing source code between revisions. The availability of such infrastructure has enabled researchers to study refactoring practice in large scale, leading to important advances on refactoring knowledge. However, although a plethora of programming languages are used in practice, the vast majority of existing studies are restricted to the Java language due to limitations of the underlying tools. This fact poses an important threat to external validity. Thus, to overcome such limitation, in this paper we propose RefDiff 2.0, a multi-language refactoring detection tool. Our approach leverages techniques proposed in our previous work and introduces a novel refactoring detection algorithm that relies on the Code Structure Tree (CST), a simple yet powerful representation of the source code that abstracts away the specificities of particular programming languages. Despite its language-agnostic design, our evaluation shows that RefDiff's precision (96 percent) and recall (80 percent) are on par with state-of-the-art refactoring detection approaches specialized in the Java language. Our modular architecture also enables one to seamlessly extend RefDiff to support other languages via a plugin system. As a proof of this, we implemented plugins to support two other popular programming languages: JavaScript and C. Our evaluation in these languages reveals that precision and recall ranges from 88 to 91 percent. With these results, we envision RefDiff as a viable alternative for breaking the single-language barrier in refactoring research and in practical applications of refactoring detection.",
        "keywords": [
            "Codes",
            "Java",
            "Source coding",
            "History",
            "Crawlers",
            "Measurement"
        ]
    },
    {
        "title": "An Empirical Study on Heterogeneous Defect Prediction Approaches.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2968520",
        "volume": "47",
        "abstract": "Software defect prediction has always been a hot research topic in the field of software engineering owing to its capability of allocating limited resources reasonably. Compared with cross-project defect prediction (CPDP), heterogeneous defect prediction (HDP) further relaxes the limitation of defect data used for prediction, permitting different metric sets to be contained in the source and target projects. However, there is still a lack of a holistic understanding of existing HDP studies due to different evaluation strategies and experimental settings. In this paper, we provide an empirical study on HDP approaches. We review the research status systematically and compare the HDP approaches proposed from 2014 to June 2018. Furthermore, we also investigate the feasibility of HDP approaches in CPDP. Through extensive experiments on 30 projects from five datasets, we have the following findings: (1) metric transformation-based HDP approaches usually result in better prediction effects, while metric selection-based approaches have better interpretability. Overall, the HDP approach proposed by Li \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">et al.</i>\n (CTKCCA) currently has the best performance. (2) Handling class imbalance problems can boost the prediction effects, but the improvements are usually limited. In addition, utilizing mixed project data cannot improve the performance of HDP approaches consistently since the label information in the target project is not used effectively. (3) HDP approaches are feasible for cross-project defect prediction in which the source and target projects have the same metric set.",
        "keywords": [
            "Measurement",
            "NASA",
            "Predictive models",
            "Data models",
            "Software quality"
        ]
    },
    {
        "title": "Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2969178",
        "volume": "47",
        "abstract": "A <i>Cyber-Physical System</i> (CPS) is a system which consists of software components and physical components. Traditional system verification techniques such as model checking or theorem proving are difficult to apply to CPS because the physical components have infinite number of states. To solve this problem, robustness guided falsification of CPS is introduced. Robustness measures how robustly the given specification is satisfied. Robustness guided falsification tries to minimize the robustness by changing inputs and parameters of the system. The input with a minimal robustness (counterexample) is a good candidate to violate the specification. Existing methods use several optimization techniques to minimize robustness. However, those methods do not use temporal structures in a system input and often require a large number of simulation runs to minimize the robustness. In this paper, we explore state-of-the-art <i>Deep Reinforcement Learning</i> (DRL) techniques, i.e., <i>Asynchronous Advantage Actor-Critic</i> (A3C) and <i>Double Deep Q Network</i> (DDQN), to reduce the number of simulation runs required to find such counterexamples. We theoretically show how robustness guided falsification of a safety property is formatted as a reinforcement learning problem. Then, we experimentally compare the effectiveness of our methods with three baseline methods, i.e., random sampling, cross entropy and simulated annealing, on three well known CPS systems. We thoroughly analyse the experiment results and identify two factors of CPS which make DRL based methods better than existing methods. The most important factor is the availability of the system internal dynamics to the reinforcement learning algorithm. The other factor is the existence of learnable structure in the counterexample.",
        "keywords": [
            "Robustness",
            "Reinforcement learning",
            "Model checking",
            "Software",
            "Optimization"
        ]
    },
    {
        "title": "Contract-Based Program Repair Without The Contracts: An Extended Study.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2970009",
        "volume": "47",
        "abstract": "Most techniques for automated program repair (APR) use tests to drive the repair process; this makes them prone to generating spurious repairs that overfit the available tests unless additional information about expected program behavior is available. Our previous work on \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Jaid</small>\n, an APR technique for Java programs, showed that constructing detailed state abstractions—similar to those employed by techniques for programs with contracts—from plain Java code without any special annotations provides valuable additional information, and hence helps mitigate the overfitting problem. This paper extends the work on \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Jaid</small>\n with a comprehensive experimental evaluation involving 693 bugs in three different benchmark suites. The evaluation shows, among other things, that: 1) \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Jaid</small>\n is effective: it produced correct fixes for over 15 percent of all bugs, with a precision of nearly 60 percent; 2) \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Jaid</small>\n is reasonably efficient: on average, it took less than 30 minutes to output a correct fix; 3) \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Jaid</small>\n is competitive with the state of the art, as it fixed more bugs than any other technique, and 11 bugs that no other tool can fix; 4) \n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Jaid</small>\n is robust: its heuristics are complementary and their effectiveness does not depend on the fine-tuning of parameters. The experimental results also indicate the main trade-offs involved in designing an APR technique based on tests, as well as possible directions for further progress in this line of work.",
        "keywords": [
            "Maintenance engineering",
            "Computer bugs",
            "Tools",
            "Java",
            "Monitoring",
            "Contracts",
            "Programming"
        ]
    },
    {
        "title": "A Qualitative Study of the Benefits and Costs of Logging From Developers' Perspectives.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2970422",
        "volume": "47",
        "abstract": "Software developers insert logging statements in their source code to collect important runtime information of software systems. In practice, logging appropriately is a challenge for developers. Prior studies aimed to improve logging by proactively inserting logging statements in certain code snippets or by learning \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">where to log</i>\n from existing logging code. However, there exists no work that systematically studies developers’ logging considerations, i.e., the benefits and costs of logging from developers’ perspectives. Without understanding developers’ logging considerations, automated approaches for logging decisions are based primarily on researchers’ intuition which may not be convincing to developers. In order to fill the gap between developers’ logging considerations and researchers’ intuition, we performed a qualitative study that combines a survey of 66 developers and a case study of 223 logging-related issue reports. The findings of our qualitative study draw a comprehensive picture of the benefits and costs of logging from developers’ perspectives. We observe that developers consider a wide range of logging benefits and costs, while most of the uncovered benefits and costs have never been observed nor discussed in prior work. We also observe that developers use \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">ad hoc</i>\n strategies to balance the benefits and costs of logging. Developers need to be fully aware of the benefits and costs of logging, in order to better benefit from logging (e.g., leveraging logging to enable users to solve problems by themselves) and avoid unnecessary negative impact (e.g., exposing users’ sensitive information). Future research needs to consider such a wide range of logging benefits and costs when developing automated logging strategies. Our findings also inspire opportunities for researchers and logging library providers to help developers balance the benefits and costs of logging, for example, to support different log levels for different parts of a logging statement, or to help developers estimate and reduce the negative impact of logging statements.",
        "keywords": [
            "Runtime",
            "Libraries",
            "Performance evaluation",
            "Software systems",
            "Computational modeling",
            "Quality assessment"
        ]
    },
    {
        "title": "Checking Smart Contracts With Structural Code Embedding.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2971482",
        "volume": "47",
        "abstract": "Smart contracts have been increasingly used together with blockchains to automate financial and business transactions. However, many bugs and vulnerabilities have been identified in many contracts which raises serious concerns about smart contract security, not to mention that the blockchain systems on which the smart contracts are built can be buggy. Thus, there is a significant need to better maintain smart contract code and ensure its high reliability. In this paper, we propose an automated approach to learn characteristics of smart contracts in Solidity, which is useful for clone detection, bug detection and contract validation on smart contracts. Our new approach is based on word embeddings and vector space comparison. We parse smart contract code into word streams with code structural information, convert code elements (e.g., statements, functions) into numerical vectors that are supposed to encode the code syntax and semantics, and compare the similarities among the vectors encoding code and known bugs, to identify potential issues. We have implemented the approach in a prototype, named S\n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">mart</small>\nE\n<sc xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">mbed</small>\n,\n<xref ref-type=\"fn\" rid=\"fn1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><sup>1</sup></xref>\n<fn id=\"fn1\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><label>1.</label><p>The anonymous replication packages can be accessed at: <uri>https://drive.google.com/file/d/1kauLT3y2IiHPkUlVx4FSTda-dVAyL4za/view?usp=sharing</uri>.</p> </fn>\n and evaluated it with more than 22,000 smart contracts collected from the Ethereum blockchain. Results show that our tool can effectively identify many repetitive instances of Solidity code, where the clone ratio is around 90 percent. Code clones such as type-III or even type-IV semantic clones can also be detected accurately. Our tool can identify more than 1000 clone related bugs based on our bug databases efficiently and accurately. Our tool can also help to efficiently validate any given smart contract against a known set of bugs, which can help to improve the users’ confidence in the reliability of the contract.",
        "keywords": [
            "Computer bugs",
            "Smart contracts",
            "Cloning",
            "Blockchains",
            "Security"
        ]
    },
    {
        "title": "Relations Between Effort Estimates, Skill Indicators, and Measured Programming Skill.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2973638",
        "volume": "47",
        "abstract": "There are large skill differences among software developers, and clients and managers will benefit from being able to identify those with better skill. This study examines the relations between low effort estimates, and other commonly used skill indicators, and measured programming skill. One hundred and four professional software developers were recruited. After skill-related information was collected, they were asked to estimate the effort for four larger and five smaller programming tasks. Finally, they completed a programming skill test. The lowest and most over-optimistic effort estimates for the larger tasks were given by those with the lowest programming skill, which is in accordance with the well-known Dunning-Kruger effect. For the smaller tasks, however, those with the lowest programming skill had the highest and most over-pessimistic estimates. The other programming skill indicators, such as length of experience, company assessed skill and self-assessed skill, were only moderately correlated with measured skill and not particularly useful in guiding developer skill identification. A practical implication is that for larger and more complex tasks, the use of low effort estimates and commonly used skill indicators as selection criteria leads to a substantial risk of selecting among the least skilled developers.",
        "keywords": [
            "Software engineering",
            "Psychology",
            "Programming profession",
            "Estimation",
            "Java"
        ]
    },
    {
        "title": "ConfigMiner: Identifying the Appropriate Configuration Options for Config-Related User Questions by Mining Online Forums.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2973997",
        "volume": "47",
        "abstract": "While the behavior of a software system can be easily changed by modifying the values of a couple of configuration options, finding one out of hundreds or thousands of available options is, unfortunately, a challenging task. Therefore, users often spend a considerable amount of time asking and searching around for the appropriate configuration options in online forums such as StackOverflow. In this paper, we propose ConfigMiner, an approach to automatically identify the appropriate option(s) to config-related user questions by mining already-answered config-related questions in online forums. Our evaluation on 2,062 config-related user questions for seven software systems shows that ConfigMiner can identify the appropriate option(s) for a median of 83 percent (up to 91 percent) of user questions within the top-20 recommended options, improving over state-of-the-art approaches by a median of 130 percent. Besides, ConfigMiner reports the relevant options at a median rank of 4, compared to a median of 16-20.5 as reported by the state-of-the-art approaches.",
        "keywords": [
            "Software systems",
            "Computer bugs",
            "Debugging",
            "Statistical analysis",
            "Task analysis",
            "Prediction algorithms",
            "Data mining"
        ]
    },
    {
        "title": "Studying the Association Between Bountysource Bounties and the Issue-Addressing Likelihood of GitHub Issue Reports.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2974469",
        "volume": "47",
        "abstract": "Due to the voluntary nature of open source software, it can be hard to find a developer to work on a particular task. For example, some issue reports may be too cumbersome and unexciting for someone to volunteer to do them, yet these issue reports may be of high priority to the success of a project. To provide an incentive for implementing such issue reports, one can propose a monetary reward, i.e., a bounty, to the developer who completes that particular task. In this paper, we study bounties in open source projects on GitHub to better understand how bounties can be leveraged to evolve such projects in terms of addressing issue reports. We investigated 5,445 bounties for GitHub projects. These bounties were proposed through the Bountysource platform with a total bounty value of $406,425. We find that 1) in general, the timing of proposing bounties is the most important factor that is associated with the likelihood of an issue being addressed. More specifically, issue reports are more likely to be addressed if they are for projects in which bounties are used more frequently and if they are proposed earlier. 2) The bounty value of an issue report is the most important factor that is associated with the issue-addressing likelihood in the projects in which no bounties were used before. 3) There is a risk of wasting money for backers who invest money on long-standing issue reports.",
        "keywords": [
            "Security",
            "Open source software",
            "Task analysis",
            "Timing",
            "Computer bugs"
        ]
    },
    {
        "title": "A Longitudinal Study of Application Structure and Behaviors in Android.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2975176",
        "volume": "47",
        "abstract": "With the rise of the mobile computing market, Android has received tremendous attention from both academia and industry. Application programming in Android is known to have unique characteristics, and Android apps be particularly vulnerable to various security attacks. In response, numerous solutions for particular security issues have been proposed. However, there is little broad understanding about Android app code structure and behaviors along with their implications for app analysis and security defense, especially in an evolutionary perspective. To mitigate this gap, we present a longitudinal characterization study of Android apps to systematically investigate how they are built and execute over time. Through lightweight static analysis and method-level tracing, we examined the code and execution of 17,664 apps sampled from the apps developed in each of eight past years, with respect to metrics in three complementary dimensions. Our study revealed that (1) apps functionalities heavily rely on the Android framework/SDK, and the reliance continues to grow, (2) \n<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Activity</i>\n components constantly dominated over other types of components and were responsible for the invocation of most lifecycle callbacks, (3) event-handling callbacks consistently focused more on user-interface events than system events, (4) the overall use of callbacks has been slowly diminishing over time, (5) the majority of exercised inter-component communications (ICCs) did not carry any data payloads, and (6) sensitive data sources and sinks targeted only one/two dominant categories of information or operations, and the ranking of source/sink categories remained quite stable throughout the eight years. We discuss the implications of our empirical findings for cost-effective app analysis and security defense for Android, and make cost-effectiveness improvement recommendations accordingly.",
        "keywords": [
            "Androids",
            "Humanoid robots",
            "Computer security",
            "Runtime",
            "Measurement",
            "Codes"
        ]
    },
    {
        "title": "Whence to Learn? Transferring Knowledge in Configurable Systems Using BEETLE.",
        "venue_name": "IEEE Transactions on Software Engineering",
        "year": 2021,
        "venue_type": "journals",
        "url": "https://doi.org/10.1109/TSE.2020.2983927",
        "volume": "47",
        "abstract": "As software systems grow in complexity and the space of possible configurations increases exponentially, finding the near-optimal configuration of a software system becomes challenging. Recent approaches address this challenge by learning performance models based on a sample set of configurations. However, collecting enough sample configurations can be very expensive since each such sample requires configuring, compiling, and executing the entire system using a complex test suite. When learning on new data is too expensive, it is possible to use \n<i>Transfer Learning</i>\n to “transfer” old lessons to the new context. Traditional transfer learning has a number of challenges, specifically, (a) learning from excessive data takes excessive time, and (b) the performance of the models built via transfer can deteriorate as a result of learning from a poor source. To resolve these problems, we propose a novel transfer learning framework called BEETLE, which is a “bellwether”-based transfer learner that focuses on identifying and learning from the most relevant source from amongst the old data. This paper evaluates BEETLE with 57 different software configuration problems based on five software systems (a video encoder, an SAT solver, a SQL database, a high-performance C-compiler, and a streaming data analytics tool). In each of these cases, BEETLE found configurations that are as good as or better than those found by other state-of-the-art transfer learners while requiring only a fraction (\n<inline-formula><tex-math notation=\"LaTeX\">$\\frac{1}{7}$</tex-math></inline-formula>\nth) of the measurements needed by those other methods. Based on these results, we say that BEETLE is a new high-water mark in optimally configuring software.",
        "keywords": [
            "Optimization",
            "Software systems",
            "Data collection",
            "Performance evaluation",
            "Computer science",
            "Software engineering",
            "Transfer learning"
        ]
    }
]